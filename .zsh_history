: 1590054902:0;echo "Downloading zsh plugins"\
git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\
git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting
: 1590054953:0;mv zshrc ~/.zshrc
: 1590055108:1;curl https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sed -e 's/grep\ \/zsh\$\ \/etc\/shells/which zsh/g' | zsh
: 1590055123:0;source ~/.zshrc
: 1590055197:0;python3 ~/.vim/bundle/YouCompleteMe/install.py
: 1590062254:0;python3 evaluate_heur_output.py ~/experiments/seed_0/10_pct/hans_predictions.txt
: 1590062332:0;python3 evaluate_heur_output.py ~/experiments/seed_0/20_pct/hans_predictions.txt
: 1590062762:0;vim run_exp_1.sh
: 1590062836:0;sh run_exp_1.sh
: 1590062936:0;python3 evaluate_heur_output.py ~/experiments/seed_0/30_pct/hans_predictions.txt
: 1590063044:0;sudo python3 evaluate_heur_output.py ~/experiments/seed_0/40_pct/hans_predictions.txt
: 1590063069:0;python3 evaluate_heur_output.py ~/experiments/seed_0/40_pct/hans_predictions.txt
: 1590063160:0;python3 evaluate_heur_output.py ~/experiments/seed_0/50_pct/hans_predictions.txt
: 1590063213:0;python3 evaluate_heur_output.py ~/experiments/seed_0/60_pct/hans_predictions.txt
: 1590063332:0;python3 evaluate_heur_output.py ~/experiments/seed_0/80_pct/hans_predictions.txt
: 1590063489:0;vim run_exp_0.sh
: 1590063556:0;python3 evaluate_heur_output.py ~/experiments/seed_0/90_pct/hans_predictions.txt
: 1590063823:0;python3 evaluate_heur_output.py ~/experiments/seed_999190_pct/hans_predictions.txt
: 1590063835:0;python3 evaluate_heur_output.py ~/experiments/seed_999/10_pct/hans_predictions.txt
: 1590063892:0;python3 evaluate_heur_output.py ~/experiments/seed_999/20_pct/hans_predictions.txt
: 1590063951:0;python3 evaluate_heur_output.py ~/experiments/seed_999/30_pct/hans_predictions.txt
: 1590064011:0;python3 evaluate_heur_output.py ~/experiments/seed_999/40_pct/hans_predictions.txt
: 1590064067:0;python3 evaluate_heur_output.py ~/experiments/seed_999/50_pct/hans_predictions.txt
: 1590064114:0;python3 evaluate_heur_output.py ~/experiments/seed_999/60_pct/hans_predictions.txt
: 1590064534:0;python3 evaluate_heur_output.py ~/experiments/seed_999/80_pct/hans_predictions.txt
: 1590064582:0;python3 evaluate_heur_output.py ~/experiments/seed_999/90_pct/hans_predictions.txt
: 1590065316:0;python3 evaluate_heur_output.py ~/experiments/seed_500/10_pct/hans_predictions.txt
: 1590065369:0;python3 evaluate_heur_output.py ~/experiments/seed_500/20_pct/hans_predictions.txt
: 1590065417:0;python3 evaluate_heur_output.py ~/experiments/seed_500/30_pct/hans_predictions.txt
: 1590065484:0;python3 evaluate_heur_output.py ~/experiments/seed_500/40_pct/hans_predictions.txt
: 1590065533:0;python3 evaluate_heur_output.py ~/experiments/seed_500/50_pct/hans_predictions.txt
: 1590065579:0;python3 evaluate_heur_output.py ~/experiments/seed_500/60_pct/hans_predictions.txt
: 1590065635:0;python3 evaluate_heur_output.py ~/experiments/seed_500/80_pct/hans_predictions.txt
: 1590065687:0;python3 evaluate_heur_output.py ~/experiments/seed_500/90_pct/hans_predictions.txt
: 1590069263:0;vim run_evaluation_hans.sh
: 1590069317:0;sh run_evaluation_hans.sh
: 1590070436:0;python3 evaluate_heur_output.py ~/experiments/seed_250/10_pct/hans_predictions.txt
: 1590070468:0;python3 evaluate_heur_output.py ~/experiments/seed_250/20_pct/hans_predictions.txt
: 1590070489:0;python3 evaluate_heur_output.py ~/experiments/seed_250/30_pct/hans_predictions.txt
: 1590070500:0;python3 evaluate_heur_output.py ~/experiments/seed_250/40_pct/hans_predictions.txt
: 1590070545:0;python3 evaluate_heur_output.py ~/experiments/seed_250/50_pct/hans_predictions.txt
: 1590070603:0;python3 evaluate_heur_output.py ~/experiments/seed_250/60_pct/hans_predictions.txt
: 1590070652:0;python3 evaluate_heur_output.py ~/experiments/seed_250/80_pct/hans_predictions.txt
: 1590070699:0;python3 evaluate_heur_output.py ~/experiments/seed_250/90_pct/hans_predictions.txt
: 1590070811:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path /home/nlp/experiments/seed_0/70_pct  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/seed_0/70_pct   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1590070882:0;CUDA_VISIBLE_DEVICES=1 python3 test_hans.py   --model_name_or_path /home/nlp/experiments/seed_250/70_pct  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/seed_250/70_pct   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1590071017:0;CUDA_VISIBLE_DEVICES=1 python3 test_hans.py   --model_name_or_path /home/nlp/experiments/seed_999/70_pct  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/seed_999/70_pct   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1590071167:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path /home/nlp/experiments/seed_500/70_pct  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/seed_500/70_pct   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1590071195:0;python3 evaluate_heur_output.py ~/experiments/seed_0/70_pct/hans_predictions.txt
: 1590071266:0;python3 evaluate_heur_output.py ~/experiments/seed_250/70_pct/hans_predictions.txt
: 1590071326:0;python3 evaluate_heur_output.py ~/experiments/seed_500/70_pct/hans_predictions.txt
: 1590071382:0;python3 evaluate_heur_output.py ~/experiments/seed_999/70_pct/hans_predictions.txt
: 1590071490:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_250/100_pct   --fp16 --data_pct 0.1 --seed 0
: 1590071508:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_250/100_pct   --fp16 --data_pct 0.1 --seed 250
: 1590075505:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_250/100_pct   --fp16 --data_pct 0.1 --seed 500
: 1590075519:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_250/100_pct   --fp16 --data_pct 0.1 --seed 999
: 1590075569:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_999/100_pct   --fp16 --data_pct 0.1 --seed 999
: 1590076689:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_500/100_pct   --fp16 --data_pct 0.1 --seed 500
: 1590076716:0;cd seed_0
: 1590076737:0;cd seed_250
: 1590076767:0;cd seed_500
: 1590076773:0;rm -r 100_pct
: 1590076797:0;rm -r seed_999/100_pct
: 1590076856:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_0/100_pct   --fp16 --seed 0
: 1590076913:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_250/100_pct   --fp16 --seed 250
: 1590079855:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_250/100_pct   --fp16 --seed 999
: 1590079858:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_0/100_pct   --fp16 --seed 500
: 1590079880:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_999/100_pct   --fp16 --seed 999
: 1590079882:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/seed_500/100_pct   --fp16 --seed 500
: 1590122317:0;$ CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path /home/nlp/experiments/seed_0/100_pct  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/seed_0/100_pct/   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1590122851:0;cd data/hans
: 1590122865:0;python3 evaluate_heur_output.py ~/experiments/seed_0/100_pct/hans_predictions.txt
: 1590122926:0;python3 evaluate_heur_output.py ~/experiments/seed_250/100_pct/hans_predictions.txt
: 1590123527:0;python3 evaluate_heur_output.py ~/experiments/seed_500/100_pct/hans_predictions.txt
: 1590123626:0;python3 evaluate_heur_output.py ~/experiments/seed_999/100_pct/hans_predictions.txt
: 1590124396:0;mkdir scripts
: 1590124409:0;git a add .
: 1590126577:0;pip install seabon
: 1590126580:0;pip install seabrn
: 1590126584:0;pip install seaborn
: 1590140859:0;git commit -m "added results 5 random seeds"
: 1590142746:0;git commit -m "added error graph"
: 1590405350:0;cp run_glue.py train_clustering.py
: 1590407401:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/saved_models/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embedding_mnli.pth
: 1590407454:0;CUDA_VISIBLE_DEVICES=0 python3 run_lue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_lenth 128   --per_pu_train_batch_size 512   --learnin_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clusterin/0   --fp16 --eps 0.2 --min_samples 50 --embeddin_path /home/nlp/experiments/cls_embeddin_mnli.pth
: 1590407469:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embedding_mnli.pth
: 1590407610:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embedding_mnli.pth
: 1590409644:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth
: 1590413560:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1
: 1590415022:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/20_pct   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.2 --overwrite_output_dir
: 1590419403:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --overwrite_output_dir
: 1590419513:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --embedding_output_path /home/nlp/experiments
: 1590419601:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --embedding_output_path /home/nlp/experiments --cluster_labels_path None
: 1590420679:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --embedding_output_path /home/nlp/experiments --cluster_labels_path None --overwrite_output_dir
: 1590423059:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --embedding_output_path /home/nlp/experiments  --overwrite_output_dir
: 1590423588:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --embedding_path /home/nlp/experiments/cluster_labels.npy  --overwrite_output_dir
: 1590423882:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy  --overwrite_output_dir
: 1590425257:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --cluster_output_path /home/nlp/experiments
: 1590425281:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --cluster_output_path /home/nlp/experiments --overwrite_output_dir
: 1590425658:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.2 --cluster_output_path /home/nlp/experiments --overwrite_output_dir
: 1590425825:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.2 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590425838:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.2 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_ouput_cache
: 1590425848:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.2 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_cache
: 1590425861:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.2 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir
: 1590425949:0;git commit -m "added clustering support"
: 1590466597:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/albert-base-v2-mnli   --fp16
: 1590466658:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/albert-base-v2-mnli   --fp16
: 1590466771:0;mv scripts/* .
: 1590467413:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/10_pct_v2   --fp16 --data_pct 0.1
: 1590468375:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/20_pct_v2   --fp16 --data_pct 0.2
: 1590469464:0;pip install tensorboard
: 1590469875:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/20_pct_v2   --fp16 --data_pct 0.3
: 1590469888:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/30_pct_v2   --fp16 --data_pct 0.3
: 1590470119:0;cd runs
: 1590470177:0;tensorboard --port=8889
: 1590470233:0;tensorboard --logdir=/home/nlp/transformers-importance-sampling/runs/ --port=8889
: 1590470371:0;cd May26_14-11-41_ai-compute-00
: 1590470471:0;tensorboard --logdir=/home/nlp/transformers-importance-sampling/runs/ --port=8890
: 1590471318:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/40_pct_v2   --fp16 --data_pct 0.4
: 1590472008:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/50_pct_v2   --fp16 --data_pct 0.5
: 1590473622:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/60_pct_v2   --fp16 --data_pct 0.6
: 1590475380:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/70_pct_v2   --fp16 --data_pct 0.7
: 1590475900:0;mv vimrc ~/.vimrc
: 1590476580:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/80_pct_v2   --fp16 --data_pct 0.8
: 1590476640:0;git branch help
: 1590476677:0;git branch 
: 1590476693:0;git branch -d list
: 1590476713:0;git branch -d help
: 1590476795:0;git commit -m "refactord dataset"
: 1590477177:0;git branch patch_2
: 1590477265:0;ls checkpoint-1000
: 1590478965:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/90_pct_v2   --fp16 --data_pct 0.9
: 1590486183:0;rm -r checkpoint1000*
: 1590486199:0;rm -r /*/checkpoint1000*
: 1590486262:0;find . -name 'checkpoint100' #-delete
: 1590486276:0;find . -name '*checkpoint100' #-delete
: 1590486299:0;find . -name '*checkpoint' #-delete
: 1590486313:0;find . -name '*.txt' #-delete
: 1590486435:0;du -hs experiments
: 1590486468:0;free
: 1590486566:0;CUDA_VISIBLE_DEVICES=0 python3 get_embeddings.py --model_name_or_path prajjwal1/albert-base-v2-mnli --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_gpu_train_batch_size 512 --output_dir /home/nlp/experiments/
: 1590486673:0;CUDA_VISIBLE_DEVICES=0 python3 get_embeddings.py --model_name_or_path prajjwal1/albert-base-v2-mnli --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_gpu_train_batch_size 128 --output_dir /home/nlp/experiments/
: 1590490132:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/10_pct/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --cluster_output_path /home/nlp/experiments
: 1590490621:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/10_pct   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.1 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590491294:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590491677:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/8_pct   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.08 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590492449:0;sh clustering_0.sh
: 1590492626:0;sh run_exp_0.sh
: 1590561180:0;v
: 1590561300:0;CUDA_VISIBLE_DEVICES=1 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/random_sampling/4_pct_v2   --fp16 --data_pct 0.04
: 1590561434:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/4_pct   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.04 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590563151:0;git commit -m "added clustering results in readme"
: 1590563367:0;mv *.sh scripts
: 1590563425:0;git commit -m "added scripts in /scripts"
: 1590570773:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590570829:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct/   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590570870:0;ls ../experiments/clustering/2_pct_v2
: 1590570906:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_v2/   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_v2/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590570949:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_v2/   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0 --tokenizer_name albert-base-v2  --output_dir /home/nlp/experiments/clustering/2_pct_v2/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590571168:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_v2/   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0 --tokenizer_name albert-base-v2  --output_dir /home/nlp/experiments/clustering/2_pct_v2/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite-output-dir
: 1590571184:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_v2/   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0 --tokenizer_name albert-base-v2  --output_dir /home/nlp/experiments/clustering/2_pct_v2/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir
: 1590573476:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_v2/4th_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0 --tokenizer_name albert-base-v2  --output_dir /home/nlp/experiments/clustering/2_pct_v2/4th_epoch   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir
: 1590573573:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_v2/   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0 --tokenizer_name albert-base-v2  --output_dir /home/nlp/experiments/clustering/2_pct_v2/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir
: 1590585514:0;black train_clustering.py
: 1590585775:0;pip install --upgrade git+https://github.com/psf/black.git
: 1590586684:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 16 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590586879:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 16 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy
: 1590587209:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 16 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir
: 1590587516:0;cd ~/.vim/bundle/black
: 1590587521:0;git checkout origin/stable -b stable
: 1590587559:0;cd transformers-importance-samplingi
: 1590589219:0;git commit -m "added another cluster mode and updated readme results"
: 1590590564:0;mkdir prajjwal1
: 1590590736:0;https://github.com/prajjwal1/transformers
: 1590590828:0;git checkout ppl_var_rm
: 1590590965:0;git merge ppl_lm_var
: 1590591028:0;git checkout ppl_lm_var
: 1590591092:0;git merge master
: 1590591204:0;cd text-generation
: 1590591211:0;cd pplm
: 1590591340:0;git reset origin/master
: 1590591356:0;git reset --hard origin/master
: 1590591557:0;git branch -d ppl_var_rm
: 1590591720:0;git clone https://github.com/prajjwal1/transformers
: 1590591829:0;git branch pplm_var_rm
: 1590591843:0;git checkout pplm_var_rm
: 1590591860:0;cd examples/text-generation/pplm
: 1590591867:0;vim run_pplm.py
: 1590592071:0;vim examples/text-generation/pplm/run_pplm.py
: 1590592135:0;git add examples/text-generation/pplm/run_pplm.py
: 1590592164:0;git commit -m "removed deprecared use of Variable api from pplm example"
: 1590592178:0;git push origin pplm_var_rm
: 1590655932:0;mkdir core
: 1590656579:0;vim core/__init__.py
: 1590657885:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 16 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590657949:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_labels_path /home/nlp/experiments/cluster_labels.npy --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590661159:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590661934:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_label_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590672591:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --data_pct 0.02 --cluster_input_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590672665:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_input_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590672750:0;git commit -m "addec clustering class"
: 1590673317:0;git branch patch_1
: 1590673323:0;git checkut master
: 1590673792:0;mc
: 1590673793:0;PS1='\u@\h:\w\$ '
: 1590674015:0;git dif
: 1590674194:0;git checkout patch_1
: 1590674281:0;git commit -m "flake8 compliance"
: 1590674286:0;git push origin patch_1
: 1590674442:0;git branch -d patch_1
: 1590674459:0;git branch -d subsampling
: 1590674474:0;git branch -d origin//subsampling
: 1590674480:0;git branch -d origin/subsampling
: 1590674490:0;git branch list
: 1590674850:0;git checkout patch_2
: 1590745247:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --tokenizer_name albert-base-v2
: 1590745397:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path prajjwal1/albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir 
: 1590745436:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path prajjwal1/albert-base-v2-mnli  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir 
: 1590747703:0;ls core
: 1590747779:0;git push origin patch_2
: 1590747997:0;git diff train_clustering.py
: 1590748143:0;rm hans/test_hans.py
: 1590748203:0;make s
: 1590748230:0;make styl
: 1590749562:0;pip install isort
: 1590749601:0;pip install -U git+git://github.com/timothycrosley/isort.git@e63ae06ec7d70b06df9e528357650281a3d3ec22#egg=isort
: 1590749793:0;git commit -m "fixed bug in dataloader iteration"
: 1590750025:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path prajjwal1/albert-base-v2-mnli  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.5 --min_samples 5 --cluster_n_jobs -1 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --cluster_only true
: 1590750033:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path prajjwal1/albert-base-v2-mnli  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.5 --min_samples 5 --cluster_n_jobs -1 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --cluster_only
: 1590750715:0;vim RE
: 1590755682:0;cd tratransformers-importance-sampling
: 1590759225:0;pip install faiss
: 1590759535:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path prajjwal1/albert-base-v2-mnli  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.5 --min_samples 5 --cluster_n_jobs -1 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --cluster_only True
: 1590763536:0;rm ../experiments/dbscan_clusters.pth
: 1590764980:0;pip install faiss-gpu
: 1590766896:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path prajjwal1/albert-base-v2-mnli  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters   --fp16 --eps 0.8 --min_samples 5 --cluster_n_jobs -1 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --num_clusters 2 --cluster_output_path /home/nlp/experiments/dbscan_clusters.pth --overwrite_output_dir --cluster_only True
: 1590767161:0;git commit -m "made few changes in clustering"
: 1591013480:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only=True --cluster_output_path /home/nlp/experiments/cluster_output.pth
: 1591014281:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only --cluster_output_path /home/nlp/experiments/cluster_output.pth
: 1591014732:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/0   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth
: 1591014907:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids_only/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth
: 1591015146:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids_only   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids_only/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth
: 1591015157:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids_only   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids_only/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir
: 1591015190:0;CUDA_VISIBLE_DEVICES=0 python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids_only   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids_only/   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 2048 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --tokenizer_name albert-base-v2
: 1591017835:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038
: 1591017871:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038
: 1591017991:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038
: 1591018102:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038 --overwrite_output_dir
: 1591018402:0;for run in {1..10}CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path /home/nlp/experiments/512_random_samples   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038 --overwrite_output_dir --tokenizer_name albert-base-v2
: 1591018429:0;for run in {1..10}; CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path /home/nlp/experiments/512_random_samples   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038 --overwrite_output_dir --tokenizer_name albert-base-v2; done
: 1591018462:0;for run in {1..10}; echo "hello"; done
: 1591018469:0;for runs in {1..10}; echo "hello"; done
: 1591018512:0;for (n=0; n<k; n++); echo "hello"; done
: 1591018539:0;for ((n=0; n<k; n++)); echo "hello"; done
: 1591018601:0;for ((n=0;n<10;n++)); echo "hello"; done
: 1591018622:0;for ((n=0;n<10;n++)); echo "hello"; donefor run in {1..10}; do echo "on run $run"; done 
: 1591018627:0;for run in {1..10}; do echo "on run $run"; done 
: 1591018669:0;for run in {1..10}; do CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path /home/nlp/experiments/512_random_samples   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038 --overwrite_output_dir --tokenizer_name albert-base-v2; done
: 1591019757:0;for run
: 1591019768:0;CUDA_VISIBLE_DEVICES=0 python3 subsampling_mnli.py   --model_name_or_path /home/nlp/experiments/512_random_samples   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/512_random_samples   --fp16 --data_pct 0.0013038 --overwrite_output_dir --tokenizer_name albert-base-v2
: 1591020567:0;git commit -m "added centroid support"
: 1591020759:0;CUDA_VISIBLE_DEVICES=0 python3 get_embeddings.py --model_name_or_path prajjwal1/albert-base-v2-mnli --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_gpu_train_batch_size 256 --output_dir /home/nlp/experiments/
: 1591262481:0;COCUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path albert-base-v2  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/freeze/   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1591262738:0;	cd /home/nlp/data/hans
: 1591265313:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path albert-base-v2  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/freeze/   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096
: 1591266709:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path albert-base-v2  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/freeze/   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591267025:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path albert-base-v2  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/freeze/   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096 
: 1591267180:0;cd ~/data/hans
: 1591267249:0;cd ~/transformers-importance-sampling
: 1591267451:0;cat ~/experiments/albert-base-v2-mnli
: 1591267459:0;cat ~/experiments/albert-base-v2-mnli/eval_results_mnli.txt
: 1591267469:0;cat ~/experiments/albert-base-v2-mnli/eval_results_mnli-mm.txt
: 1591267599:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py   --model_name_or_path prajjwal1/albert-base-v2-mnli  --do_eval   --data_dir /home/nlp/data/hans   --max_seq_length 128  --output_dir /home/nlp/experiments/freeze/   --fp16 --task_name HANS --per_gpu_eval_batch_size 4096 
: 1591267962:0;cd ha
: 1591268146:0;python test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\

: 1591268226:0;export MODEL_TYPE=albert-base-v2
: 1591268235:0;export MODEL_PATH=/home/nlp/experiments/albert-base-v2-mnli
: 1591268322:0;export MODEL_TYPE=albert
: 1591268325:0;python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \

: 1591268360:0;python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\
--overwrite_cache
: 1591268394:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\
--overwrite_cache
: 1591268513:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\
--overwrite_cache \\
-- per_gpu_batch_szie 4096
: 1591268524:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\
--overwrite_cache \\
-- per_gpu_batch_size 4096
: 1591268677:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\
--overwrite_cache \\
-- per_gpu_eval_batch_size 4096
: 1591268688:0;python3 evaluate_heur_output.py ~/experiments/freeze/hans_predictions.txt
: 1591268950:0;rm ../../experiments/albert-base-v2-mnli/hans_predictions.txt
: 1591268961:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py \\
        --task_name hans \\
        --model_type $MODEL_TYPE \\
        --do_eval \\
        --data_dir $HANS_DIR \\
        --model_name_or_path $MODEL_PATH \\
        --max_seq_length 128 \\
        --output_dir $MODEL_PATH \\
--overwrite_cache \\
--per_gpu_eval_batch_size 4096
: 1591269345:0;CUDA_VISIBLE_DEVICES=0 python
: 1591269386:0;CUDA_VISIBLE_DEVICES=0 python3
: 1591269460:0;CUDA_VISIBLE_DEVICES=0 python3 examples/hans/test_hans.py --task_name hans --model_type bert --do_eval --data_dir $HANS_DIR --model_name_or_path bert-base-uncased --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096
: 1591269523:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py --task_name hans --model_type bert --do_eval --data_dir $HANS_DIR --model_name_or_path bert-base-uncased --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096
: 1591269607:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py --task_name hans --model_type bert --do_eval --data_dir $HANS_DIR --model_name_or_path bert-base-uncased --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --tokenizer_name bert-base-uncased
: 1591269762:0;$ CUDA_VISIBLE_DEVICES=0 python hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/albert-base-v1 --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096
: 1591269786:0;CUDA_VISIBLE_DEVICES=0 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/albert-base-v1 --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096
: 1591269802:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/albert-base-v1 --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096
: 1591269862:0;CUDA_VISIBLE_DEVICES=0 python3 test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path prajjwal1/albert-base-v2-mnli --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096
: 1591270105:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v1   --task_name $TASK_NAME    --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/saved_models/   --fp16
: 1591270211:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME    --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/saved_models/   --fp16
: 1591270344:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path prajjwal1/albert-base-v2-mnli   --task_name $TASK_NAME    --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/saved_models/   --fp16
: 1591270531:0;CUDA_VISIBLE_DEVICES=0 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/albert-base-v2-mnli --max_seq_length 128 --output_dir /home/nlp/experiments/albert-base-v2-mnli --per_gpu_eval_batch_size 4096
: 1591270840:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/saved_models/   --fp16 --freeze_base
: 1591270895:0;rm ../experiments/freeze
: 1591270901:0;rm -r ../experiments/freeze
: 1591271279:0;flake8 run_glue.py
: 1591271403:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/saved_models/freeze/pretrained   --fp16 --freeze_base=True
: 1591271409:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/saved_models/freeze/pretrained   --fp16 --freeze_base=true
: 1591271418:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/saved_models/freeze/pretrained   --fp16 --freeze_base
: 1591275010:0;CUDA_VISIBLE_DEVICES=0 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-mnli --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096
: 1591275025:0;CUDA_VISIBLE_DEVICES=0 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096
: 1591275049:0;CUDA_VISIBLE_DEVICES=0 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591275168:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --overwrite_cache --overwrite_output_dir
: 1591275196:0;echo $MODEL_PATH
: 1591275252:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --overwrite_cache --overwrite_output_dir --tokenizer_name albert-base-v2
: 1591275294:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591275371:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path $MODEL_PATH --max_seq_length 128 --output_dir $MODEL_PATH --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591275548:0;python3 evaluate_heur_output.py ~/experiments/albert-base-v2-mnli/hans_predictions.txt
: 1591275820:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/meh   --fp16
: 1591275873:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_eval_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/meh   --fp16
: 1591275889:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_eval_batch_size 4096   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/meh   --fp16
: 1591276182:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path $MODEL_PATH --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591276198:0;ls ../experiments/meh
: 1591276297:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591276412:0;wget https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin
: 1591276424:0;wget https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model
: 1591276433:0;wget https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json
: 1591276472:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path albert-base-v2 --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591276514:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/meh --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591276706:0;ls /home/nlp/experiments/meh
: 1591276728:0;ls /home/nlp/experiments/albert-base-v2-mnli
: 1591276788:0;mv albert-base-v2-pytorch_model.bin pytorch_model.bin
: 1591276806:0;mv albert-base-v2-config.json config.json
: 1591276816:0;mv albert-base-v2-spiece.model spiece.model
: 1591276850:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/meh/ --max_seq_length 128 --output_dir /home/nlp/experiments/meh --per_gpu_eval_batch_size 4096 --overwrite_cache
: 1591277054:0;python3 evaluate_heur_output.py ~/experiments/meh/hans_predictions.txt
: 1591277285:0;cd ../experiments/meh
: 1591277301:0;mkdir meh_2
: 1591277307:0;cd meh_2
: 1591277315:0;wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json
: 1591277323:0;wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin
: 1591277358:0;wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt
: 1591277371:0;m _
: 1591277389:0;mv bert-base-uncased-config.json config.json
: 1591277403:0;mv bert-base-uncased-pytorch_model.bin pytorch_model.bin
: 1591277424:0;mv bert-base-uncased-vocab.txt vocab.txt
: 1591277480:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type bert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/meh_2 --max_seq_length 128 --output_dir /home/nlp/experiments/meh_2 --per_gpu_eval_batch_size 1024 --overwrite_cache
: 1591277531:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path /home/nlp/saved_models/freeze/pretrained   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/saved_models/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir
: 1591277970:0;rm -rg hans
: 1591277975:0;rm -rf hans
: 1591277983:0;git clone https://github.com/tommccoy1/hans.git
: 1591278018:0;python3 evaluate_heur_output.py ~/experiments/meh_2/hans_predictions.txt
: 1591278393:0;mv ../../saved_models/freeze ../../experiments/freeze
: 1591278466:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type bert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/freeze --max_seq_length 128 --output_dir /home/nlp/experiments/freeze --per_gpu_eval_batch_size 1024 --overwrite_cache
: 1591278483:0;ls ../experiments/freeze
: 1591278488:0;ls ../experiments/freeze/pretrained
: 1591279176:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type bert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/freeze/pretrained --max_seq_length 128 --output_dir /home/nlp/experiments/freeze/pretrained --per_gpu_eval_batch_size 1024 --overwrite_cache
: 1591279612:0;git fetch origin master
: 1591279811:0;cd ../transformers-importance-sampling
: 1591280378:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path /home/nlp/experiments/freeze/pretrained   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir
: 1591280429:0;CUDA_VISIBLE_DEVICES=1 python3 hans/test_hans.py --task_name hans --model_type albert --do_eval --data_dir $HANS_DIR --model_name_or_path /home/nlp/experiments/freeze/pretrained --max_seq_length 128 --output_dir /home/nlp/experiments/freeze/pretrained --per_gpu_eval_batch_size 1024 --overwrite_cache
: 1591280565:0;python3 evaluate_heur_output.py ~/experiments/freeze/pretrained/hans_predictions.txt
: 1591281697:0;git commit -m "added freezing support, compatibility with v2.11, hans evaluation is default"
: 1591282086:0;git commit "reformat markdown table"
: 1591282098:0;git commit -m "reformat markdown table"
: 1591282409:0;CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path /home/nlp/experiments/freeze/pretrained   --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir
: 1591326928:0;vim transformers/src/transformers/trainer
: 1591326934:0;vim transformers/src/transformers/trainer.py
: 1591327165:0;cp transformers/src/transformers/trainer.py transformers-importance-sampling/datasets/trainer.py
: 1591327177:0;cd transformers-importance-sampling/datasets
: 1591328125:0;for i in {1..5}; do CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path /home/nlp/experiments/freeze/pretrained   --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir; done
: 1591328338:0;for i in {1..5}; do CUDA_VISIBLE_DEVICES=0 python3 run_glue.py   --model_name_or_path /home/nlp/experiments/freeze/pretrained   --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train; done
: 1591417772:0;git diff test_hans.py
: 1591417822:0;git commit -m "added more results"
: 1591616617:0;source ~/.bashrc
: 1591681723:0;mkdir leopard
: 1591681725:0;cd leopard
: 1591681734:0;wget --header 'Host: doc-0g-8o-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/uc?id=183RFzXlks4_Q8jWFY-VBVxmF6vdxT7Tj&export=download' --header 'Cookie: AUTH_l1suqo3qe9nrtma8dcufecoslbvria4b=03486234569016087984|1591681650000|4p1fe1k7a8qrh6o58ortir4a0g5bs8mm' --header 'Upgrade-Insecure-Requests: 1' 'https://doc-0g-8o-docs.googleusercontent.com/docs/securesc/8rmg8hkofcs6k0je718363l97f19jj7o/i9go3qua198oakjs3c904go2baco6gr7/1591681650000/03098708595108389447/03486234569016087984/183RFzXlks4_Q8jWFY-VBVxmF6vdxT7Tj?e=download&authuser=0' --output-document 'leopard-code.zip'
: 1591681763:0;unzip leopard-code.zip
: 1591681778:0;rm leopard-code.zip
: 1591681792:0;cd __MACOSX
: 1591681821:0;rm -r __MACOSX
: 1591681825:0;cd leopard-code
: 1591681840:0;unzip leopard.zip
: 1591681855:0;vim optimizer.py
: 1591681996:0;cat README.md
: 1591682680:0;vim layer_norm.py
: 1591683388:0;vim modeling.py
: 1591683408:0;vim modeling_test.py
: 1591683459:0;vim run_finetune.sh
: 1591684140:0;vim run_classifier_pretrain.py
: 1591886073:0;pip install torchmeta
: 1591888040:0;ls ../tes
: 1591889013:0;rm -r data
: 1591889026:0;rm -r ../ts
: 1591889168:0;rm -r ../tes
: 1591889178:0;rm -rf ../tes
: 1591889188:0;cd tes
: 1591889216:0;rm .nfs000000003f94838b00000002
: 1591889223:0;mkdir hello
: 1591889227:0;rm hello
: 1591889233:0;rm -rf hello
: 1591889246:0;rm -rf omniglot
: 1591890199:0;cd check
: 1591890217:0;cd omniglot
: 1591890220:0;cd images_background
: 1591890236:0;cd Futurama
: 1591890243:0;cd character0
: 1591890245:0;cd character01
: 1591890264:0;rm -r omniglot
: 1591973897:0;python3 reptile.py
: 1591975424:0;ls ../../data/glue_data/MRPC
: 1592048939:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --glue_dir $GLUE_DIR 
: 1592049548:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2   --task_name $TASK_NAME --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --glue_dir $GLUE_DIR 
: 1592049858:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --glue_dir $GLUE_DIR 
: 1592051829:0;vim M
: 1592054275:0;vim datasets/hans_processors.py
: 1592054799:0;git diff datasets/hans_dataset.py
: 1592054868:0;rm -r datasets
: 1592054920:0;mv reptile_glue.py .
: 1592054922:0;mv reptile_glue.py ..
: 1592054946:0;mv ../reptile_glue.py .
: 1592054965:0;mv nbs/reptile.py /home/nlp
: 1592205113:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list [mrpc, mnli, rte, qqp]
: 1592205135:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list=[mrpc, mnli, rte, qqp]
: 1592205430:0;vim ~
: 1592206173:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list=mrpc,mnli,rte,qqp
: 1592206203:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list=mrpc mnli rte qqp
: 1592208050:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR 
: 1592208115:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc mnli rte qqp
: 1592208762:0;which-command python3
: 1592208773:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_gpu_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592209657:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592210204:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592210644:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592215516:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592215691:0;CUDA_VISIBLE_DEVICES=1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592215833:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592216827:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592217437:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 32  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592217544:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,mnli,rte,qqp
: 1592217991:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp
: 1592220968:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200
: 1592221236:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=10
: 1592222573:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=10 --save_steps=10
: 1592224539:0;ls checkpoint-10
: 1592224558:0;ls ../experiments/meta/checkpoint-10
: 1592224582:0;rm -r ../experiments/meta/checkpoint-10
: 1592225299:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=10 --save_steps=200
: 1592225325:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=200
: 1592225407:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 48  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500
: 1592228389:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500
: 1592229296:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500
: 1592230918:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500 --fp16
: 1592231424:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 25.0   --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500 --fp16
: 1592231549:0;transformers-cli env
: 1592231968:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500 --fp16
: 1592232284:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500 --fp16 --num_train_epochs=3
: 1592232345:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500 --fp16 --num_train_epochs=3
: 1592232774:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2,rte,qqp --eval_steps=200 --save_steps=500 --num_train_epochs=3
: 1592234008:0;git add core/meta.py
: 1592234164:0;git commit -m "added Meta Trainer and meta learning script"
: 1592309967:0;rm -r hans/wandb
: 1592309985:0;r -r hans/__
: 1592310002:0;rm -r hans/__pycache__
: 1592312739:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=200 --save_steps=500 --num_train_epochs=3
: 1592313660:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=200 --save_steps=500 --num_train_epochs=3 --fp16
: 1592313712:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=200 --save_steps=500 --num_train_epochs=3 
: 1592314395:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=100 --num_train_epochs=3 --fp16 
: 1592315079:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=100 --num_train_epochs=3 --fp16 --fp16_opt_level O2
: 1592315524:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=100 --num_train_epochs=3
: 1592316504:0;rm -r ../experiments/meta/
: 1592316542:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=100 --num_train_epochs=20
: 1592316856:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=200 --num_train_epochs=20
: 1592380907:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=200 --num_train_epochs=25
: 1592380942:0;nvidia-smi -l 1 
: 1592388798:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=200 --num_train_epochs=25 --output_file_name results
: 1592394829:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=200 --num_train_epochs=25 --output_file_name results --fp16
: 1592395578:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=200 --num_train_epochs=25 --output_file_name results --fp16
: 1592396399:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=50 --save_steps=200 --num_train_epochs=25 --output_file_name results --fp16
: 1592396818:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=20 --save_steps=200 --num_train_epochs=25 --output_file_name results --fp16
: 1592397565:0;CUDA_VISIBLE_DEVICES=0,1 python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=20 --save_steps=200 --num_train_epochs=25 --output_file_name results 
: 1592398338:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=20 --save_steps=200 --num_train_epochs=25 --output_file_name results 
: 1592399764:0;python3 rui 
: 1592399765:0;sudo cd hans
: 1592400152:0;python3 run_hans.py --model_name_or_path albert-base-v2 --task_name hans --do_eval --data_dir=/home/nlp/data/hans --max_Seq_length 128 --per_device_eval_batch_size 32 --output_dir=/home/nlp/experiments/hans_test
: 1592400637:0;python3 run_hans.py --model_name_or_path albert-base-v2 --task_name hans --do_eval --data_dir=/home/nlp/data/hans --max_seq_length 128 --per_device_eval_batch_size 32 --output_dir=/home/nlp/experiments/hans_test --overwrite_cache
: 1592401221:0;cd ../data/hans
: 1592401615:0;cd ../../transformers
: 1592402381:0;git remote add upstream https://github.com/huggingface/transformers.git
: 1592402499:0;git branch hans_example
: 1592402670:0;cp transformers/examples/adversarial/README.md prajjwal1/transformers/examples/adversarial/README.md
: 1592402695:0;git checkout hans_example
: 1592402780:0;git add examples/adversarial/README.md
: 1592402792:0;git commit -m "updated hans eval instructions"
: 1592403000:0;cat examples/adversarial/README.md
: 1592403067:0;mv examples/adversarial/run_hans.py mv examples/adversarial/test_hans.py
: 1592403074:0;cd examples/adversarial
: 1592403087:0;mv run_hans.py test_hans.py
: 1592403123:0;git add examples/adversarial/test_hans.py
: 1592403144:0;git commit -m "renamed run_hans to test_hans"
: 1592403149:0;git push origin hans_example
: 1592403695:0;python3 run_hans.py --model_name_or_path albert-base-v2 --task_name hans --do_eval --data_dir=/home/nlp/data/hans --max_seq_length 128 --per_device_eval_batch_size 32 --output_dir=/home/nlp/experiments/hans_test
: 1592403853:0;ls ../../experiments/hans_test
: 1592404383:0;python3 run_hans.py --model_name_or_path albert-base-v2 --task_name hans --do_eval --data_dir=/home/nlp/data/hans --max_seq_length 128 --per_device_eval_batch_size 512 --output_dir=/home/nlp/experiments/hans_test
: 1592404465:0;python3 evaluate_heur_output.py ~/experiments/hans_test/hans_predictions.txt
: 1592405605:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=20 --save_steps=200 --num_train_epochs=25 --output_file_name results --fp16
: 1592406713:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --target_task mrpc --data_dir $GLUE_DIR --task_list mrpc,cola,sst-2 --eval_task_list rte,qqp --eval_steps=20 --save_steps=200 --num_train_epochs=25 --output_file_name results
: 1592407219:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --data_dir $GLUE_DIR --task_list qnli --eval_task_list wnli --eval_steps=20 --save_steps=200 --num_train_epochs=25 --output_file_name results_2
: 1592407926:0;python3 reptile_glue.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 64  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --data_dir $GLUE_DIR --task_list qnli --eval_task_list wnli --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name results_2
: 1592455364:0;rm -r ../experiments/meta/checkpoint*
: 1592455371:0;rm -r ../experiments/meta_2/checkpoint*
: 1592463445:0;vim coree/meta.py
: 1592466389:0;cp reptile_glue.py reptile_nli_few_shot.py
: 1592468245:0;vim reptile_nli_few_shot.py
: 1592468476:0;mv reptile_nli_few_shot.py reptile_few_shot.py
: 1592470557:0;cp core/meta.py core/meta_fs.py
: 1592475801:0;mv /home/nlp/data/hans /home/nlp/data/glue_data
: 1592477843:0;python3 eval
: 1592481306:0;mv meta_
: 1592481316:0;mv meta_2/results_2.csv meta
: 1592481323:0;mv meta
: 1592481343:0;mv results.csv bi-class_0.csv
: 1592481360:0;mv results_2.csv nli_0.csv
: 1592481820:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans
: 1592481907:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 
: 1592483121:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --overwrite_cache
: 1592483144:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 
: 1592483987:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 512 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1
: 1592484602:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1
: 1592484727:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1 --overwrite_cache
: 1592554069:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1 
: 1592554806:0;ls ../experiments/meta_@/
: 1592556452:0;head 
: 1592556465:0;tail
: 1592559262:0;rm -r ../../../experiments/meta_2/hans_predictions_*
: 1592559522:0;python3 evaluate_heur_output.py ~/experiments/meta_2/hans_predictions_4.txt
: 1592559858:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=200 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1 
: 1592560501:0;python3 evaluate_heur_output.py ~/experiments/meta_2/hans_predictions_2.txt
: 1592561866:0;cd ../../../experiments
: 1592561885:0;rm -r checkpoint-
: 1592562876:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1 
: 1592658054:0;pip install higher
: 1592659793:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768 --num_update_steps 1 --num_tasks 1
: 1592660154:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 32768*2 --num_update_steps 1 --num_tasks 1
: 1592706804:0;cd traansformers-importance-sampling
: 1592709086:0;cd experiments/meta_2
: 1592709153:0;python3 reptile_few_shot.py   --model_name_or_path albert-base-v2  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 131072 --num_update_steps 1 --num_tasks 1
: 1592711383:0;rm -r ../experiments/meta_2/
: 1592711841:0;cd meta_2
: 1592711847:0;mkdir meta_2
: 1592711858:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=25 --output_file_name mnli_hans --max_sample_limit 131072 --num_update_steps 1 --num_tasks 1
: 1592727482:0;rm core/.meta_fs.py.swp
: 1592727488:0;rm core/.meta_fs.py.swn
: 1592727492:0;rm core/.meta_fs.py.swo 
: 1592727528:0;rm core/.nfs000000003f9201b60000000b
: 1592727807:0;git reset core/.*
: 1592727816:0;git commit -m "BIG UPDATE: Working MetaLearing Traner for few shot, hans evaluation code"
: 1593085774:0;git clone https://github.com/prajjwal1/fluence
: 1593085943:0;pip install blackcellmagic
: 1593085978:0;pip install nbdev --upgrade
: 1593086092:0;pip install flake8 pycodestyle_magic
: 1593087567:0;sudo cd transformers-importance-sampling
: 1593087612:0;cp experiments/cls_embeddings_mnli.pth experiments/albert-base-v2-mnli
: 1593087632:0;cd experiments/albert-base-v2-mnli
: 1593087688:0;cd albert-base-v2-mnli
: 1593087698:0;rm eval_results_mnli.txt
: 1593087717:0;rm -rf wandb
: 1593087730:0;transformers-cli upload albert-base-v2-mnli
: 1593090987:0;pip install nb_black
: 1593091087:0;pip uninstall nb_black
: 1593091228:0;make docs_serve
: 1593091861:0;nbdev 
: 1593091889:0;nbdev_install_git_hooks
: 1593091949:0;nbdev_fix_merge
: 1593092587:0;nbdev_clean_nbs
: 1593092961:0;git commit -m "added importance sampling"
: 1593099086:0;vim make_lib.sh
: 1593099644:0;git commit -m "added better testing"
: 1593100206:0;git commit "fix nbdev_diff_nbs"
: 1593100421:0;mv nbs/* .
: 1593100425:0;nbdev_diff_nbs
: 1593101404:0;git pull master
: 1593101436:0;git branch new
: 1593101440:0;git checkout new
: 1593102413:0;rm -r fluence
: 1593102427:0;sh make_lib.sh
: 1593102558:0;git commit -m "fix nbdev_diff_nbs"
: 1593145234:0;rm -r docs
: 1593145249:0;cat settings.ini
: 1593145874:0;rm settings.ini
: 1593145899:0;rm requirements.txt
: 1593145958:0;mkdir ~/archive
: 1593145967:0;mv nbs ../archive
: 1593146004:0;rm _nbdev.py
: 1593146012:0;cd adaptive
: 1593146018:0;vim adaptive_span.py
: 1593146040:0;mv adaptive_span.py span.py
: 1593146044:0;vim span.py
: 1593146082:0;vim entmax.py
: 1593146246:0;vim layerdrop.py
: 1593146412:0;mkdir tests
: 1593149498:0;python3 test_adaptive.py
: 1593149607:0;vim fluence
: 1593150011:0;mv tests .
: 1593150013:0;mv tests ..
: 1593150257:0;black setup.py
: 1593150336:0;python3 tests/test_adaptive.py
: 1593150365:0;rm wandb
: 1593150394:0;cd build
: 1593150401:0;rm -r build
: 1593150413:0;rm Fluencels
: 1593150421:0;rm Fluence.egg-info
: 1593150427:0;rm -r Fluence.egg-info
: 1593150433:0;rm -r dist
: 1593150516:0;cd optim
: 1593150713:0;vim tests/test_adaptive.py
: 1593150977:0;python3 tests/test_optim.py
: 1593151184:0;cd sampling/
: 1593151260:0;rm make_lib.sh
: 1593152958:0;vim test_optim.py
: 1593153085:0;cd ../fluence/sampling/
: 1593153260:0;python3 tests/test_clustering.py
: 1593153855:0;python3 tests/test_clustering.py -v
: 1593154371:0;git commit -m "pure .py"
: 1593154654:0;vim hooks
: 1593154681:0;pip unsintall nbdev
: 1593154692:0;pip uninstall nbdev
: 1593154912:0;pip install pytest
: 1593156401:0;git commit -m "CI testing"
: 1593157302:0;mv cls_embeddings_mnli.pth cls_embeddings_mnli_1.pth
: 1593157381:0;pytest tests/test_clustering.py
: 1593157526:0;ls tests
: 1593157642:0;pytest tests/test_optim.py
: 1593158475:0;git commit -m "debugging actions"
: 1593159346:0;vim .isort.cfg
: 1593159361:0;rm .isort.cfg
: 1593159366:0;rm .pre-commit-config.yaml
: 1593160042:0;git commit -m "added badge"
: 1593161113:0;pip unsintalll isort
: 1593161120:0;pip uninstalll isort
: 1593161131:0;pip install git+git://github.com/timothycrosley/isort.git@e63ae06ec7d70b06df9e528357650281a3d3ec22#egg=isort
: 1593161514:0;pip uninstall isort
: 1593161524:0;pip install isort --upgrade
: 1593161735:0;git commit -m "remove isort"
: 1593162148:0;git commit -m "remove code quality check"
: 1593167662:0;mkdir meta
: 1593168004:0;vim test_meta_dataset.py
: 1593168622:0;git commit -m "added meta dataset"
: 1593169261:0;pytest --cov=./ --cov_report=xml tests/
: 1593169281:0;pytest --cov=tests --cov_report=xml 
: 1593169648:0;git branch -d meta
: 1593170563:0;git commit -m "added pypi action"
: 1593170904:0;git commit -m "fix classifier"
: 1593172318:0;vim fluence/sampling/clustering.py
: 1593172357:0;git branch meta
: 1593318220:0;ls data/glue_data/MRPC
: 1593318272:0;mkdir fluence/tests/fixtures/tests_samples/MRPC
: 1593318289:0;mkdir fixtures
: 1593318300:0;mkdir tests_samples
: 1593318834:0;mkdir MRPC
: 1593318896:0;cp data/glue_data/MRPC/dev.tsv fluence/tests/fixtures/tests_samples/MRPC
: 1593318905:0;cp data/glue_data/MRPC/train.tsv fluence/tests/fixtures/tests_samples/MRPC
: 1593319689:0;pytest test_meta.py
: 1593320090:0;git commit -m "added test for meta_dataset"
: 1593321516:0;git branch
: 1593328676:0;vim ../transformers-importance-sampling/reptile_few_shot.py
: 1593336774:0;mkdir examples
: 1593343019:0;python3 run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mrpc --eval_task_list sts-b --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name check
: 1593344112:0;python3 experiments/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mrpc --eval_task_list sts-b --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2
: 1593344807:0;vim run_maml_glue.py
: 1593344861:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mrpc --eval_task_list sts-b --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2
: 1593345496:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task sts-b --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2 --overwrite_cache
: 1593345555:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task sts-b --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2 --overwrite_cache True
: 1593345565:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task sts-b --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2 --overwrite_cache true
: 1593353583:0;lsmod | grep nvidia
: 1593408671:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task cola --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2
: 1593410030:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task sts-b --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2
: 1593410297:0;vim examples/run_maml_glue.py
: 1593411200:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/freeze/pretrained   --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train; done
: 1593411214:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/freeze/pretrained   --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/freeze/pretrained   --fp16 --freeze_base --tokenizer_name albert-base-v2 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train
: 1593413265:0;vim fluence/meta/__init__.py 
: 1593413499:0;vim fluence/meta/meta_args.py
: 1593416409:0;pytest tests/test_meta.py -vv
: 1593416499:0;pytest tests/test_meta.py 
: 1593416562:0;pytest tests/test_meta.py -v  --pdb
: 1593416686:0;python3 -m pytest tests/test_meta.py
: 1593416814:0;python3 -m pytest tests/test_meta.py -k test_meta_trainer
: 1593416902:0;python3 -m pytest tests/test_meta.py -k test_meta_trainer --pdb
: 1593416948:0;python3 -m pytest tests/test_meta.py -k test_meta_trainer --pdb -v
: 1593417829:0;cd tests/fixtures/tests_samples/MRPC
: 1593417854:0;cd tests_samples
: 1593417859:0;cd MRPC
: 1593417864:0;rm cached_dev_*
: 1593417891:0;vim .gitignore 
: 1593417971:0;pytest tests/test_meta.py -v -k test_meta_dataset --pdb
: 1593418123:0;git commit -m "added Meta Trainer"
: 1593418156:0;git branch -d new
: 1593418162:0;git branch -D new
: 1593418181:0;git checkout meta
: 1593418260:0;git checkout -b new 11b7c43
: 1593418304:0;git commit -m "added Meta Trainer, tests, example"
: 1593418424:0;git commit -m "added higher as dependency"
: 1593419425:0;vim .github/workflows/pip.yml
: 1593419494:0;git commit -m "added dev version of transformers in workflow"
: 1593419805:0;git commit -m "added pandas as a requirement"
: 1593420273:0;git commit -m "added wandb as a requirement"
: 1593421667:0;git add 
: 1593422298:0;git commit -m "made wandb optional"
: 1593431850:0;git commit -m "trigger action"
: 1593432811:0;pip unsinstall wandb
: 1593433090:0;git commit -m "epoch set in distributed sampler"
: 1593433535:0;python3 tests/test_meta.py
: 1593433783:0;python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task sst-2 --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2
: 1593434619:0;python3 setup.py install --user
: 1593434854:0;git commit -m removed wandb"
: 1593434858:0;git commit -m "removed wandb"
: 1593435104:0;git commit -m "removed tensorboard"
: 1593435874:0;echo 'python3 examples/run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --train_task mrpc --eval_task sst-2 --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2' > examples/README.md
: 1593435883:0;vim examples/README.md
: 1593435952:0;git commit -m "added usage instructions"
: 1593437345:0;git commit -m "fix tes_metat"
: 1593437356:0;git commit -m "fix test_meta"
: 1593438607:0;vim .github/workflows/codecov.yml
: 1593438975:0;ls .github/workflows
: 1593444515:0;pytest tests/test_clustering.py -vv
: 1593446180:0;pytest tests/test_meta.py
: 1593690376:0;make sty
: 1593691133:0;python3 run_glue.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 256 --linear_dim=4096 --freeze-a --freeze-b
: 1593691502:0;python3 run_glue.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --freeze-a --freeze-b --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 256
: 1593693544:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --freeze-a --freeze-b --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 256
: 1593693866:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --freeze-a --freeze-b --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 256 --freeze-a --freeze-b
: 1593693890:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --freeze-a --freeze-b --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 256 
: 1593694790:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 256 
: 1593695033:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 1536
: 1593696615:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 1536 --freeze-a --freeze-b
: 1593697298:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --input_dim 1536 --freeze_a --freeze_b
: 1593697333:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b
: 1593697645:0;python3 train_siamese.py   --model_name_or_path bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b
: 1593699149:0;ls ../experiments/meta_2/
: 1593699158:0;ls ../experiments/meta_2/checkpoint-130000
: 1593701849:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b
: 1593702297:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b --config_name bert-base-uncased --tokenizer-name bert-base-uncased
: 1593762412:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593763568:0;vim core/siamese_dataset.py
: 1593764280:0;vim train_siamese.py ls
: 1593765014:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b --config_name bert-base-uncased --tokenizer_name bert-base-uncased --overwrite_cache
: 1593765021:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b --config_name bert-base-uncased --tokenizer_name bert-base-uncased 
: 1593773563:0;git commit -m "fix added siamese network"
: 1593787026:0;vim core/siamese_model.py
: 1593787117:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593788796:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 1536 --freeze_a --freeze_b --config_name bert-base-uncased --tokenizer_name bert-base-uncased --load_model_path /home/nlp/experiments/siamese
: 1593851079:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 196608 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593851198:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 196608 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593851251:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 196608 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593852996:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593853044:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593855705:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593855800:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593855952:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593939799:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --max_seq_len=32
: 1593939940:0;pip install wandb --upgrade
: 1593940023:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593940087:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 768  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 768 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1593950724:0;git commit -m "restructured code"
: 1594031802:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --load_model_path /home/nlp/experiments/siamese
: 1594033072:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594034302:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16
: 1594034548:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --overwrite-cache
: 1594034830:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --overwrite_cache
: 1594040013:0;python3 install .
: 1594040031:0;python3 install setup.py 
: 1594042717:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 
: 1594042939:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --load_model_path /home/nlp/experiments/siamese
: 1594043140:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 2.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --load_model_path /home/nlp/experiments/siamese
: 1594043652:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 5.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594044179:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 5.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594047548:0;git adddd .
: 1594047568:0;git commit -m "progress"
: 1594048774:0;echo 'python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 32   --per_device_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 5.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training' >> README.md
: 1594048942:0;flake8 .
: 1594104574:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 2.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594106738:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training --learning_rate=0.0001
: 1594109396:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594216349:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training 
: 1594218761:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training --overwrite_cache
: 1594218891:0;cd ../transformers
: 1594220460:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 512 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594220828:0;nvi
: 1594263609:0;rm -r 4dad*
: 1594263615:0;rm -r checkpoint*
: 1594264627:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 5.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594269754:0;rm -r ../experiments/siamese/*
: 1594269783:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training
: 1594271007:0;cd ../../experiments/siamese
: 1594271048:0;cp pytorch_model.bin epoch_1
: 1594271063:0;cp *.json epoch_1
: 1594271072:0;cp *.txt epoch_1
: 1594271098:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --evaluate_during_training --load_model_path ~/experiments/siamese/
: 1594272381:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --load_model_path ~/experiments/siamese/
: 1594274242:0;cp *.json epoch_3
: 1594274253:0;cp pytorch_model.bin epoch_3
: 1594274295:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --load_model_path ~/experiments/siamese/epoch_1/
: 1594276296:0;mkdir epoch_2
: 1594276302:0;cp pytorch_model.bin epoch_2
: 1594276312:0;cp *.json epoch_2
: 1594276327:0;cp *.txt epoch_3
: 1594276335:0;cp *.txt epoch_2
: 1594276352:0;python3 train_siamese.py   --model_name bert-base-uncased   --linear_dim=4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese   --overwrite_output_dir --per_device_eval_batch_size 256 --do_train --input_dim 12 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --fp16 --load_model_path ~/experiments/siamese/epoch_3/
: 1594276859:0;cd ../../transformers-importance-sampling
: 1594276878:0;cp run_hans.py run_siamese_hans.py
: 1594278782:0;ls ../../data/glue_data/hans
: 1594280658:0;python3 run_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans
: 1594281057:0;flake8 hans/run_siamese_hans.py
: 1594281394:0;python3 run_siamese_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_1
: 1594281626:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_1
: 1594281747:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_1 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594281795:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_1 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --overwrite_cache
: 1594282069:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_1 --config_name bert-base-uncased --tokenizer_name bert-base-uncased 
: 1594283314:0;python3 run_siamese_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_2
: 1594283348:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_1 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594283371:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_2 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594283542:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_3 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594283823:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_4 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594283953:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594284674:0;cd ../experiments/siamese
: 1594284679:0;mkdir epoch_0
: 1594284713:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --load_model_path=/home/nlp/experiments/siamese/epoch_0 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1594284725:0;mkdir epoch_4
: 1594284742:0;cp *.txt epoch_4
: 1594284749:0;cp *.bin epoch_4
: 1594284756:0;cp *.json epoch_4
: 1594284860:0;python3 evaluate_heur_output.py ~/experiments/siamese/hans/hans_predictions.txt
: 1594376659:0;cp transformers-importance-sampling/datasets/siamese_dataset.py fluence/fluence
: 1594376677:0;cp transformers-importance-sampling/models/siamese_model.py fluence/fluence
: 1594376698:0;mkdir datasets
: 1594376706:0;cp siamese_model.py models
: 1594376718:0;cp siamese_dataset.py datasets
: 1594376765:0;cd ../models
: 1594376800:0;python3 setup.py .
: 1594378446:0;cd ../fluence/
: 1594378484:0;rm utils
: 1594378598:0;mkdir utils
: 1594378758:0;cd ../tests
: 1594380471:0;vim ../fluence/utils/siamese_utils.py
: 1594380609:0;vim fluence/datasets/siamese_dataset.py
: 1594380646:0;vim fluence/datasets/__init__.py
: 1594385249:0;git commit -m "added siamese transformer support"
: 1594386301:0;git commit -m "rm files, set overwrite_cache=True"
: 1594386450:0;git rm -r --cached runs
: 1594386477:0;git commit -m "removed tfevents files"
: 1594387789:0;git commit -m "set overwrite_cache=True"
: 1594448168:0;cd modeels
: 1594449609:0;mkdir docs
: 1594450283:0;git commit -m "code clean up; logo design"
: 1594472435:0;git commit -m "README redesign"
: 1594474812:0;git commit -m "README writeup"
: 1594485933:0;cp ~/.vimrc dotfiles/vimrc
: 1594485955:0;git commit -m "vimrc changes"
: 1594534986:0;ctags
: 1594539443:0;cd dotfiles
: 1594539459:0;cp vimrc ~/.vimrc
: 1594539467:0;vim +PluginInstall +qall
: 1594706022:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1594706094:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 2048  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/small   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1594706138:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 2048  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/small   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train --overwrite_cache
: 1594707314:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_gpu_train_batch_size 1024  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/small   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1594707520:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 512  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/small   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1594710506:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 512  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/small   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --overwrite_cache
: 1594710549:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/small --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 512  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/small   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --overwrite_cache --tokenizer_name bert-base-uncased
: 1594710686:0;python3 run_glue.py   --model_name_or_path bery-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 512  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512
: 1594710703:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 512  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512
: 1594711090:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 512  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train
: 1594711305:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 256  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 512 --do_train
: 1594711315:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --per_device_eval_batch_size 256  --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train
: 1594714587:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1594798329:0;rm cls_embeddings_mnli.pth
: 1594798333:0;rm pytorch_model.bin
: 1594798337:0;rm config.json
: 1594815256:0;vim siamese_trainer.py
: 1595139115:0;rm -r 10_pct_v2
: 1595139122:0;rm -r 20_pct_v2
: 1595139127:0;rm -r 30_pct_v2
: 1595139131:0;rm -r 40_pct_v2
: 1595139135:0;rm -r 50_pct_v2
: 1595139139:0;rm -r 60_pct_v2
: 1595139144:0;rm -r 70_pct_v2
: 1595139148:0;rm -r 80_pct_v2
: 1595139155:0;rm -r 90_pct_v2
: 1595139164:0;rm -r 512_random_samples
: 1595139174:0;rm -r seed_*
: 1595139327:0;ls cluster
: 1595139331:0;ls clustering
: 1595139344:0;rm -r random_sampling
: 1595139353:0;rm -r freeze
: 1595139413:0;ls hans
: 1595139416:0;rm -r hans
: 1595139425:0;rm -r cluster_labels.npy
: 1595139428:0;rm -r cluster_output.pth
: 1595139440:0;rm -r cls_embeddings_mnli_1.pth
: 1595139811:0;python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/ --overwrite_cache
: 1595142848:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/10_pct   --fp16 --data_pct 0.1
: 1595143604:0;python3 subsampling_mnli.py   --model_name_or_path /home/nlp/experiments/10_pct --tokenizer_name bert-base-uncased  --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/10_pct   --fp16 --data_pct 0.1
: 1595143848:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/20_pct   --fp16 --data_pct 0.2
: 1595143897:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/20_pct   --fp16 --data_pct 0.2
: 1595144417:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/30_pct   --fp16 --data_pct 0.3
: 1595145070:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/40_pct   --fp16 --data_pct 0.4
: 1595146085:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/50_pct   --fp16 --data_pct 0.5
: 1595146931:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/60_pct   --fp16 --data_pct 0.6
: 1595147929:0;echo "python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train  --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/60_pct   --fp16 --data_pct 0.6" >> run_sh.sh
: 1595147933:0;vim run_sh.sh
: 1595148234:0;sh run_sh.sh
: 1595150773:0;cp run_sh.sh run_seeds.sh
: 1595151848:0;sleep 2s & ls
: 1595151855:0;sleep 5s & ls
: 1595151863:0;sleep 5s && ls
: 1595151892:0;sleep 30s && sh run_seeds.sh
: 1595212955:0;ls *500
: 1595212961:0;grep 500
: 1595212967:0;grep *500
: 1595213060:0;ls experiments/0.5_pct_500
: 1595213068:0;ls experiments/0.4_pct_500
: 1595213079:0;cat experiments/0.4_pct_500/eval_results_mnli.txt
: 1595213306:0;ls 90_pct
: 1595213418:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/90_pct   --fp16 --data_pct 0.9 --overwrite_output_dir
: 1595213504:0;python3 subsampling_mnli.py   --model_name_or_path ~/experiments/90_pct --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/90_pct   --fp16 --data_pct 0.9 --overwrite_output_dir
: 1595213643:0;ls 70_pct/eval_results_mnli.txt
: 1595213649:0;cat 70_pct/eval_results_mnli.txt
: 1595213664:0;cat 70_pct/eval_results_mnli-mm.txt
: 1595213676:0;cat 80_pct/eval_results_mnli.txt
: 1595213687:0;cat 80_pct/eval_results_mnli-mm.txt
: 1595213699:0;cat 90_pct/eval_results_mnli.txt
: 1595213734:0;cat 90_pct/eval_results_mnli-mm.txt
: 1595213878:0;cat big_small/small/eval_results_mnli.txt
: 1595213886:0;cat big_small/small/eval_results_mnli-mm.txt
: 1595214256:0;sh run_seeds.sh
: 1595214369:0;cat 0.1_pct_0/eval_results_mnli.txt
: 1595214424:0;cat 0.1_pct_0/eval_results_mnli-mm.txt
: 1595214439:0;cat 0.2_pct_0/eval_results_mnli-mm.txt
: 1595214456:0;cat 0.2_pct_0/eval_results_mnli.txt
: 1595214469:0;cat 0.3_pct_0/eval_results_mnli.txt
: 1595214482:0;cat 0.3_pct_0/eval_results_mnli-mm.txt
: 1595214536:0;cat 0.4_pct_0/eval_results_mnli.txt
: 1595214547:0;cat 0.4_pct_0/eval_results_mnli-mm.txt
: 1595214559:0;cat 0.5_pct_0/eval_results_mnli.txt
: 1595214575:0;cat 0.5_pct_0/eval_results_mnli-mm.txt
: 1595214593:0;cat 0.6_pct_0/eval_results_mnli.txt
: 1595214603:0;cat 0.6_pct_0/eval_results_mnli-mm.txt
: 1595214614:0;cat 0.7_pct_0/eval_results_mnli.txt
: 1595214623:0;cat 0.7_pct_0/eval_results_mnli-mm.txt
: 1595214634:0;cat 0.8_pct_0/eval_results_mnli.txt
: 1595214642:0;cat 0.8_pct_0/eval_results_mnli-mm.txt
: 1595214653:0;cat 0.9_pct_0/eval_results_mnli.txt
: 1595214664:0;cat 0.9_pct_0/eval_results_mnli-mm.txt
: 1595214678:0;cat 1.0_pct_0/eval_results_mnli-mm.txt
: 1595214687:0;cat 1.0_pct_0/eval_results_mnli.txt
: 1595214927:0;cat 0.1_pct_250/eval_results_mnli.txt
: 1595214939:0;cat 0.1_pct_250/eval_results_mnli-mm.txt
: 1595214953:0;cat 0.2_pct_250/eval_results_mnli.txt
: 1595214966:0;cat 0.2_pct_250/eval_results_mnli-mm.txt
: 1595214978:0;cat 0.3_pct_250/eval_results_mnli.txt
: 1595214989:0;cat 0.3_pct_250/eval_results_mnli-mm.txt
: 1595215000:0;cat 0.4_pct_250/eval_results_mnli.txt
: 1595215008:0;cat 0.4_pct_250/eval_results_mnli-mm.txt
: 1595215021:0;cat 0.5_pct_250/eval_results_mnli.txt
: 1595215029:0;cat 0.5_pct_250/eval_results_mnli-mm.txt
: 1595215040:0;cat 0.6_pct_250/eval_results_mnli.txt
: 1595215049:0;cat 0.6_pct_250/eval_results_mnli-mm.txt
: 1595215060:0;cat 0.7_pct_250/eval_results_mnli.txt
: 1595215068:0;cat 0.7_pct_250/eval_results_mnli-mm.txt
: 1595215079:0;cat 0.8_pct_250/eval_results_mnli.txt
: 1595215089:0;cat 0.8_pct_250/eval_results_mnli-mm.txt
: 1595215099:0;cat 0.9_pct_250/eval_results_mnli.txt
: 1595215108:0;cat 0.9_pct_250/eval_results_mnli-mm.txt
: 1595215119:0;cat 1.0_pct_250/eval_results_mnli.txt
: 1595215132:0;cat 1.0_pct_250/eval_results_mnli-mm.txt
: 1595227954:0;cat 0.1_pct_500/eval_results_mnli.txt
: 1595227978:0;cat 0.1_pct_500/eval_results_mnli-mm.txt
: 1595227996:0;cat 0.2_pct_500/eval_results_mnli.txt
: 1595228008:0;cat 0.2_pct_500/eval_results_mnli-mm.txt
: 1595228025:0;cat 0.3_pct_500/eval_results_mnli.txt
: 1595228055:0;cat 0.3_pct_500/eval_results_mnli-mm.txt
: 1595228066:0;cat 0.4_pct_500/eval_results_mnli.txt
: 1595228075:0;cat 0.4_pct_500/eval_results_mnli-mm.txt
: 1595228084:0;cat 0.5_pct_500/eval_results_mnli.txt
: 1595228093:0;cat 0.5_pct_500/eval_results_mnli-mm.txt
: 1595228153:0;cat 0.6_pct_500/eval_results_mnli.txt
: 1595228162:0;cat 0.6_pct_500/eval_results_mnli-mm.txt
: 1595228175:0;cat 0.7_pct_500/eval_results_mnli.txt
: 1595228186:0;cat 0.7_pct_500/eval_results_mnli-mm.txt
: 1595228195:0;cat 0.8_pct_500/eval_results_mnli.txt
: 1595228207:0;cat 0.8_pct_500/eval_results_mnli-mm.txt
: 1595228217:0;cat 0.9_pct_500/eval_results_mnli.txt
: 1595228227:0;cat 0.9_pct_500/eval_results_mnli-mm.txt
: 1595228237:0;cat 1.0_pct_500/eval_results_mnli.txt
: 1595228250:0;cat 1.0_pct_500/eval_results_mnli-mm.txt
: 1595229952:0;cat 0.1_pct_750/eval_results_mnli.txt
: 1595230070:0;cat 0.1_pct_750/eval_results_mnli-mm.txt
: 1595230087:0;cat 0.2_pct_750/eval_results_mnli.txt
: 1595230100:0;cat 0.2_pct_750/eval_results_mnli-mm.txt
: 1595230111:0;cat 0.3_pct_750/eval_results_mnli.txt
: 1595230118:0;cat 0.3_pct_750/eval_results_mnli-mm.txt
: 1595230127:0;cat 0.4_pct_750/eval_results_mnli.txt
: 1595230135:0;cat 0.4_pct_750/eval_results_mnli-mm.txt
: 1595230145:0;cat 0.5_pct_750/eval_results_mnli.txt
: 1595230154:0;cat 0.5_pct_750/eval_results_mnli-mm.txt
: 1595230163:0;cat 0.6_pct_750/eval_results_mnli.txt
: 1595230247:0;cat 0.6_pct_750/eval_results_mnli-mm.txt
: 1595230270:0;cat 0.7_pct_750/eval_results_mnli.txt
: 1595230278:0;cat 0.7_pct_750/eval_results_mnli-mm.txt
: 1595230292:0;cat 0.8_pct_750/eval_results_mnli.txt
: 1595230301:0;cat 0.8_pct_750/eval_results_mnli-mm.txt
: 1595230313:0;cat 0.9_pct_750/eval_results_mnli.txt
: 1595230321:0;cat 0.9_pct_750/eval_results_mnli-mm.txt
: 1595230333:0;cat 1.0_pct_750/eval_results_mnli.txt
: 1595230491:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/1.0_pct_750   --fp16 --data_pct 1.0 --overwrite_output_dir -seed 750
: 1595230498:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/1.0_pct_750   --fp16 --data_pct 1.0 --overwrite_output_dir --seed 750
: 1595230576:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/1.0_pct_750   --fp16 --data_pct 1.0 --overwrite_output_dir --seed 750 --do_train
: 1595233206:0;ls ../experiments
: 1595233231:0;ls ../experiments/*0
: 1595233285:0;echo "python3 run_hans.py--model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans" >> run_hans.sh
: 1595233504:0;ls experiments/
: 1595233623:0;python3 run_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/siamese/hans --overwrite_cache
: 1595235738:0;vim hans/run_hans.sh
: 1595236470:0;ls ../../experiments/10_pct
: 1595236481:0;ls ../../experiments/10_pct_0
: 1595236504:0;ls ../../experiments/20_pct_0
: 1595236576:0;ls 10_pct_0
: 1595236582:0;rm 10_pct_0
: 1595236587:0;rm -rf 10_pct_0
: 1595236706:0;ls ../experiments/10_pct
: 1595236789:0;python3 run_hans.py --model_name_or_path ber --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 256 --output_dir=/home/nlp/experiments/10_pct
: 1595236799:0;python3 evaluate_heur_output.py ~/experiments/siamese/20_pct/hans_predictions.txt
: 1595236933:0;cd ../../exp
: 1595236936:0;cd ../../experiments
: 1595236991:0;ls 0.1_pct_0
: 1595237011:0;python3 evaluate_heur_output.py ~/experiments/siamese/10_pct/hans_predictions.txt
: 1595237018:0;python3 evaluate_heur_output.py ~/experiments/10_pct/hans_predictions.txt
: 1595237181:0;python3 evaluate_heur_output.py ~/experiments/20_pct/hans_predictions.txt
: 1595237228:0;python3 evaluate_heur_output.py ~/experiments/30_pct/hans_predictions.txt
: 1595237263:0;python3 evaluate_heur_output.py ~/experiments/40_pct/hans_predictions.txt
: 1595237309:0;python3 evaluate_heur_output.py ~/experiments/50_pct/hans_predictions.txt
: 1595237421:0;python3 evaluate_heur_output.py ~/experiments/60_pct/hans_predictions.txt
: 1595239088:0;python3 evaluate_heur_output.py ~/experiments/70_pct/hans_predictions.txt
: 1595239194:0;python3 evaluate_heur_output.py ~/experiments/80_pct/hans_predictions.txt
: 1595239241:0;python3 evaluate_heur_output.py ~/experiments/90_pct/hans_predictions.txt
: 1595239336:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/small --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/big_small/small
: 1595239396:0;python3 evaluate_heur_output.py ~/experiments/big_small/small/hans_predictions.txt
: 1595239522:0;python3 evaluate_heur_output.py ~/experiments/0.1_pct_0/hans_predictions.txt
: 1595239562:0;python3 evaluate_heur_output.py ~/experiments/0.2_pct_0/hans_predictions.txt
: 1595239988:0;python3 evaluate_heur_output.py ~/experiments/0.3_pct_0/hans_predictions.txt
: 1595240035:0;python3 evaluate_heur_output.py ~/experiments/0.4_pct_0/hans_predictions.txt
: 1595240087:0;python3 evaluate_heur_output.py ~/experiments/0.5_pct_0/hans_predictions.txt
: 1595240129:0;python3 evaluate_heur_output.py ~/experiments/0.6_pct_0/hans_predictions.txt
: 1595240177:0;python3 evaluate_heur_output.py ~/experiments/0.7_pct_0/hans_predictions.txt
: 1595240239:0;python3 evaluate_heur_output.py ~/experiments/0.8_pct_0/hans_predictions.txt
: 1595240280:0;python3 evaluate_heur_output.py ~/experiments/0.9_pct_0/hans_predictions.txt
: 1595240324:0;python3 evaluate_heur_output.py ~/experiments/1.0_pct_0/hans_predictions.txt
: 1595240744:0;python3 evaluate_heur_output.py ~/experiments/0.1_pct_250/hans_predictions.txt
: 1595240828:0;python3 evaluate_heur_output.py ~/experiments/0.2_pct_250/hans_predictions.txt
: 1595240871:0;python3 evaluate_heur_output.py ~/experiments/0.3_pct_250/hans_predictions.txt
: 1595240908:0;python3 evaluate_heur_output.py ~/experiments/0.4_pct_250/hans_predictions.txt
: 1595240958:0;python3 evaluate_heur_output.py ~/experiments/0.5_pct_250/hans_predictions.txt
: 1595241044:0;python3 evaluate_heur_output.py ~/experiments/0.6_pct_250/hans_predictions.txt
: 1595241081:0;python3 evaluate_heur_output.py ~/experiments/0.7_pct_250/hans_predictions.txt
: 1595241127:0;python3 evaluate_heur_output.py ~/experiments/0.8_pct_250/hans_predictions.txt
: 1595241271:0;python3 evaluate_heur_output.py ~/experiments/0.9_pct_250/hans_predictions.txt
: 1595241470:0;python3 evaluate_heur_output.py ~/experiments/1.0_pct_250/hans_predictions.txt
: 1595241512:0;python3 evaluate_heur_output.py ~/experiments/0.1_pct_500/hans_predictions.txt
: 1595241601:0;python3 evaluate_heur_output.py ~/experiments/0.2_pct_500/hans_predictions.txt
: 1595241658:0;python3 evaluate_heur_output.py ~/experiments/0.3_pct_500/hans_predictions.txt
: 1595241692:0;python3 evaluate_heur_output.py ~/experiments/0.4_pct_500/hans_predictions.txt
: 1595241748:0;python3 evaluate_heur_output.py ~/experiments/0.5_pct_500/hans_predictions.txt
: 1595241845:0;python3 evaluate_heur_output.py ~/experiments/0.6_pct_500/hans_predictions.txt
: 1595241879:0;python3 evaluate_heur_output.py ~/experiments/0.7_pct_500/hans_predictions.txt
: 1595241918:0;python3 evaluate_heur_output.py ~/experiments/0.8_pct_500/hans_predictions.txt
: 1595241957:0;python3 evaluate_heur_output.py ~/experiments/0.9_pct_500/hans_predictions.txt
: 1595241990:0;python3 evaluate_heur_output.py ~/experiments/1.0_pct_500/hans_predictions.txt
: 1595242677:0;python3 evaluate_heur_output.py ~/experiments/0.1_pct_750/hans_predictions.txt
: 1595242792:0;python3 evaluate_heur_output.py ~/experiments/0.2_pct_750/hans_predictions.txt
: 1595242831:0;python3 evaluate_heur_output.py ~/experiments/0.3_pct_750/hans_predictions.txt
: 1595242866:0;python3 evaluate_heur_output.py ~/experiments/0.4_pct_750/hans_predictions.txt
: 1595242903:0;python3 evaluate_heur_output.py ~/experiments/0.5_pct_750/hans_predictions.txt
: 1595242935:0;python3 evaluate_heur_output.py ~/experiments/0.6_pct_750/hans_predictions.txt
: 1595242969:0;python3 evaluate_heur_output.py ~/experiments/0.7_pct_750/hans_predictions.txt
: 1595243007:0;python3 evaluate_heur_output.py ~/experiments/0.8_pct_750/hans_predictions.txt
: 1595243040:0;python3 evaluate_heur_output.py ~/experiments/0.9_pct_750/hans_predictions.txt
: 1595243076:0;python3 evaluate_heur_output.py ~/experiments/1.0_pct_750/hans_predictions.txt
: 1595246352:0;vim get_embeddings.py
: 1595246386:0;python3 get
: 1595246404:0;rm ../experiments/cls_embeddings_mnli.pth
: 1595246414:0;python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/
: 1595247690:0;rm -r clustering
: 1595247856:0;ls ../experiments/
: 1595247867:0;python3 train_clustering.py   --model_name_or_path bert-bcase-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --eps 0.2 --min_samples 50 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.2 --cluster_output_path /home/nlp/experiments/cluster_output.pth
: 1595247908:0;python3 train_clustering.py   --model_name_or_path bert-bcase-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.2 --cluster_output_path /home/nlp/experiments/cluster_output.pth
: 1595247942:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.2 --cluster_output_path /home/nlp/experiments/cluster_output.pth
: 1595248351:0;echo
: 1595248371:0;echo "python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.2 --cluster_input_path /home/nlp/experiments/cluster_output.pth" << README.md
: 1595248400:0;echo "python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.2 --cluster_input_path /home/nlp/experiments/cluster_output.pth" >> README.md
: 1595248419:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.2 --cluster_input_path /home/nlp/experiments/cluster_output.pth
: 1595248834:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth
: 1595248919:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir
: 1595251202:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering_2_pct --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/clustering/2_pct
: 1595251642:0;ls ../experiments/clustering
: 1595251670:0;for epoch in 1 2 3 4 5 6 7 8 9 10 11 12 13 14; do python3 train_clustering.py   --model_name_or_path /home/experiments/clustering/"2_pct_"$epoch"_epoch"   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/"2_pct_"$1"_epoch"   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir; done
: 1595251824:0;ls ../experiments/clustering/2_pct_1_epoch
: 1595251913:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_1_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir
: 1595252031:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_1_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512
: 1595252168:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_1_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_2_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512
: 1595252208:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_1_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_2_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252330:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_1_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/"2_pct_3_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252365:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_2_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_3_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252449:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_3_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_4_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252543:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_4_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_5_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252628:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_5_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_6_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252712:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_6_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_7_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252798:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_7_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_8_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252883:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_8_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_9_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595252967:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_9_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_10_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595253388:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_10_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_11_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595253488:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_11_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_12_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595253574:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_12_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_13_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595254524:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_13_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_14_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595254629:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_14_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_15_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595254771:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_15_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_16_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595254849:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_16_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_17_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595255078:0;vim run_seeds.sh
: 1595255347:0;cat 2_pct_1_epoch/eval_results_mnli.txt
: 1595255387:0;cat 2_pct_1_epoch/eval_results_mnli-mm.txt
: 1595255408:0;cat 2_pct_2_epoch/eval_results_mnli.txt
: 1595255418:0;cat 2_pct_2_epoch/eval_results_mnli-mm.txt
: 1595255426:0;cat 2_pct_3_epoch/eval_results_mnli.txt
: 1595255434:0;cat 2_pct_3_epoch/eval_results_mnli-mm.txt
: 1595255443:0;cat 2_pct_4_epoch/eval_results_mnli.txt
: 1595255451:0;cat 2_pct_4_epoch/eval_results_mnli-mm.txt
: 1595255467:0;cat 2_pct_5_epoch/eval_results_mnli.txt
: 1595255492:0;cat 2_pct_5_epoch/eval_results_mnli-mm.txt
: 1595255502:0;cat 2_pct_6_epoch/eval_results_mnli.txt
: 1595255512:0;cat 2_pct_6_epoch/eval_results_mnli-mm.txt
: 1595255522:0;cat 2_pct_7_epoch/eval_results_mnli.txt
: 1595255530:0;cat 2_pct_7_epoch/eval_results_mnli-mm.txt
: 1595255544:0;cat 2_pct_8_epoch/eval_results_mnli.txt
: 1595255554:0;cat 2_pct_8_epoch/eval_results_mnli-mm.txt
: 1595255567:0;cat 2_pct_9_epoch/eval_results_mnli.txt
: 1595255576:0;cat 2_pct_9_epoch/eval_results_mnli-mm.txt
: 1595255588:0;cat 2_pct_10_epoch/eval_results_mnli.txt
: 1595255598:0;cat 2_pct_10_epoch/eval_results_mnli-mm.txt
: 1595255608:0;cat 2_pct_11_epoch/eval_results_mnli.txt
: 1595255618:0;cat 2_pct_11_epoch/eval_results_mnli-mm.txt
: 1595255634:0;cat 2_pct_12_epoch/eval_results_mnli.txt
: 1595255643:0;cat 2_pct_12_epoch/eval_results_mnli-mm.txt
: 1595255656:0;cat 2_pct_13_epoch/eval_results_mnli.txt
: 1595255666:0;cat 2_pct_13_epoch/eval_results_mnli-mm.txt
: 1595255676:0;cat 2_pct_14_epoch/eval_results_mnli.txt
: 1595255684:0;cat 2_pct_14_epoch/eval_results_mnli-mm.txt
: 1595255692:0;cat 2_pct_15_epoch/eval_results_mnli.txt
: 1595255700:0;cat 2_pct_15_epoch/eval_results_mnli-mm.txt
: 1595255709:0;cat 2_pct_16_epoch/eval_results_mnli.txt
: 1595255716:0;cat 2_pct_16_epoch/eval_results_mnli-mm.txt
: 1595255725:0;cat 2_pct_17_epoch/eval_results_mnli.txt
: 1595255733:0;cat 2_pct_17_epoch/eval_results_mnli-mm.txt
: 1595255741:0;cat 2_pct_18_epoch/eval_results_mnli.txt
: 1595255749:0;cat 2_pct_18_epoch/eval_results_mnli-mm.txt
: 1595255894:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_0_epoch/hans_predictions.txt
: 1595255902:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_1_epoch/hans_predictions.txt
: 1595255937:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_2_epoch/hans_predictions.txt
: 1595255987:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_3_epoch/hans_predictions.txt
: 1595256031:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_4_epoch/hans_predictions.txt
: 1595256080:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_5_epoch/hans_predictions.txt
: 1595256123:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_6_epoch/hans_predictions.txt
: 1595256163:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_7_epoch/hans_predictions.txt
: 1595256200:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_8_epoch/hans_predictions.txt
: 1595256257:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_9_epoch/hans_predictions.txt
: 1595256305:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_10_epoch/hans_predictions.txt
: 1595256346:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_11_epoch/hans_predictions.txt
: 1595256383:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_12_epoch/hans_predictions.txt
: 1595256418:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_13_epoch/hans_predictions.txt
: 1595256471:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_14_epoch/hans_predictions.txt
: 1595256503:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_15_epoch/hans_predictions.txt
: 1595256540:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_16_epoch/hans_predictions.txt
: 1595256581:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_17_epoch/hans_predictions.txt
: 1595256620:0;python3 evaluate_heur_output.py ~/experiments/clustering/2_pct_18_epoch/hans_predictions.txt
: 1595257275:0;cd ../experiments/clustering
: 1595257286:0;rm -r 2_pct
: 1595257288:0;mkdir 2_pct
: 1595257292:0;mv * 2_pct
: 1595257923:0;cd 2_pct
: 1595258342:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_1   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_elements 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595258473:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct_17_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_18_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595258509:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/2_pct/2_pct_17_epoch   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/2_pct_18_epoch   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --data_pct 0.02 --cluster_input_path /home/nlp/experiments/cluster_output.pth --overwrite_output_dir --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595258787:0;for epoch in 2 3 4 5 6 7 8 9 10; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/16_clusters/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/"epoch_"$((epoch+1))   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_elements 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased; done
: 1595258818:0;for epoch in 1 2 3 4 5 6 7 8 9 10; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/16_clusters/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/"epoch_"$((epoch+1))   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_elements 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased; done
: 1595258889:0;ls ../experiments/clustering/16_clusters/epoch_1
: 1595259070:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_1   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_2   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595259666:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_2   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_3   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595259855:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_3   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_4   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595260021:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_4   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_5   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595260128:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_5   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_6   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --tokenizer_name bert-base-uncased
: 1595260245:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_6   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_7   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595260346:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_7   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_8   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595260440:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_8   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_9   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595260605:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_9   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_10   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595260702:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_10   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_11   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595260806:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_11   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_12   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595261001:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_12   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_13   --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595261115:0;python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/16_clusters/epoch_13   --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/16_clusters/epoch_14  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --num_clusters_element 16 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595300682:0;cd 16_clusters
: 1595300778:0;ls epoch_1
: 1595301215:0;cat epoch_12/eval_results_mnli-mm.txt
: 1595301233:0;cat epoch_13/eval_results_mnli-mm.txt
: 1595301245:0;cat epoch_14/eval_results_mnli.txt
: 1595301253:0;cat epoch_14/eval_results_mnli-mm.txt
: 1595301263:0;cat epoch_15/eval_results_mnli.txt
: 1595301500:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_1/hans_predictions.txt
: 1595301546:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_2/hans_predictions.txt
: 1595301582:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_3/hans_predictions.txt
: 1595301630:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_4/hans_predictions.txt
: 1595301715:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_5/hans_predictions.txt
: 1595301803:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_6/hans_predictions.txt
: 1595302313:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_7/hans_predictions.txt
: 1595302408:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_8/hans_predictions.txt
: 1595302453:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_9/hans_predictions.txt
: 1595302493:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_10/hans_predictions.txt
: 1595302647:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_11/hans_predictions.txt
: 1595302690:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_12/hans_predictions.txt
: 1595302730:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_13/hans_predictions.txt
: 1595302765:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_14/hans_predictions.txt
: 1595303455:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/epoch_14  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroids_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595303474:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/epoch_14  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --use_centroids_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595303509:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/epoch_14  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595303538:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/epoch_1  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1595303907:0;for epoch in 1 2 3 4 5 6 7 8 9 10; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/"epoch_"{{$epoch+1}}  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased; done
: 1595304015:0;for epoch in 1 2 3 4 5 6 7 8 9 10; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/"epoch_"${{++epoch}}  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased; done
: 1595305454:0;l4s ..
: 1595305475:0;for epoch in 1 2 3 4 5 6 7 8 9 10; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/"epoch_"$((++epoch))  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased; done
: 1595306018:0;for epoch in 11 12 13 14 15 16 17 18; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/"epoch_"$((++epoch))  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased; done
: 1595306491:0;for epoch in 19 20 21 22 23 25 25; do python3 train_clustering.py   --model_name_or_path /home/nlp/experiments/clustering/centroids/"epoch_"$epoch  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/centroids/"epoch_"$((++epoch))  --fp16 --embedding_path /home/nlp/experiments/cls_embeddings_mnli.pth --batch_size 512 --num_clusters 512 --centroid_elements_only --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased; done
: 1595309718:0;mv -r 2_pct_18_epoch 2_pct
: 1595309726:0;mv 2_pct_18_epoch 2_pct/
: 1595309775:0;mv 2_pct_18_epoch /2_pct
: 1595309790:0;mv 2_pct_18_epoch 2_pct
: 1595309820:0;ls 2_pct_18_epoch
: 1595309827:0;rm 2_pct_18_epoch
: 1595309832:0;rm -r 2_pct_18_epoch
: 1595309834:0;ls 2_pct
: 1595309888:0;cat centroids/epoch_1/eval_results_mnli.txt
: 1595309899:0;cat centroids/epoch_1/eval_results_mnli-mm.txt
: 1595309964:0;cat centroids/epoch_2/eval_results_mnli.txt
: 1595309997:0;cat centroids/epoch_2/eval_results_mnli-mm.txt
: 1595310005:0;cat centroids/epoch_3/eval_results_mnli.txt
: 1595310014:0;cat centroids/epoch_3/eval_results_mnli-mm.txt
: 1595310022:0;cat centroids/epoch_4/eval_results_mnli.txt
: 1595310030:0;cat centroids/epoch_4/eval_results_mnli-mm.txt
: 1595310040:0;cat centroids/epoch_5/eval_results_mnli.txt
: 1595310104:0;cat centroids/epoch_5/eval_results_mnli-mm.txt
: 1595310112:0;cat centroids/epoch_6/eval_results_mnli.txt
: 1595310119:0;cat centroids/epoch_6/eval_results_mnli-mm.txt
: 1595310180:0;cat centroids/epoch_7/eval_results_mnli.txt
: 1595310199:0;cat centroids/epoch_7/eval_results_mnli-mm.txt
: 1595310210:0;cat centroids/epoch_8/eval_results_mnli.txt
: 1595310279:0;cat centroids/epoch_8/eval_results_mnli-mm.txt
: 1595310358:0;cat centroids/epoch_9/eval_results_mnli.txt
: 1595310369:0;cat centroids/epoch_9/eval_results_mnli-mm.txt
: 1595310378:0;cat centroids/epoch_10/eval_results_mnli.txt
: 1595310390:0;cat centroids/epoch_10/eval_results_mnli-mm.txt
: 1595310404:0;cat centroids/epoch_11/eval_results_mnli.txt
: 1595310413:0;cat centroids/epoch_11/eval_results_mnli-mm.txt
: 1595310424:0;cat centroids/epoch_12/eval_results_mnli.txt
: 1595310444:0;cat centroids/epoch_12/eval_results_mnli-mm.txt
: 1595310463:0;cat centroids/epoch_13/eval_results_mnli.txt
: 1595310472:0;cat centroids/epoch_13/eval_results_mnli-mm.txt
: 1595310484:0;cat centroids/epoch_14/eval_results_mnli.txt
: 1595310492:0;cat centroids/epoch_14/eval_results_mnli-mm.txt
: 1595310503:0;cat centroids/epoch_15/eval_results_mnli.txt
: 1595310539:0;cat centroids/epoch_15/eval_results_mnli-mm.txt
: 1595310553:0;cat centroids/epoch_16/eval_results_mnli.txt
: 1595310564:0;cat centroids/epoch_16/eval_results_mnli-mm.txt
: 1595310687:0;vim run_hans.sh
: 1595310802:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_1/hans_predictions.txt
: 1595310826:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_2/hans_predictions.txt
: 1595311915:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_3/hans_predictions.txt
: 1595311943:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_4/hans_predictions.txt
: 1595311969:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_5/hans_predictions.txt
: 1595311994:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_6/hans_predictions.txt
: 1595312035:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_7/hans_predictions.txt
: 1595312069:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_8/hans_predictions.txt
: 1595312235:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_9/hans_predictions.txt
: 1595312270:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_10/hans_predictions.txt
: 1595312314:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_11/hans_predictions.txt
: 1595312352:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_12/hans_predictions.txt
: 1595312386:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_13/hans_predictions.txt
: 1595312425:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_14/hans_predictions.txt
: 1595312557:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_16/hans_predictions.txt
: 1595312596:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_17/hans_predictions.txt
: 1595312707:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_18/hans_predictions.txt
: 1595313460:0;python3 evaluate_heur_output.py ~/experiments/clustering/16_clusters/epoch_15/hans_predictions.txt
: 1595316429:0;\
python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters\
  --train_adapter \\
  --adapter_config pfeiffer
: 1595316545:0;\
python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1595316610:0;\
python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1595318529:0;\
CUDA_VISIBLE_DEVICES = 0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1595318548:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1595319173:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer \\
-- overwrite_cache_dir
: 1595319187:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer \\
-- overwrite_output_dir
: 1595319300:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer --overwrite_output_dir
: 1595319378:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 472 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer --overwrite_output_dir
: 1595319424:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 415 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters \\
  --train_adapter \\
  --adapter_config pfeiffer --overwrite_output_dir
: 1595321639:0;mv * epoch_1
: 1595321695:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 415 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters/epoch_2 \\
  --train_adapter \\
  --adapter_config pfeiffer --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/mnli
: 1595321855:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 415 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters/epoch_2 \\
  --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/
: 1595321877:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --data_dir $GLUE_DIR/$TASK_NAME \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 415 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 1.0 \\
  --output_dir /home/nlp/experiments/adapters/epoch_2 \\
  --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/mnli
: 1595322546:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 learning_rate 1e-4 num_train_epochs 1.0 output_dir /home/nlp/experiments/adapters/epoch_2 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/mnli
: 1595322580:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_2 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/mnli
: 1595322651:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_2 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/mnli --adapter_config /home/nlp/experiments/adapters/mnli
: 1595322680:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_2 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/mnli --adapter_config /home/nlp/experiments/adapters/epoch_1/mnli
: 1595322695:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_2 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/epoch_1/mnli
: 1595324685:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_3 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/epoch_2/mnli
: 1595326665:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_4 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/epoch_3/mnli
: 1595328677:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_5 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/epoch_4/mnli
: 1595330049:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_1/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_1/mnli
: 1595331389:0;\
CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --do_train --do_eval --data_dir $GLUE_DIR/$TASK_NAME --max_seq_length 128 --per_device_train_batch_size 415 --learning_rate 1e-4 --num_train_epochs 1.0 --output_dir /home/nlp/experiments/adapters/epoch_6 --train_adapter --overwrite_output_dir --load_task_adapter /home/nlp/experiments/adapters/epoch_5/mnli
: 1595331913:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_1/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_1/mnli
: 1595332058:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_2/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_2/mnli
: 1595332454:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_3/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_3/mnli
: 1595332695:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_4/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_4/mnli
: 1595333262:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_6/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_6/mnli
: 1595333339:0;cat ../experiments/adapters/epoch_1/eval_results_mnli.txt
: 1595333374:0;cat ../experiments/adapters/epoch_1/eval_results_mnli-mm.txt
: 1595333385:0;cat ../experiments/adapters/epoch_2/eval_results_mnli.txt
: 1595333393:0;cat ../experiments/adapters/epoch_2/eval_results_mnli-mm.txt
: 1595333402:0;cat ../experiments/adapters/epoch_3/eval_results_mnli.txt
: 1595333410:0;cat ../experiments/adapters/epoch_3/eval_results_mnli-mm.txt
: 1595333421:0;cat ../experiments/adapters/epoch_4/eval_results_mnli.txt
: 1595333429:0;cat ../experiments/adapters/epoch_4/eval_results_mnli-mm.txt
: 1595333438:0;cat ../experiments/adapters/epoch_5/eval_results_mnli.txt
: 1595333468:0;cat ../experiments/adapters/epoch_5/eval_results_mnli-mm.txt
: 1595333478:0;cat ../experiments/adapters/epoch_6/eval_results_mnli.txt
: 1595333486:0;cat ../experiments/adapters/epoch_6/eval_results_mnli-mm.txt
: 1595333667:0;cd adapers
: 1595333681:0;mv epoch_1/hans_predictions.txt ../adapters/epoch_1/
: 1595333690:0;mv epoch_2/hans_predictions.txt ../adapters/epoch_2/
: 1595333697:0;mv epoch_3/hans_predictions.txt ../adapters/epoch_3/
: 1595333703:0;mv epoch_4/hans_predictions.txt ../adapters/epoch_4/
: 1595333709:0;mv epoch_5/hans_predictions.txt ../adapters/epoch_5/
: 1595333716:0;mv epoch_6/hans_predictions.txt ../adapters/epoch_6/
: 1595333724:0;rm -r adapers
: 1595333949:0;python3 evaluate_heur_output.py ~/experiments/adapters/epoch_2/hans_predictions.txt
: 1595333990:0;python3 evaluate_heur_output.py ~/experiments/adapters/epoch_3/hans_predictions.txt
: 1595334035:0;python3 evaluate_heur_output.py ~/experiments/adapters/epoch_4/hans_predictions.txt
: 1595334074:0;python3 evaluate_heur_output.py ~/experiments/adapters/epoch_5/hans_predictions.txt
: 1595334111:0;python3 evaluate_heur_output.py ~/experiments/adapters/epoch_6/hans_predictions.txt
: 1595430414:0;jupyter notebook password
: 1595576434:0;git commit -m "updates"
: 1595576439:0;git stats
: 1595765406:0;cp siamese_trainer.py orthogonal_trainer.py
: 1595765411:0;vim orthogonal_trainer.py
: 1595765612:0;cp run_glue.py train_orthogonal.py
: 1595767039:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/big_small/big   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1595767998:0;cp core/siamese_trainer.py core/orthogonal_trainer.py
: 1595769084:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/debias   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1595770471:0;pip unsinstall transformers
: 1595771206:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/debias   --fp16 --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1595771227:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/debias   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train
: 1595775986:0;vim models/lstm.py
: 1595825499:0;vim hans/run_hans_adapter.py
: 1595827695:0;cd tra
: 1595833801:0;expo
: 1595835550:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 128 --do_train
: 1595835668:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 256 --do_train
: 1595836482:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --do_train
: 1595838016:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --do_train --evaluate_during_training --dataloader_drop_last
: 1595839855:0;python3 train_orthogonal.py   --model_name_or_path ~/experiments/debias --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --do_train --evaluate_during_training --dataloader_drop_last
: 1595839927:0;python3 train_orthogonal.py   --model_name_or_path ~/experiments/debias --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last
: 1595841890:0;python3 train_orthogonal.py   --model_name_or_path ~/experiments/debias --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1595842078:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=50
: 1595843024:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=50 --do_train --model_weights_path ~/experiments/debias
: 1595843238:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=50 --model_weights_path ~/experiments/debias
: 1595843519:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=10
: 1595843550:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=10 --do_train
: 1595845898:0;git pull remote upstream
: 1595847977:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 768 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=30 --do_train
: 1595848153:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 768 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=30 --do_train
: 1595851837:0;git commit -m "adapter, HEX"
: 1595854967:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=30 --do_train --model_weight_path ~/experiments/debias
: 1595854982:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=30 --do_train --model_weights_path ~/experiments/debias
: 1595858196:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=50 --do_train
: 1595862959:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=30 --do_train
: 1595864192:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=30 --do_train
: 1595904178:0;echo "sudo python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=100 --do_train >> "run.sh"
: 1595904185:0;echo "sudo python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=100 --do_train << "run.sh"
: 1595904223:0;echo "sudo python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=100 --do_train" >> run.sh
: 1595904486:0;rm -r scripts
: 1595904493:0;rm run_sh.sh
: 1595904508:0;vim dataset_utils.py
: 1595905090:0;sh run_hans.sh
: 1595906719:0;rm *
: 1595906727:0;rm -f *
: 1595918706:0;cat ../experiments/debias/epoch_3/eval_results_mnli
: 1595927682:0;cat ../experiments/debias/epoch_10/eval_results_mnli.txt
: 1595927752:0;cat ../experiments/debias/epoch_1/eval_results_mnli.txt
: 1595927767:0;cat ../experiments/debias/epoch_1/eval_results_mnli-mm.txt
: 1595927777:0;cat ../experiments/debias/epoch_2/eval_results_mnli.txt
: 1595927786:0;cat ../experiments/debias/epoch_2/eval_results_mnli-mm.txt
: 1595927799:0;cat ../experiments/debias/epoch_3/eval_results_mnli.txt
: 1595927810:0;cat ../experiments/debias/epoch_3/eval_results_mnli-mm.txt
: 1595927821:0;cat ../experiments/debias/epoch_4/eval_results_mnli.txt
: 1595927831:0;cat ../experiments/debias/epoch_4/eval_results_mnli-mm.txt
: 1595927844:0;cat ../experiments/debias/epoch_5/eval_results_mnli.txt
: 1595927852:0;cat ../experiments/debias/epoch_5/eval_results_mnli-mm.txt
: 1595927863:0;cat ../experiments/debias/epoch_6/eval_results_mnli.txt
: 1595927872:0;cat ../experiments/debias/epoch_6/eval_results_mnli-mm.txt
: 1595927880:0;cat ../experiments/debias/epoch_7/eval_results_mnli.txt
: 1595927888:0;cat ../experiments/debias/epoch_7/eval_results_mnli-mm.txt
: 1595927900:0;cat ../experiments/debias/epoch_8/eval_results_mnli.txt
: 1595927909:0;cat ../experiments/debias/epoch_8/eval_results_mnli-mm.txt
: 1595927917:0;cat ../experiments/debias/epoch_9/eval_results_mnli.txt
: 1595927924:0;cat ../experiments/debias/epoch_9/eval_results_mnli-mm.txt
: 1595929969:0;cp run_hans.py run_hex.py
: 1595929974:0;vim run_hex.py
: 1595930411:0;rm run_hex.py
: 1595930504:0;python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/debiasing/epoch_1 --model_weights_path /home/nlp/experiments/debias/epoch_1
: 1595930678:0;for i in {1..10}; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/debiasing/"epoch_"$epoch --model_weights_path /home/nlp/experiments/debias/"epoch_"$epoch; done
: 1595930703:0;for epoch in {1..10}; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/debiasing/"epoch_"$epoch --model_weights_path /home/nlp/experiments/debias/"epoch_"$epoch; done
: 1595930950:0;for epoch in {1..10}; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/debiasing/"epoch_"$epoch --model_weights_path /home/nlp/experiments/debias/"epoch_"$epoch --dataloader_drop_last; done
: 1595931556:0;python3 evaluate_heur_output.py ~/experiments/debiasing/epoch_2/hans_predictions.txt
: 1595941255:0;vim modells/orthogonal_transformer.py
: 1595947221:0;vim cbow.py
: 1595947366:0;rm -r ../experiments/debias
: 1595950582:0;cd ../experiments/debias
: 1595953132:0;rm ../experiments/debias
: 1595953144:0;rm -r ../experiments/debias/*
: 1595954992:0;jupyter notebook --no-browser --port=8890
: 1595992682:0;git fetch upstream
: 1595992687:0;git pull upstream
: 1595992965:0;git add modeling_utils.py
: 1595992972:0;git staus
: 1595993913:0;git restore trainer.py
: 1595994127:0;rm -r ../experiments/debias2/*
: 1595994144:0;ls ../experiments/debias2
: 1595994153:0;cp run.sh run_2.sh
: 1595994270:0;cd experiments/debias_2
: 1595995894:0;rm -r debias
: 1595995904:0;grep debias
: 1595995911:0;ls debi*
: 1595995979:0;vim run_2.sh
: 1595995987:0;sh run_2.sh
: 1595997708:0;cd debias_3
: 1595997717:0;rm -r debias_3
: 1595997726:0;ls debias*
: 1595997798:0;rm run_2.sh
: 1595997838:0;mv debias_2 debias
: 1595997855:0;sh run.sh
: 1595999295:0;cat experiments/debias/epoch_1/eval_results_mnli.txt
: 1595999305:0;cat debias/epoch_1/eval_results_mnli.txt
: 1595999312:0;cat debias/epoch_2/eval_results_mnli.txt
: 1596016027:0;for epoch in {1..10}; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/debiasing/"epoch_"$epoch --model_weights_path /home/nlp/experiments/debias/"epoch_"$epoch; done
: 1596018214:0;python3 evaluate_heur_output.py ~/experiments/debiasing/epoch_1/hans_predictions.txt
: 1596018246:0;cd debias
: 1596018264:0;rm -r debiasing
: 1596018359:0;for epoch in {1..10}; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/debias/"epoch_"$epoch --model_weights_path /home/nlp/experiments/debias/"epoch_"$epoch; done
: 1596018554:0;cat epoch_2/eval_results_mnli.txt
: 1596018575:0;cat epoch_3/eval_results_mnli.txt
: 1596018582:0;cat epoch_3/eval_results_mnli-mm.txt
: 1596018590:0;cat epoch_4/eval_results_mnli.txt
: 1596018598:0;cat epoch_4/eval_results_mnli-mm.txt
: 1596018606:0;cat epoch_5/eval_results_mnli.txt
: 1596018615:0;cat epoch_5/eval_results_mnli-mm.txt
: 1596018623:0;cat epoch_6/eval_results_mnli.txt
: 1596018635:0;cat epoch_6/eval_results_mnli-mm.txt
: 1596018644:0;cat epoch_7/eval_results_mnli.txt
: 1596018651:0;cat epoch_7/eval_results_mnli-mm.txt
: 1596018661:0;cat epoch_8/eval_results_mnli.txt
: 1596018669:0;cat epoch_8/eval_results_mnli-mm.txt
: 1596018678:0;cat epoch_9/eval_results_mnli.txt
: 1596018687:0;cat epoch_9/eval_results_mnli-mm.txt
: 1596018696:0;cat epoch_10/eval_results_mnli.txt
: 1596018703:0;cat epoch_10/eval_results_mnli-mm.txt
: 1596018712:0;cat epoch_11/eval_results_mnli.txt
: 1596018720:0;cat epoch_11/eval_results_mnli-mm.txt
: 1596018731:0;cat epoch_12/eval_results_mnli.txt
: 1596018750:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_1/hans_predictions.txt
: 1596018787:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_2/hans_predictions.txt
: 1596018823:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_3/hans_predictions.txt
: 1596018867:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_4/hans_predictions.txt
: 1596018910:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_5/hans_predictions.txt
: 1596019566:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_6/hans_predictions.txt
: 1596019610:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_7/hans_predictions.txt
: 1596019642:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_8/hans_predictions.txt
: 1596019678:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_9/hans_predictions.txt
: 1596019718:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_10/hans_predictions.txt
: 1596019846:0;cd experiments/debias
: 1596019857:0;cd epoch_11
: 1596019915:0;python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/debias/epoch_11 --model_weights_path /home/nlp/experiments/debias/epoch_11
: 1596019990:0;cd ../../
: 1596020004:0;python3 evaluate_heur_output.py ~/experiments/debias/epoch_11/hans_predictions.txt
: 1596081458:0;pip install torch --upgrade
: 1596081950:0;pip unsintalll torchmeta
: 1596081954:0;pip unintalll torchmeta
: 1596081958:0;pip uninstalll torchmeta
: 1596081961:0;pip uninstall torchmeta
: 1596083698:0;cp src/transformers/trainer.py ../../transformers-importance-sampling
: 1596083744:0;import torch
: 1596087036:0;cd prajjwal1/transformers/
: 1596087299:0;conda
: 1596087345:0;pip install numpy ninja pyyaml mkl mkl-include setuptools cmake cffiinstall transformers --upgrade
: 1596087353:0;pip install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi 
: 1596087777:0;git clone --recursive https://github.com/pytorch/pytorch
: 1596092292:0;make CXX=g++-7 CC=gcc-7
: 1596092309:0;./configure CXX=g++-8 CC=gcc-8
: 1596092322:0;cd pytorch
: 1596092328:0;make CXX=g++-8 CC=gcc-8
: 1596092686:0;export CC=/usr/bin/gcc-7
: 1596092723:0;gcc -v
: 1596092902:0;cat /usr/bin/gcc
: 1596092909:0;ls /usr/bin/gcc
: 1596092913:0;ls /usr/bin/gcc*
: 1596092935:0;export CC=/usr/bin/gcc-8
: 1596092938:0;which gcc
: 1596093627:0;python3 run_glue.py   --model_name_or_path albert-base-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/hf_pr   --fp16 --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train
: 1596093906:0;python3 run_glue.py   --model_name_or_path albert-base-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/hf_pr   --fp16 --overwrite_output_dir --per_device_eval_batch_size 1024 --do_train
: 1596093980:0;cp trainer.py /home/nlp/prajjwal1/transformers/src/transformers/trainer.py
: 1596094277:0;cp src/transformers/modeling_utils.py ../
: 1596094295:0;cp src/transformers/trainer.py ../
: 1596094461:0;git remote -v
: 1596094696:0;git branch -d torch_cuda_amp
: 1596094706:0;git fetch upstream master
: 1596094711:0;git rebase upstream/master
: 1596094721:0;git branch torch_cuda_amp
: 1596094763:0;git push origin torch_cuda_amp
: 1596094792:0;mv src/transformers/trainer.py ../
: 1596094803:0;mv src/transformers/modeling_utils.py ../
: 1596094824:0;git checkout torch_cuda_amp
: 1596094850:0;git branch -D torch_cuda_amp
: 1596094860:0;git branch pytorch_native_amp
: 1596094866:0;git checkout pytorch_native_amp
: 1596094870:0;mv ../modeling_utils.py src/transformers/modeling_utils.py
: 1596094874:0;mv ../trainer.py src/transformers/trainer.py
: 1596094890:0;git commit -m "fixed type; add Pytorch Native CUDA AMP support"
: 1596095461:0;git checkout 10064
: 1596095464:0;git show
: 1596095475:0;git checkout 7296b4a
: 1596095541:0;git checkout HEAD^ -- modeling_utils.py
: 1596095563:0;git commit -am "reverted commit on modeling_utils"
: 1596095748:0;git commit -am "confirming to HF black formatting rule"
: 1596095768:0;git commit -am "conforming to HF black formatting rule"
: 1596095826:0;vim modeling_utils.py
: 1596096207:0;git add trainer.py
: 1596096221:0;git commit -am "changed bool value of _use_apex"
: 1596096592:0;python3 setup.py install
: 1596097108:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/hf_pr   --fp16 --overwrite_output_dir --per_device_eval_batch_size 256 --do_train
: 1596097183:0;git commit -am "scaler support for gradient clipping"
: 1596097279:0;git commit -am "fix inplace operation of clip_grad_norm"
: 1596097718:0;pip purge transformers
: 1596097747:0;pip unsinstall adapter-transformers
: 1596098896:0;cp transformers-importance-sampling/models/orthogonal_transformer.py fluence/fluence/models
: 1596098903:0;vim fluence/fluence/models
: 1596098955:0;cd fluence/fluence
: 1596099005:0;vim ../fluence/fluence/models/orthogonal_transformer.py
: 1596099044:0;mv orthogonal_transformer.py orthogonal.py
: 1596099058:0;cd tests/
: 1596099104:0;vim ../fluence/tests/test_siamese.py
: 1596099574:0;cp models/cbow.py ../fluence/tests/fixtures/models
: 1596099616:0;mv models cbow.py
: 1596099646:0;mkdir models
: 1596099650:0;mv cbow.py models
: 1596099780:0;vim fluence/tests/test_siamese.py
: 1596100079:0;cd /home/nlp/.local/lib/python3.8/site-packages
: 1596100091:0;rm transformer*
: 1596100096:0;rm -rf transformer*
: 1596100375:0;vim fluence/__init__.py
: 1596100413:0;git commit -m "added debiasing method: HEX"
: 1596102266:0;vim .github/workflows
: 1596102554:0;pytest tests/
: 1596102578:0;pytest tests/ --ignore=tests/test_clustering.py
: 1596102638:0;git commit -m "skip clustering test"
: 1596103372:0;pytest tests/test_meta.py -v
: 1596103785:0;pytest tests/ -v --ignore=tests/test_clustering.py
: 1596103894:0;git commit -m "updated README"
: 1596105015:0;git commit -m "test only current commit"
: 1596105563:0;git commit -m "remove mem requirements"
: 1596105860:0;git commit -m "updated README and fixed tests mem issue"
: 1596118829:0;cd prajjwal1/transformers/src/transformers
: 1596118954:0;git commit -m "removed not while version comparison"
: 1596118962:0;git push origin pytorch_native_amp
: 1596170649:0;git uninstall torch
: 1596170781:0;pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html
: 1596196971:0;git clone https://github.com/bhoov/exbert
: 1596197133:0;pip install spacyface
: 1596197342:0;pip install -e server
: 1596197364:0;pip install fastapi
: 1596197407:0;pip install aiofiles
: 1596197420:0;pip install uvicorn
: 1596197579:0;pip install -e server/spacyface
: 1596197621:0;python3 -m spacy download en_core_web_sm
: 1596197640:0;pip install server/spacyface
: 1596197710:0;pip uninstall spacyface
: 1596197835:0;cd server/spacyface
: 1596197972:0;cd spacyface/utils
: 1596198041:0;cd spacyface
: 1596198235:0;vim aligner.py
: 1596198276:0;python3 server/main.py
: 1596199393:0;python3 server/main.py --model ~/experiments/big_small/ --kind bidirectional --corpus ~/experiments/big_small/
: 1596199446:0;python3 server/main.py --model ~/experiments/big_small/small --kind bidirectional --corpus ~/experiments/big_small/small
: 1596200032:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis.txt -o .
: 1596200061:0;cd ../big
: 1596200065:0;rm -r eval_analysis
: 1596200071:0;rm -r det
: 1596200135:0;python3 server/main.py --model ~/experiments/big_small/small --kind bidirectional --corpus ~/experiments/big_small/small/eval_analysis/
: 1596200503:0;npm
: 1596200614:0;cd small
: 1596201049:0;cd big
: 1596201061:0;cd ../small
: 1596201063:0;rm -r eval_analysis_hans
: 1596365423:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 256 --do_train --fp16
: 1596365596:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 256 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100 --overwrite_data_cache
: 1596365610:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 256 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100 --overwrite_cache
: 1596366551:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 256 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596366662:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 128 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596366781:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596369689:0;git commit -m "added siamese2"
: 1596369746:0;git rm -r --cached tags
: 1596369805:0;git commit -m "rm tags"
: 1596369913:0;rm trainer.py
: 1596370016:0;python3 train_siamese.py   --model_name /home/nlp/experiments/siamese_2/checkpoint-1000 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 512 --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100 --overwrite_cache
: 1596370266:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2 --per_device_eval_batch_size 512 --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100 --overwrite_cache --model_weights_path /home/nlp/experiments/siamese_2/checkpoint-1000
: 1596370646:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2_one_mlp --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596371386:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2_one_mlp --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596371464:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 384  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2_one_mlp --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596371620:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 450  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2_one_mlp --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100
: 1596373102:0;mv siamese siamese_add
: 1596373108:0;mv siamese_2 siamese
: 1596373157:0;mv siamese_2_one_mlp siamese
: 1596373311:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/debias  --overwrite_output_dir --per_device_eval_batch_size 384 --evaluate_during_training --dataloader_drop_last --eval_steps=100 --do_train
: 1596373446:0;$((epoch+1))
: 1596373451:0;$epoch = 1
: 1596373524:0;for epoch in {1..4}; do python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 450  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/"epoch_"$((epoch+1)) --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 300 --do_train --load_model_weights /home/nlp/experiments/siamese/"epoch_"$epoch; done
: 1596373613:0;for epoch in {1..4}; do python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 450  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/"epoch_"$((epoch+1)) --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 300 --do_train --model_weights_path /home/nlp/experiments/siamese/"epoch_"$epoch; done
: 1596380631:0;cat experiments/siamese/epoch_4/eval_results_mnli.txt
: 1596380640:0;cat experiments/siamese/epoch_5/eval_results_mnli.txt
: 1596380651:0;cat experiments/siamese/epoch_5/eval_results_mnli-mm.txt
: 1596381099:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_0 --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381129:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_0/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381243:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_1/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased --overwrite_cache
: 1596381408:0;vim ../core/siamese_trainer.py
: 1596381472:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_1/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381508:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 8192 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_1/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381530:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_1/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381648:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_2/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381759:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_3/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381860:0;python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_4/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased
: 1596381959:0;for epoch in {1..5}; do python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/"epoch_"$epoch --model_weights_path=/home/nlp/experiments/siamese/"epoch_"$epoch --config_name bert-base-uncased --tokenizer_name bert-base-uncased; done
: 1596382392:0;python3 evaluate_heur_output.py ~/experiments/siamese/epoch_1/hans_predictions.txt
: 1596382427:0;python3 evaluate_heur_output.py ~/experiments/siamese/epoch_2/hans_predictions.txt
: 1596382464:0;python3 evaluate_heur_output.py ~/experiments/siamese/epoch_3/hans_predictions.txt
: 1596382504:0;python3 evaluate_heur_output.py ~/experiments/siamese/epoch_4/hans_predictions.txt
: 1596382541:0;python3 evaluate_heur_output.py ~/experiments/siamese/epoch_5/hans_predictions.txt
: 1596440074:0;;s
: 1596442021:0;rm -r ~/experiments/big_small/big/eval_analysis_hans/*
: 1596442029:0;rm -r ~/experiments/big_small/small/eval_analysis_hans/*
: 1596442067:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m ~/experiments/big_small/small
: 1596442093:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m ~/experiments/big_small/big
: 1596444921:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m ~/experiments/siamese/epoch_2
: 1596444943:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m ~/experiments/siamese/epoch_2/
: 1596444975:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m ~/experiments/siamese/epoch_1/
: 1596445045:0;cp big_small/small/config.json siamese/epoch_2
: 1596445123:0;python3 server/main.py --model ~/experiments/big_small/big --kind bidirectional --corpus ~/experiments/siamese/epoch_2/eval_analysis_hans/
: 1596445374:0;rm -r siamese/epoch_2/eval_analysis_hans
: 1596445402:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m /home/nlp/experiments/siamese/epoch_222
: 1596445428:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o . --m /home/nlp/experiments/siamese/epoch_2
: 1596445988:0;rm -r bert-base-cased
: 1596445999:0;rm -r siamese/epoch_2/eval_analysis_hans/*
: 1596446175:0;rm -r big/big/eval_analysis_hans/*
: 1596446182:0;rm -r big_small/big/eval_analysis_hans/*
: 1596446683:0;python3 server/main.py --model ~/experiments/siamese/epoch_2 --kind bidirectional --corpus ~/experiments/siamese/epoch_2/eval_analysis_hans/
: 1596447911:0;vim hans
: 1596447940:0;vim hans/utils_siamese_hans.py
: 1596448856:0;cd ../exbert
: 1596448898:0;rm -r big_small/small/eval_analysis_hans/*
: 1596448970:0;vim transformers-importance-sampling
: 1596449787:0;cd data_processing
: 1596449792:0;python3 create_corpus.py -f ~/exbert/server/eval_analysis_hans.txt -o .
: 1596449817:0;vim create_corpus.py
: 1596449843:0;python3 server/main.py --model ~/experiments/big_small/small --kind bidirectional --corpus ~/experiments/big_small/small/eval_analysis_hans/
: 1596450117:0;python3 server/main.py --model ~/experiments/big_small/big --kind bidirectional --corpus ~/experiments/big_small/big/eval_analysis_hans/
: 1596465835:0;pip install pytest-cov
: 1596465853:0;pytest --cov=myproj tests/
: 1596466203:0;pytest --cov=fluence tests/
: 1596466469:0;coverage
: 1596466549:0;PYTHONPATH 
: 1596466554:0;$PYTHONPATH 
: 1596466769:0;py.test --cov-report html --cov fluence --verbose
: 1596466947:0;cd htmlcov
: 1596466954:0;cat index.html
: 1596466960:0;vim index.html
: 1596467014:0;rm htmlcov
: 1596467018:0;rm -r htmlcov
: 1596467387:0;git commit -m "add standard siamese implementation"
: 1596519578:0;pip install coverage
: 1596519608:0;coverage run pytest tests/ -v
: 1596519629:0;coverage run -m pytest tests/ -v
: 1596520277:0;cd examples
: 1596520570:0;coverage run test_adaptive.py
: 1596520582:0;coverage report -m
: 1596520704:0;pytest --cov=fluence fluence/tests
: 1596521415:0;coverage run tests/test_adaptive.py
: 1596521497:0;pytest tests/test_siamese.py -v
: 1596521527:0;coverage tests/test_siamese.py
: 1596521533:0;coverage run tests/test_siamese.py
: 1596521574:0;ls -a
: 1596521592:0;coverage run test_siamese.py
: 1596521659:0;coverage report
: 1596521982:0;pytest --cov=tests/test_adaptive
: 1596522006:0;pytest --cov=test_adaptive
: 1596522038:0;rm .coverage
: 1596522044:0;rm tests/.coverage
: 1596522052:0;pytest --cov=tests/
: 1596522364:0;pytest --cov-report --cov=./tests
: 1596522379:0;pytest --cov-report report.txt --cov=./tests
: 1596522389:0;pytest --cov-report term --cov=./tests
: 1596523301:0;git commit -m "add codecov"
: 1596523599:0;git commit -m "fixed syntax error"
: 1596527417:0;git commit -m "add codecov token"
: 1596527652:0;git commit -m "fix syntax issue"
: 1596528584:0;git commit -m "add codecov badge"
: 1596529749:0;vim CONTRIBUTING.md
: 1596774597:0;mv small bert_base
: 1596774601:0;mv big bert_large
: 1596774811:0;python3 run_glue.py   --model_name_or_path roberta-base --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/roberta/"epoch_"$epoch   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596774825:0;python3 run_glue.py   --model_name_or_path roberta-base --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/roberta/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596775009:0;python3 run_glue.py   --model_name_or_path roberta-base --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 476 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/roberta/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596775084:0;python3 run_glue.py   --model_name_or_path roberta-base --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/roberta/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1596775772:0;for epoch in {1..3}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/roberta/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/roberta/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1596780446:0;cd experiments/big_small/
: 1596780469:0;mv roberta big_small
: 1596780487:0;mv roberta roberta_base
: 1596780609:0;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596781027:0;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1596781768:0;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/epoch_1   --fp16 --per_device_eval_batch_size 196 --do_train
: 1596781783:0;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/epoch_1   --fp16 --per_device_eval_batch_size 196 --do_train --overwrite_output_dir
: 1596783680:0;for epoch in {1..3}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1596784119:0;for epoch in {1..3}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 256 --do_train; done
: 1596784448:0;for epoch in {1..3}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 128 --do_train; done
: 1596784463:0;for epoch in {1..3}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 160 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 128 --do_train; done
: 1596784484:0;nvidia-smi help
: 1596784487:0;nvidia-smi -h
: 1596784530:0;for epoch in {1..3}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 144 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 128 --do_train; done
: 1596784984:0;vim hans/utils_hans.py
: 1596787144:0;cd 0.1_pct_0
: 1596787158:0;cd 0.1_pct_250
: 1596787161:0;rm -r pytorch_model.bin
: 1596787221:0;rm -r 0.1*/pytorch_model.bin
: 1596787233:0;ls 0.1_pct_750
: 1596787240:0;rm -r 0.2*/pytorch_model.bin
: 1596787244:0;rm -r 0.3*/pytorch_model.bin
: 1596787249:0;rm -r 0.4*/pytorch_model.bin
: 1596787253:0;rm -r 0.5*/pytorch_model.bin
: 1596794312:0;python3 run_glue.py   --model_name_or_path t5_small --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/t5_small/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596794373:0;python3 run_glue.py   --model_name_or_path t5-small --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/t5_small/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1596794846:0;python3 run_glue.py   --model_name_or_path albert-base-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 1024 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_base/epoch_1   --fp16 --per_device_eval_batch_size 1024 --do_train
: 1596794896:0;python3 run_glue.py   --model_name_or_path albert-base-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_base/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1596794957:0;python3 run_glue.py   --model_name_or_path albert-base-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_base/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596795010:0;python3 run_glue.py   --model_name_or_path albert-base-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 315 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_base/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596796847:0;for epoch in {1..2}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_base/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 144 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_base/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 128 --do_train; done
: 1596800370:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 315 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596800419:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 256 --do_train
: 1596800464:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 196 --do_train
: 1596800506:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1596800569:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 96 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1596800631:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 112 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1596800685:0;python3 run_glue.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 118 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1596805937:0;for epoch in {1..2}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 144 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 128 --do_train; done
: 1596805985:0;for epoch in {1..2}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 128 --do_train; done
: 1596806045:0;for epoch in {1..2}; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 108 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 108 --do_train; done
: 1596815903:0;cd ../experiments/big_small
: 1596816086:0;cat bert_base/eval_results_mnli-mm.txt
: 1596816096:0;cat bert_base/eval_results_mnli.txt
: 1596816107:0;cat bert_large/eval_results_mnli.txt
: 1596816124:0;cat bert_large/eval_results_mnli-mm.txt
: 1596816162:0;cd centroids
: 1596816176:0;cat epoch_13/eval_results_mnli.txt
: 1596816538:0;cd..
: 1596816665:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering/centroids/epoch_15 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/clustering/centroids/epoch_15
: 1596816695:0;ls centroids/epoch_15
: 1596816715:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering/centroids/epoch_15 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/clustering/centroids/epoch_15 --tokenizer_name bert-base-uncased
: 1596816823:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering/centroids/epoch_15 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/clustering/centroids/epoch_15 --tokenizer_name bert-base-uncased --overwrite_cache
: 1596816994:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/ --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/big_small/bert_base/ --tokenizer_name bert-base-uncased --overwrite_cache
: 1596817176:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_large/ --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/big_small/bert_large/ --tokenizer_name bert-large-uncased --overwrite_cache
: 1596817476:0;cd ../big_small
: 1596817511:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/albert_base/epoch_3 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/big_small/albert_base/epoch_3 --tokenizer_name albert-base-v2
: 1596817644:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/albert_base/epoch_3 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/big_small/albert_base/epoch_3 --tokenizer_name albert-base-v2 --overwrite_cache
: 1596817736:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/albert_large/epoch_3 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/big_small/albert_large/epoch_3 --tokenizer_name albert-large-v2
: 1596817768:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/albert_large/epoch_3 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/albert_large/epoch_3 --tokenizer_name albert-large-v2
: 1596818030:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/roberta_base/epoch_3 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/roberta_base/epoch_3 --tokenizer_name roberta-base
: 1596818577:0;python3 evaluate_heur_output.py ~/experiments/clustering/centroids/epoch_15/hans_predictions.txt
: 1596818747:0;python3 evaluate_heur_output.py ~/experiments/big_small/bert_base/hans_predictions.txt
: 1596819145:0;python3 evaluate_heur_output.py ~/experiments/big_small/albert_base/hans_predictions.txt
: 1596819151:0;python3 evaluate_heur_output.py ~/experiments/big_small/albert_base/epoch_3/hans_predictions.txt
: 1596819224:0;python3 evaluate_heur_output.py ~/experiments/big_small/albert_large/epoch_3/hans_predictions.txt
: 1596819323:0;python3 evaluate_heur_output.py ~/experiments/big_small/roberta_base/epoch_3/hans_predictions.txt
: 1596819348:0;python3 evaluate_heur_output.py ~/experiments/big_small/roberta_base/epoch_2/hans_predictions.txt
: 1596819394:0;python3 evaluate_heur_output.py ~/experiments/big_small/roberta_large/epoch_3/hans_predictions.txt
: 1596850190:0;python3 train_orthogonal.py   --model_name_or_path albert-v2-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 96 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_albert  --per_device_eval_batch_size 128 --evaluate_during_training --eval_steps=100 --do_train
: 1596850214:0;python3 train_orthogonal.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 96 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_albert  --per_device_eval_batch_size 128 --evaluate_during_training --eval_steps=100 --do_train
: 1596850399:0;python3 train_orthogonal.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_albert  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train
: 1596850454:0;python3 train_orthogonal.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_albert  --per_device_eval_batch_size 196 --evaluate_during_training --eval_steps=100 --do_train
: 1596851277:0;python3 train_orthogonal.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_albert  --per_device_eval_batch_size 196 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.00001
: 1596851657:0;python3 train_orthogonal.py   --model_name_or_path albert-large-v2 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_albert  --per_device_eval_batch_size 196 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.000001
: 1596851949:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 196 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.000001
: 1596852255:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.000001
: 1596853694:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.00001
: 1596854314:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.001
: 1596855216:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.0002
: 1596855679:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 6.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.0001
: 1596858988:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.00009 --dataloader_drop_last
: 1596859170:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.00009 --dataloader_drop_last --overwrite_existing_dir
: 1596859178:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.00009 --dataloader_drop_last --overwrite_output_dir
: 1596859845:0;python3 train_orthogonal.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/orthogonal_bert_large  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps=100 --do_train --lamb 0.0001 --dataloader_drop_last --overwrite_output_dir
: 1596863505:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2_large/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 8192 --num_update_steps 1 --num_tasks 1
: 1596877345:0;mkdir /home/nlp/experiments/meta_2_large
: 1596877348:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2_large/   --per_device_eval_batch_size 512 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 8192 --num_update_steps 1 --num_tasks 1
: 1596878304:0;ls ../experiments/meta_2_large
: 1596878536:0;cd experiments/meta_2_large
: 1596878559:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta_2_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 8192 --num_update_steps 1 --num_tasks 1
: 1596886373:0;python3 evaluate_heur_output.py ~/experiments/meta_2_large/hans_predictions_1.txt
: 1596886466:0;pip install git+https://github.com/adapter-hub/adapter-transformers.git
: 1596886707:0;python3 train_adapter.py
: 1596887812:0;python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1596888614:0;python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596888715:0;python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596888874:0;CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596888957:0;CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596889090:0;CUDA_VISIBLE_DEVICES=1 python3 train_siamese.py   --model_name bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 312  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_big --per_device_eval_batch_size 256 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased --evaluate_during_training --eval_steps 100
: 1596889361:0;CUDA_VISIBLE_DEVICES=1 python3 train_adapter.py   --model_name roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_roberta_big --per_device_eval_batch_size 256 --do_train --fp16 --adapter_config pfeiffer --train_adapter 
: 1596890568:0;CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_2 --load_adapter /home/nlp/experiments/adapter_big/epoch_1/mnli   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596890609:0;CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_2 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_1/mnli   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596890902:0;cd adapter_roberta_big
: 1596890910:0;mkdir epoch_1
: 1596890919:0;mv  checkpoint-* epoch_1
: 1596890924:0;mv *.txt epoch_1
: 1596890928:0;mv *.json epoch_1
: 1596890937:0;mv *.bin epoch_1
: 1596890940:0;cd mnli
: 1596890947:0;mv mnli epoch_1
: 1596890992:0;CUDA_VISIBLE_DEVICES=1 python3 train_adapter.py   --model_name roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_roberta_big/epoch_2 --per_device_eval_batch_size 256 --do_train --fp16 --adapter_config pfeiffer --train_adapter --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_1/mnli
: 1596892426:0;CUDA_VISIBLE_DEVICES=0 python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_2/mnli   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1596892447:0;CUDA_VISIBLE_DEVICES=1 python3 train_adapter.py   --model_name roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 312  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_roberta_big/epoch_3 --per_device_eval_batch_size 256 --do_train --fp16 --adapter_config pfeiffer --train_adapter --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_2/mnli
: 1596895365:0;python3 run_hans_adapter.pyRR
: 1596895445:0;python3 run_hans_adapter.py
: 1596895512:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapers/epoch_5/ --train_adapter --load_task_adapter /home/nlp/experiments/adapters/epoch_5/mnli
: 1596895626:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/ --load_task_adapter /home/nlp/experiments/adapter_big
: 1596896057:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_1 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_1
: 1596896421:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_2 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_2
: 1596896526:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_3
: 1596896785:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_1 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_1
: 1596896973:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_2 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_2
: 1596897191:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_3
: 1596897303:0;	ls ../../experiments/adapters
: 1596897333:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_1 --load_task_adapter /home/nlp/experiments/adapters/epoch_1
: 1596897453:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_1 --load_task_adapter /home/nlp/experiments/adapters/epoch_1
: 1596897538:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_2 --load_task_adapter /home/nlp/experiments/adapters/epoch_2
: 1596897558:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_3 --load_task_adapter /home/nlp/experiments/adapters/epoch_3
: 1596897795:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_3 --load_task_adapter /home/nlp/experiments/adapters/epoch_3
: 1596897836:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_4 --load_task_adapter /home/nlp/experiments/adapters/epoch_4
: 1596897905:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_5 --load_task_adapter /home/nlp/experiments/adapters/epoch_5
: 1596897966:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_6 --load_task_adapter /home/nlp/experiments/adapters/epoch_6
: 1596898079:0;python3 evaluate_heur_output.py ~/experiments/adapters/epoch_1/hans_predictions.txt
: 1596898593:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_1 --load_task_adapter /home/nlp/experiments/adapters/epoch_1 --train_adapter
: 1596898672:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_1 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_1 --train_adapter
: 1596898750:0;ls ../experiments/adapter_big/epoch_1
: 1596899845:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_1 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_1/mnli --train_adapter
: 1596900019:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_1 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_1/mnli
: 1596900354:0;python3 evaluate_heur_output.py ~/experiments/adapter_big/epoch_1/hans_predictions.txt
: 1596900390:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_2 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_2/mnli
: 1596900756:0;python3 evaluate_heur_output.py ~/experiments/adapter_big/epoch_2/hans_predictions.txt
: 1596900773:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_big/epoch_3/mnli
: 1596901128:0;python3 evaluate_heur_output.py ~/experiments/adapter_big/epoch_3/hans_predictions.txt
: 1596901199:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_1/mnli
: 1596901496:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path roberta-large --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_1/mnli
: 1596901535:0;ls ../../../experiments/adapter_big/epoch_1
: 1596901540:0;ls ../../../experiments/adapter_big/epoch_1/mnli
: 1596901751:0;ls ../../../experiments/adapter_roberta_big/epoch_1/mnli
: 1596901797:0;python3 evaluate_heur_output.py ~/experiments/adapter_roberta_big/epoch_1/hans_predictions.txt
: 1596901814:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path roberta-large --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_2 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_2/mnli
: 1596902024:0;vim ../../../transformers-importance-sampling/hans/run_hans_adapter.py
: 1596902127:0;python3 evaluate_heur_output.py ~/experiments/adapter_roberta_big/epoch_2/hans_predictions.txt
: 1596902143:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path roberta-large --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_3 --load_task_adapter /home/nlp/experiments/adapter_roberta_big/epoch_3/mnli
: 1596902528:0;python3 evaluate_heur_output.py ~/experiments/adapter_roberta_big/epoch_3/hans_predictions.txt
: 1596902649:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapter_roberta_big/epoch_1 --load_task_adapter /home/nlp/experiments/adapters/epoch_1/mnli
: 1596902662:0;cd ../../transformers-importance-sampling/hans
: 1596902788:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_1 --load_task_adapter /home/nlp/experiments/adapters/epoch_1/mnli
: 1596902834:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_2 --load_task_adapter /home/nlp/experiments/adapters/epoch_2/mnli
: 1596902914:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_3 --load_task_adapter /home/nlp/experiments/adapters/epoch_3/mnli
: 1596902941:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_4 --load_task_adapter /home/nlp/experiments/adapters/epoch_4/mnli
: 1596903022:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_5 --load_task_adapter /home/nlp/experiments/adapters/epoch_5/mnli
: 1596903096:0;CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_6 --load_task_adapter /home/nlp/experiments/adapters/epoch_6/mnli
: 1596946722:0;mkdir adapters_networks
: 1596946731:0;mv adapters adapter_bert_base
: 1596946763:0;mv adapters_networks adapters
: 1596946779:0;mv adapter_* adapters
: 1596946783:0;cd adapters
: 1596946796:0;mv adapter_big adapter_bert_large
: 1596946806:0;mkdir subsampling
: 1596946814:0;mv 0.* subsampling
: 1596946845:0;rm seeds
: 1596946849:0;rm -r seeds
: 1596946870:0;rm 1.0*/checkpoint*
: 1596946876:0;rm -r 1.0*/checkpoint*
: 1596946896:0;rm -r *_pct*/checkpoint*
: 1596946912:0;rm -r albert-base-v1-mnli
: 1596946940:0;python3 evaluate_heur_output.py ~/experiments/big_small/bert_large/hans_predictions.txt
: 1596947401:0;rm *.csv
: 1596947412:0;mv meta_2 meta
: 1596947424:0;mv meta_2_large meta
: 1596947432:0;ls meta*
: 1596947445:0;mv meta_2 bert_base
: 1596947455:0;mv meta_2_large bert_large
: 1596951434:0;pip unsintall wandb
: 1596951592:0;mkdir meta/bert_small
: 1596951594:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_small/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 8192 --num_update_steps 1 --num_tasks 1
: 1596951757:0;exit
: 1596952073:0;rm -r experiments/meta/bert_large
: 1596952087:0;mkdir bert_large
: 1596952103:0;rm -r bert_small
: 1596952240:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 16384 --num_update_steps 1 --num_tasks 1
: 1596957535:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_base/epoch_1/hans_predictions.txt
: 1596957649:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_base/epoch_2/hans_predictions.txt
: 1596957687:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_base/epoch_3/hans_predictions.txt
: 1596957696:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_base/epoch_4/hans_predictions.txt
: 1596957705:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_base/epoch_5/hans_predictions.txt
: 1596957714:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_base/epoch_6/hans_predictions.txt
: 1596958236:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_roberta_big/epoch_3/hans_predictions.txt
: 1596958254:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_big/epoch_3/hans_predictions.txt
: 1596958265:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_large/epoch_3/hans_predictions.txt
: 1596958283:0;python3 evaluate_heur_output.py ~/experiments/adapters/adapter_bert_large/epoch_2/hans_predictions.txt
: 1596961737:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_1.txt
: 1596961838:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_3.txt
: 1596961860:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_7.txt
: 1596961879:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_15.txt
: 1596961899:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_31.txt
: 1596961939:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_63.txt
: 1596961966:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_127.txt
: 1596962011:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_255.txt
: 1596962049:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_511.txt
: 1596962082:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_1023.txt
: 1596962152:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_2047.txt
: 1596962190:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_4095.txt
: 1596962259:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 4095 --num_update_steps 1 --num_tasks 1
: 1596962267:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 4096 --num_update_steps 1 --num_tasks 1
: 1596971680:0;rm -r albert_large
: 1596971686:0;rm -r bert_large
: 1596974430:0;python3 reptile_few_shot.py   --model_name_or_path albert-large-v2  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/albert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name albert_large_mnli_hans --max_sample_limit 16384 --num_update_steps 1 --num_tasks 1
: 1596974444:0;python3 reptile_few_shot.py   --model_name_or_path albert-large-v2  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/albert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name albert_large_mnli_hans --max_sample_limit 16384 --num_update_steps 1 --num_tasks 1 --overwrite_cache
: 1596977420:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 16384 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1596977501:0;python3 reptile_few_shot.py   --model_name_or_path albert-large-v2  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/albert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name albert_large_mnli_hans --max_sample_limit 16384 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1596986403:0;nohup
: 1596986813:0;echo "python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 64   --per_device_train_batch_size 450  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese_2_one_mlp --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased --evaluate_during_training --eval_steps 100" >> hup.sh
: 1596986897:0;mkdir bert_base
: 1596986905:0;mv epoch* bert_base
: 1596986913:0;mv hans bert_base
: 1596987128:0;nohup ./hup.sh > siamese_result.txt
: 1596987136:0;nohup hup.sh > siamese_result.txt
: 1596987167:0;nohup hup.sh 
: 1596987194:0;nohup ./hup.sh 
: 1596987197:0;nohup ./hup
: 1596987399:0;chmod +x hup.sh
: 1597027481:0;cat eval_results_mnli
: 1597029665:0;nvidia-smi
: 1597036363:0;cat epoch_1/eval_results_mnli-mm.txt
: 1597036368:0;cat epoch_2/eval_results_mnli-mm.txt
: 1597036378:0;rm epoch_2
: 1597036517:0;cd epoch_1
: 1597036525:0;cat training_args.bin
: 1597036531:0;vim training_args.bin
: 1597036644:0;for epoch in 1 2 3; do python3 train_siamese.py   --model_name /home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --task_name MNLI --do_eval   --data_dir /home/nlp/data/glue_data/MNLI   --max_seq_length 64   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_large/"epoch_"$((epoch+1)) --per_device_eval_batch_size 128 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done\

: 1597036736:0;for epoch in 1 2 3; do python3 train_siamese.py   --model_name /home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --task_name MNLI --do_eval   --data_dir /home/nlp/data/glue_data/MNLI   --max_seq_length 64   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_large/"epoch_"$((epoch+1)) --per_device_eval_batch_size 128 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased --model_weights_path /home/nlp/experiments/siamese/bert_large/"epoch_"$epoch; done\

: 1597038263:0;for epoch in 1 2 3; do python3 train_siamese.py   --model_name bert-large-uncased --task_name MNLI --do_eval   --data_dir /home/nlp/data/glue_data/MNLI   --max_seq_length 64   --per_device_train_batch_size 196  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_large/"epoch_"$((epoch+1)) --per_device_eval_batch_size 196 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased --model_weights_path /home/nlp/experiments/siamese/bert_large/"epoch_"$epoch; done\

: 1597038341:0;for epoch in 1 2 3; do python3 train_siamese.py   --model_name bert-large-uncased --task_name MNLI --do_eval   --data_dir /home/nlp/data/glue_data/MNLI   --max_seq_length 64   --per_device_train_batch_size 156  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_large/"epoch_"$((epoch+1)) --per_device_eval_batch_size 128 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased --model_weights_path /home/nlp/experiments/siamese/bert_large/"epoch_"$epoch; done\

: 1597038411:0;for epoch in 1 2 3; do python3 train_siamese.py   --model_name bert-large-uncased --task_name MNLI --do_eval   --data_dir /home/nlp/data/glue_data/MNLI   --max_seq_length 64   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_large/"epoch_"$((epoch+1)) --per_device_eval_batch_size 128 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased --model_weights_path /home/nlp/experiments/siamese/bert_large/"epoch_"$epoch; done\

: 1597038748:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_2.txt
: 1597038760:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_16.txt
: 1597038778:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_32.txt
: 1597038788:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_64.txt
: 1597038797:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_128.txt
: 1597038818:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_256.txt
: 1597038833:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_512.txt
: 1597038852:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_1024.txt
: 1597038936:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large/hans_predictions_8192.txt
: 1597047702:0;for epoch in 1 2 3; do python3 train_siamese.py   --model_name bert-large-uncased --task_name MNLI --do_eval   --data_dir /home/nlp/data/glue_data/MNLI   --max_seq_length 64   --per_device_train_batch_size 128  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_large/"epoch_"$((epoch+1)) --per_device_eval_batch_size 128 --do_train --fp16 --config_name bert-large-uncased --tokenizer_name bert-large-uncased --model_weights_path /home/nlp/experiments/siamese/bert_large/epoch_3/checkpoint-500\

: 1597062192:0;for epoch in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --model_weights_path=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased; done
: 1597062259:0;for epoch in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --model_weights_path=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1597062306:0;for epoch in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --model_weights_path=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased --overwrite_cache; done
: 1597062689:0;for epoch in 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --model_weights_path=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1597065338:0;cd ../../data/hans
: 1597065503:0;cat experiments/siamese/bert_large/epoch_1/eval_results_mnli.txt 
: 1597065519:0;cat experiments/siamese/bert_large/epoch_1/eval_results_mnli-mm.txt 
: 1597065531:0;cat experiments/siamese/bert_large/epoch_2/eval_results_mnli.txt 
: 1597065542:0;cat experiments/siamese/bert_large/epoch_2/eval_results_mnli-mm.txt 
: 1597065555:0;cat experiments/siamese/bert_large/epoch_3/eval_results_mnli.txt 
: 1597065585:0;cat experiments/siamese/bert_large/epoch_3/eval_results_mnli-mm.txt 
: 1597065594:0;cat experiments/siamese/bert_large/epoch_4/eval_results_mnli.txt 
: 1597065603:0;cat experiments/siamese/bert_large/epoch_4/eval_results_mnli-mm.txt 
: 1597065678:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_1/hans_predictions.txt
: 1597065714:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_2/hans_predictions.txt
: 1597065753:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_3/hans_predictions.txt
: 1597065793:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_4/hans_predictions.txt
: 1597112157:0;ls experiments/siamese/bert_large
: 1597112165:0;ls experiments/siamese/bert_large/epoch_8
: 1597113344:0;git commit -m "many changes; updated code"
: 1597113484:0;cat ../experiments/siamese/bert_large/epoch_5/eval_results_mnli.txt 
: 1597113498:0;cat ../experiments/siamese/bert_large/epoch_5/eval_results_mnli-mm.txt 
: 1597113509:0;cat ../experiments/siamese/bert_large/epoch_6/eval_results_mnli.txt 
: 1597113517:0;cat ../experiments/siamese/bert_large/epoch_6/eval_results_mnli-mm.txt 
: 1597113528:0;cat ../experiments/siamese/bert_large/epoch_7/eval_results_mnli.txt 
: 1597113537:0;cat ../experiments/siamese/bert_large/epoch_7/eval_results_mnli-mm.txt 
: 1597113546:0;cat ../experiments/siamese/bert_large/epoch_8/eval_results_mnli.txt 
: 1597113554:0;cat ../experiments/siamese/bert_large/epoch_8/eval_results_mnli-mm.txt 
: 1597113783:0;for epoch in 5 6 7 8; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch --model_weights_path=/home/nlp/experiments/siamese/bert_large/"epoch_"$epoch/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1597115730:0;ls experiments/siamese/bert_large/epoch_8/
: 1597115739:0;ls experiments/siamese/bert_large/epoch_/
: 1597115743:0;ls experiments/siamese/bert_large/epoch_7/
: 1597116730:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_5/hans_predictions.txt
: 1597116822:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_6/hans_predictions.txt
: 1597116856:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_7/hans_predictions.txt
: 1597116894:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/epoch_8/hans_predictions.txt
: 1597290826:0;mkdir check && cd check
: 1597290831:0;wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-128_A-2.zip
: 1597290975:0;unzip uncased_L-2_H-128_A-2.zip
: 1597290988:0;export BERT_BASE_DIR=/home/nlp/check/uncased_L-2_H-128_A-2\
\
transformers-cli convert --model_type bert \\
  --tf_checkpoint $BERT_BASE_DIR/bert_model.ckpt \\
  --config $BERT_BASE_DIR/bert_config.json \\
  --pytorch_dump_output $BERT_BASE_DIR/pytorch_model.bin
: 1597291077:0;pip install tensorflow
: 1597291668:0;ls experiments/big_small/bert_base
: 1597291745:0;rm -r */chec*
: 1597291773:0;cd albert_large
: 1597291870:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_large/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 108 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 108 --do_train; done
: 1597291878:0;cd bert_sm
: 1597291897:0;mv *.bin epoch_3
: 1597291902:0;mv *.json epoch_3
: 1597291907:0;mv *.txt epoch_3
: 1597291934:0;mkdir epoch_3
: 1597291936:0;mv * epoch_3
: 1597291942:0;cd epoch_3
: 1597291994:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_base/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597292056:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_base/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train --overwrite_cache
: 1597292867:0;mkdir bert_tiny
: 1597292874:0;mv pytorch_model.bin bert_tiny
: 1597292882:0;mv bert_config.json bert_tiny
: 1597292893:0;mv vocab.txt bert_tiny
: 1597292903:0;rm uncased_L-2_H-128_A-2.zip
: 1597292933:0;mv bert_tiny ../experiments
: 1597292940:0;rm -r check
: 1597292957:0;mkdir google_bert
: 1597292965:0;mv bert_tiny/ google_bert
: 1597292986:0;mkdir bert_mini
: 1597292992:0;wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-256_A-4.zip
: 1597293055:0;cd bert_tiny
: 1597293884:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_large/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_large/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597293901:0;unzip uncased_L-4_H-256_A-4.zip
: 1597294010:0;rm uncased_L-4_H-256_A-4.zip
: 1597294036:0;mkdir bert_small
: 1597294040:0;cd bert_
: 1597294051:0;wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-512_A-8.zip
: 1597296564:0;unzip uncased_L-4_H-512_A-8.zip
: 1597296573:0;rm uncased_L-4_H-512_A-8.zip
: 1597296637:0;mkdir bert_medium
: 1597296644:0;wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-8_H-512_A-8.zip
: 1597296672:0;unzip uncased_L-8_H-512_A-8.zip
: 1597296725:0;transformers-cli convert --model_type bert --tf_checkpoint bert_model.ckpt --config bert_config.json --pytorch_dump_output pytorch_model.bin
: 1597296900:0;rm uncased_L-8_H-512_A-8.zip
: 1597296914:0;cd bert_mini
: 1597296927:0;cd bert_small
: 1597296932:0;mv bert_config.json config.json
: 1597296942:0;rm bert_model.ckpt.*
: 1597296953:0;cd bert_medium
: 1597297091:0;pip uninstall tensorflow
: 1597297497:0;transformers-cli upload bert_small
: 1597297520:0;transformers-cli upload bert_tiny
: 1597297881:0;transformers-cli s3 rm bert_small
: 1597297890:0;transformers-cli s3 rm bert_tiny
: 1597297896:0;transformers-cli s3 rm bert_medium
: 1597297924:0;transformers-cli s3 rm saved_models
: 1597297959:0;transformers-cli s3 rm prajjwal1/saved_models
: 1597297968:0;transformers-cli s3 rm prajjwal1/bert_medium
: 1597297977:0;transformers-cli s3 rm prajjwal1/bert_tiny
: 1597300757:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_large/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597300859:0;mv bert_medium/ bert-medium
: 1597300873:0;mv bert_mini bert-mini
: 1597300879:0;mv bert_small bert-small
: 1597300884:0;mv bert_tiny bert-tiny
: 1597300900:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_large/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_large/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597301202:0;cp README.md bert-medium
: 1597301206:0;cp README.md bert-mini
: 1597301209:0;cp README.md bert-small
: 1597301212:0;cp README.md bert-tiny
: 1597301226:0;transformers-cli upload bert-small
: 1597301301:0;transformers-cli upload bert-tiny
: 1597301318:0;transformers-cli upload bert-medium
: 1597301357:0;transformers-cli upload bert-mini
: 1597301428:0;cp big_small/roberta_base google_bert/
: 1597301435:0;cp -r big_small/roberta_base google_bert/
: 1597301453:0;cp -r big_small/roberta_large google_bert/
: 1597301572:0;rm -r epoch_1
: 1597301574:0;rm -r epoch_2
: 1597301576:0;rm -r epoch_3
: 1597301595:0;mv epoch_4/ .
: 1597301598:0;mv epoch_4/ ..
: 1597301613:0;mv epoch_4/* roberta_base
: 1597301625:0;mv epoch_4/ roberta_base
: 1597301692:0;mv epoch_4/* .
: 1597301725:0;mv epoch_4/*
: 1597301751:0;cd epoch_4
: 1597301766:0;rm epoch_4
: 1597301792:0;cp ../big_small/roberta_base/epoch_3/* roberta_base
: 1597301798:0;cd roberta_base
: 1597301803:0;rm -r epoch_4
: 1597301853:0;rm merges.txt
: 1597301874:0;mv roberta_base roberta-base-mnli
: 1597301880:0;cp README.md roberta-base-mnli
: 1597301890:0;cd roberta-base-mnli
: 1597302284:0;cp roberta-base-mnli/README.md roberta_large
: 1597302296:0;mv roberta_large roberta-large-mnli
: 1597302301:0;cd roberta-large-mnli
: 1597302325:0;mv epoch_3/* .
: 1597302329:0;rm -r epoch_*
: 1597302347:0;cat eval_results_mnli.txt
: 1597302367:0;rm -r *.txt
: 1597302371:0;rm -r training_args.bin
: 1597302531:0;transformers-cli upload roberta-large-mnli
: 1597302675:0;vim roberta-base-mnli/README.md
: 1597302701:0;transformers-cli upload roberta-base-mnli/README.md
: 1597302715:0;transformers-cli upload roberta-base-mnli
: 1597303029:0;ls roberta-base-mnli
: 1597304625:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/albert_base/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/albert_base/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597305906:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_base/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_base/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597307185:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/roberta_large/epoch_3 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/roberta_large/epoch_4   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597308168:0;ls roberta_base
: 1597309442:0;python3 run_glue.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_tiny/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1597310222:0;for epoch in 1 2 3; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_tiny/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_tiny/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1597312371:0;python3 run_glue.py   --model_name_or_path prajjwal1/bert-mini --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_mini/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1597312612:0;for epoch in 1 2 3; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_mini/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_mini/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1597313603:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_base/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597313635:0;python3 run_glue.py   --model_name_or_path prajjwal1/bert-small --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_small/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1597314245:0;for epoch in 1 2 3; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_small/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_small/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1597314280:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_1 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_base/epoch_2   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597315667:809;python3 run_glue.py   --model_name_or_path prajjwal1/bert-medium --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_medium/epoch_1   --fp16 --per_device_eval_batch_size 512 --do_train
: 1597316669:0;for epoch in 1 2 3; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_medium/"epoch_"$epoch --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_medium/"epoch_"$((epoch+1))   --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1597316728:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597316804:0;cd exbert
: 1597316808:0;cd server
: 1597316839:0;cd server/data_processing
: 1597317064:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 96 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_large/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597318467:0;ls albert_base
: 1597318470:0;ls albert_large
: 1597318480:0;ls bert_large
: 1597318509:0;ls bert_medium
: 1597318512:0;ls bert_tiny
: 1597318515:0;ls bert_small
: 1597318521:0;ls bert_mini
: 1597318535:0;vim hans/run_hans.py
: 1597319202:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/roberta_large/epoch_3 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/roberta_large/epoch_3 --tokenizer_name roberta-large
: 1597319334:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_tiny/epoch_1 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_tiny/epoch_1 --overwrite_cache
: 1597319404:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_tiny/epoch_1 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_tiny/epoch_1
: 1597319566:0;vim ../../experiments/big_small/bert_tiny/epoch_1/hans_predictions.txt
: 1597322379:0;rm .git/ORIG_HEAD
: 1597322408:0;rm -r .git/ORIG_HEAD
: 1597322424:0;cd .git
: 1597322430:0;rm ORIG_HEAD.lock
: 1597322519:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/big_small/bert_large/epoch_1 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 96   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/big_small/bert_large/epoch_2   --fp16 --per_device_eval_batch_size 128 --do_train
: 1597322540:0;git branch typo_fix_modeling_utils
: 1597322545:0;git checkout typo_fix_modeling_utils
: 1597322560:0;vim src/transformers/modeling_utils.py
: 1597322594:0;git add src/transformers/modeling_utils.py
: 1597322603:0;git commit -m "typo fix"
: 1597322613:0;git push origin typo_fix_modeling_utils
: 1597376275:0;cat albert_base/epoch_1/eval_results_mnli.txt
: 1597376299:0;cat albert_base/epoch_1/eval_results_mnli-mm.txt
: 1597376324:0;cat albert_base/epoch_2/eval_results_mnli.txt
: 1597376334:0;cat albert_base/epoch_2/eval_results_mnli-mm.txt
: 1597376342:0;cat albert_base/epoch_3/eval_results_mnli.txt
: 1597376350:0;cat albert_base/epoch_3/eval_results_mnli-mm.txt
: 1597376359:0;cat albert_base/epoch_4/eval_results_mnli.txt
: 1597376380:0;cat albert_base/epoch_4/eval_results_mnli-mm.txt
: 1597376412:0;cat albert_large/epoch_1/eval_results_mnli.txt
: 1597376442:0;cat albert_large/epoch_1/eval_results_mnli-mm.txt
: 1597376450:0;cat albert_large/epoch_2/eval_results_mnli.txt
: 1597376457:0;cat albert_large/epoch_2/eval_results_mnli-mm.txt
: 1597376469:0;cat albert_large/epoch_3/eval_results_mnli.txt
: 1597376480:0;cat albert_large/epoch_3/eval_results_mnli-mm.txt
: 1597376501:0;cat albert_large/epoch_4/eval_results_mnli.txt
: 1597376573:0;cat albert_large/epoch_4/eval_results_mnli-mm.txt
: 1597376588:0;cat bert_base/epoch_1/eval_results_mnli.txt
: 1597376619:0;cat bert_base/epoch_1/eval_results_mnli-mm.txt
: 1597376631:0;cat bert_base/epoch_2/eval_results_mnli.txt
: 1597376639:0;cat bert_base/epoch_2/eval_results_mnli-mm.txt
: 1597376648:0;cat bert_base/epoch_3/eval_results_mnli.txt
: 1597376655:0;cat bert_base/epoch_3/eval_results_mnli-mm.txt
: 1597376674:0;cat bert_base/epoch_4/eval_results_mnli.txt
: 1597376681:0;cat bert_base/epoch_4/eval_results_mnli-mm.txt
: 1597376701:0;cat bert_large/epoch_1/eval_results_mnli.txt
: 1597376752:0;cat bert_large/epoch_1/eval_results_mnli-mm.txt
: 1597376762:0;cat bert_large/epoch_2/eval_results_mnli.txt
: 1597376776:0;cat bert_large/epoch_2/eval_results_mnli-mm.txt
: 1597376788:0;cat bert_large/epoch_3/eval_results_mnli.txt
: 1597376802:0;cat bert_large/epoch_3/eval_results_mnli-mm.txt
: 1597376812:0;cat bert_large/epoch_4/eval_results_mnli.txt
: 1597376823:0;cat bert_large/epoch_4/eval_results_mnli-mm.txt
: 1597381007:0;cd experiments/big_small
: 1597381023:0;cat roberta_base/epoch_1/eval_results_mnli.txt
: 1597381106:0;cat roberta_base/epoch_1/eval_results_mnli-mm.txt
: 1597381118:0;cat roberta_base/epoch_2/eval_results_mnli.txt
: 1597381125:0;cat roberta_base/epoch_2/eval_results_mnli-mm.txt
: 1597381132:0;cat roberta_base/epoch_3/eval_results_mnli.txt
: 1597381145:0;cat roberta_base/epoch_3/eval_results_mnli-mm.txt
: 1597381153:0;cat roberta_base/epoch_4/eval_results_mnli.txt
: 1597381160:0;cat roberta_base/epoch_4/eval_results_mnli-mm.txt
: 1597381182:0;cat roberta_large/epoch_1/eval_results_mnli.txt
: 1597381221:0;cat roberta_large/epoch_1/eval_results_mnli-mm.txt
: 1597381446:0;cat roberta_large/epoch_2/eval_results_mnli.txt
: 1597381482:0;cat roberta_large/epoch_2/eval_results_mnli-mm.txt
: 1597381492:0;cat roberta_large/epoch_3/eval_results_mnli.txt
: 1597381500:0;cat roberta_large/epoch_3/eval_results_mnli-mm.txt
: 1597381511:0;cat roberta_large/epoch_4/eval_results_mnli.txt
: 1597381519:0;cat roberta_large/epoch_4/eval_results_mnli-mm.txt
: 1597381577:0;cat bert_tiny/epoch_1/eval_results_mnli.txt
: 1597381589:0;cat bert_tiny/epoch_1/eval_results_mnli-mm.txt
: 1597381598:0;cat bert_tiny/epoch_2/eval_results_mnli.txt
: 1597381604:0;cat bert_tiny/epoch_2/eval_results_mnli-mm.txt
: 1597381611:0;cat bert_tiny/epoch_3/eval_results_mnli.txt
: 1597381619:0;cat bert_tiny/epoch_3/eval_results_mnli-mm.txt
: 1597381628:0;cat bert_tiny/epoch_4/eval_results_mnli.txt
: 1597381637:0;cat bert_tiny/epoch_4/eval_results_mnli-mm.txt
: 1597381700:0;for epoch in 1 2 3 4; do cat bert_tiny/"epoch_"$epoch/eval_results_mnli-mm.txt; done
: 1597381791:0;for epoch in 1 2 3 4; do cat bert_tiny/"epoch_"$epoch/eval_results_mnli.txt; done
: 1597381855:0;for epoch in 1 2 3 4; do cat bert_mini/"epoch_"$epoch/eval_results_mnli.txt; done
: 1597381880:0;for epoch in 1 2 3 4; do cat bert_mini/"epoch_"$epoch/eval_results_mnli-mm.txt; done
: 1597382072:0;for epoch in 1 2 3 4; do cat bert_small/"epoch_"$epoch/eval_results_mnli.txt; done
: 1597382092:0;for epoch in 1 2 3 4; do cat bert_small/"epoch_"$epoch/eval_results_mnli-mm.txt; done
: 1597382221:0;for epoch in 1 2 3 4; do cat bert_medium/"epoch_"$epoch/eval_results_mnli.txt; done
: 1597382242:0;for epoch in 1 2 3 4; do cat bert_medium/"epoch_"$epoch/eval_results_mnli-mm.txt; done
: 1597382344:0;vim evaluate_heur_output.py
: 1597382407:0;python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/epoch_1/hans_predictions.txt
: 1597384109:0;for epoch in 1 2 3 4; do cat python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384122:0;for epoch in 1 2 3 4; do python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384199:0;for epoch in 1 2 3 4; echo "Epoch " $epoch; do python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384209:0;for epoch in 1 2 3 4; do echo "Epoch " $epoch; do python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384235:0;for epoch in 1 2 3 4; do "Echo " $epoch & python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384249:0;for epoch in 1 2 3 4; do echo "Echo " $epoch & python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384265:0;for epoch in 1 2 3 4; do echo $epoch & python3 evaluate_heur_output.py ~/experiments/big_small/bert_tiny/"epoch_"$epoch/hans_predictions.txt; done
: 1597384325:0;for epoch in 1 2 3 4; do echo $epoch & python3 evaluate_heur_output.py ~/experiments/big_small/bert_mini/"epoch_"$epoch/hans_predictions.txt; done
: 1597384473:0;for epoch in 1 2 3 4; do echo $epoch  python3 evaluate_heur_output.py ~/experiments/big_small/bert_mini/"epoch_"$epoch/hans_predictions.txt; done
: 1597384486:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/bert_mini/"epoch_"$epoch/hans_predictions.txt; done
: 1597384518:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/bert_small/"epoch_"$epoch/hans_predictions.txt; done
: 1597385199:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/bert_medium/"epoch_"$epoch/hans_predictions.txt; done
: 1597385410:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/bert_base/"epoch_"$epoch/hans_predictions.txt; done
: 1597385683:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_large/epoch_2 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_large/epoch_2
: 1597385873:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/bert_large/"epoch_"$epoch/hans_predictions.txt; done
: 1597386017:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/albert_base/"epoch_"$epoch/hans_predictions.txt; done
: 1597386192:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/albert_large/"epoch_"$epoch/hans_predictions.txt; done
: 1597386715:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/roberta_base/"epoch_"$epoch/hans_predictions.txt; done
: 1597387151:0;for epoch in 1 2 3 4; do echo $epoch && python3 evaluate_heur_output.py ~/experiments/big_small/roberta_large/"epoch_"$epoch/hans_predictions.txt; done
: 1597641607:0;rm -r apex
: 1597669075:0;python3 run_maml_glue.py  --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 128   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/fluence_exp/   --overwrite_output_dir --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR --task_list mrpc --eval_task_list sts-b --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name check --eval_method every_2
: 1597669125:0;python3 reptile_few_shot.py   --model_name_or_path albert-large-v2  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/albert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=10000 --num_train_epochs=1 --output_file_name albert_large_mnli_hans --max_sample_limit 8072 m_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1597669190:0;python3 reptile_few_shot.py   --model_name_or_path albert-large-v2  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/albert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=500 --num_train_epochs=1 --output_file_name albert_large_mnli_hans --max_sample_limit 8072 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1597669297:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path albert-large-v2  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/albert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=500 --num_train_epochs=1 --output_file_name albert_large_mnli_hans --max_sample_limit 8072 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1597669577:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bet-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=500 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 8072 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1597669599:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=500 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 8072 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir
: 1597670225:0;rm -r pytorch
: 1597670454:0;cp reptile_glue.py
: 1597670459:0;vim reptile_glue.py
: 1597670503:0;cp reptile_few_shot.py reptile_few_shot_optuna.py
: 1597670512:0;vim reptile_few_shot_optuna.py
: 1597674887:0;cp bert_large bert_large_1
: 1597674939:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=500 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 2048 --overwrite_output_dir --step_size 0.04
: 1597674972:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=500 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 2048 --overwrite_output_dir --step_size=0.04
: 1597677167:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_2.txt
: 1597677283:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_4.txt
: 1597677305:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_8.txt
: 1597677386:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_16.txt
: 1597677419:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_32.txt
: 1597677454:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_64.txt
: 1597677489:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_128.txt
: 1597677522:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_256.txt
: 1597677548:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_512.txt
: 1597677570:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_1024.txt
: 1597677605:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_1/hans_predictions_2048.txt
: 1597677668:0;cd ../../../experiments/meta
: 1597677674:0;rm -r bert_large_1
: 1597677683:0;rm -rf pytorch
: 1597679086:0;cp -r bert_large bert_large_1
: 1597679215:0;mv bert_large_1 bert_large_2
: 1597679241:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_2
: 1597679244:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_2.txt
: 1597679249:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_4.txt
: 1597679252:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_8.txt
: 1597679256:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_16.txt
: 1597679484:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_128.txt
: 1597679514:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_256.txt
: 1597679559:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_512.txt
: 1597679589:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_1024.txt
: 1597679637:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_2048.txt
: 1597725226:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 2048 --overwrite_output_dir --step_size=0.004
: 1597729329:0;cp -r bert_large bert_large_3
: 1597729374:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_large_mnli_hans --max_sample_limit 2048 --overwrite_output_dir --step_size=0.0004
: 1597734122:0;cp -r bert_large bert_large_4
: 1597734384:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base_6/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_base_mnli_hans --max_sample_limit 2048 --overwrite_output_dir --step_size=0.4
: 1597736389:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base_7/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_base_mnli_hans --max_sample_limit 2048 --step_size=0.04
: 1597739767:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base_9/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_base_mnli_hans --max_sample_limit 2048 --step_size=0.004
: 1597739800:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base_8/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_base_mnli_hans --max_sample_limit 2048 --step_size=0.004
: 1597744717:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base_9/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_base_mnli_hans --max_sample_limit 2048 --step_size=0.0004
: 1597758479:0;cd exxperiments/
: 1597758498:0;cd bert-tiny
: 1597758521:0;mv bert_mini bert-mini-mnli
: 1597758531:0;mv bert_medium/ bert-medium-mnli
: 1597758542:0;mv bert_small bert-small-mnli
: 1597758558:0;mv bert_tiny bert-tiny-mnli
: 1597758591:0;cat bert-mini-mnli/epoch_4
: 1597758597:0;cat bert-mini-mnli/epoch_4/eval_results_mnli.txt
: 1597758649:0;cp big_small/bert-tiny-mnli/epoch_4 google_bert/bert-tiny-mnli
: 1597758659:0;cp -r big_small/bert-tiny-mnli/epoch_4 google_bert/bert-tiny-mnli
: 1597758677:0;cp -r big_small/bert-mini-mnli/epoch_4 google_bert/bert-mini-mnli
: 1597758688:0;cp -r big_small/bert-small-mnli/epoch_4 google_bert/bert-small-mnli
: 1597758704:0;cp -r big_small/bert-medium-mnli/epoch_4 google_bert/bert-medium-mnli
: 1597758731:0;cat bert-tiny-mnli/eval_results_mnli.txt
: 1597758746:0;cd google_bert
: 1597758756:0;cp README.md bert-tiny-mnli
: 1597758820:0;cat bert-tiny-mnli/eval_results_mnli-mm.txt
: 1597758865:0;cp README.md bert-small-mnli
: 1597758894:0;cat bert-small-mnli/eval_results_mnli-mm.txt
: 1597758957:0;cp README.md bert-medium-mnli
: 1597758964:0;cat bert-small-mnli/eval_results_mnli.txt
: 1597758976:0;vim bert-medium-mnli/README.md
: 1597758988:0;cat bert-medium-mnli/eval_results_mnli.txt
: 1597759022:0;cat bert-medium-mnli/eval_results_mnli-mm.txt
: 1597759084:0;cp REEADME.md bert-mini-mnli
: 1597759091:0;cp README.md bert-mini-mnli
: 1597759100:0;vim bert-mini-mnli/README.md
: 1597759123:0;cat bert-mini-mnli/eval_results_mnli.txt
: 1597759133:0;cat bert-mini-mnli/eval_results_mnli-mm.txt
: 1597759183:0;vim bert-tiny-mnli/README.md
: 1597759203:0;vim bert-small-mnli/README.md
: 1597759250:0;cd bert-tiny-mnli
: 1597759255:0;rm eval_results_mnli-mm.txt
: 1597759279:0;transformers-cli upload bert-tiny-mnli
: 1597759328:0;transformers-cli upload bert-small-mnli
: 1597759381:0;cd bert-mini-mnli
: 1597759400:0;transformers-cli upload bert-mini-mnli
: 1597759522:0;cd bert-small-mnli
: 1597759534:0;cd bert-medium-mnli
: 1597759539:0;rm hans_predictions.txt
: 1597759546:0;rm eval*
: 1597759558:0;transformers-cli upload bert-medium-mnli
: 1597765327:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_2.txt
: 1597766868:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_4.txt
: 1597766874:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_8.txt
: 1597766880:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_16.txt
: 1597766896:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_32.txt
: 1597766928:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_64.txt
: 1597766958:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_64.txt
: 1597767001:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_4/hans_predictions_128.txt
: 1597767026:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_5/hans_predictions_128.txt
: 1597767243:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_128.txt
: 1597767281:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_256.txt
: 1597767291:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_3/hans_predictions_512.txt
: 1597767360:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_large_2/hans_predictions_32.txt
: 1597767854:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base_6/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --output_file_name bert_base_mnli_hans --max_sample_limit 2048 --step_size=0.4
: 1597767878:0;vim corere/meta_fs.py
: 1597768254:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004
: 1597768297:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir
: 1597769705:0;rm bert_large_*
: 1597769819:0;echo "CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir" << hup.sh
: 1597769824:0;echo "CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=1000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir" >> hup.sh
: 1597802555:0;cat bert_base_0004/*.csv
: 1597802561:0;cat bert_base_004/*.csv
: 1597802618:0;cat bert_base_04/*.csv
: 1597802630:0;cat bert_base_4/*.csv
: 1597802722:0;vim ../../transformers-importance-sampling/core/meta_fs.py
: 1597802758:0;vim ../../transformers-importance-sampling/reptile_few_shot
: 1597802762:0;vim ../../transformers-importance-sampling/reptile_few_shot.py
: 1597802813:0;rm bert_base_*
: 1597802817:0;rm -r bert_base_*
: 1597802828:0;rm -r bert_large_*
: 1597805812:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --num_update_steps 1 --num_tasks 1 --overwrite_output_dir --step_size=0.004
: 1597805826:0;python3 reptile_few_shot.py   --model_name_or_path bert-large-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_large/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --overwrite_output_dir --step_size=0.004
: 1597807988:0;for seed in 250 5000 3333 4200; do CUDA_VISIBLE_DEVICES=1 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/"bert_base_"$seed/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=20000 --num_train_epochs=1 --max_sample_limit 2048 --step_size 0.4 --seed $seed; done
: 1597808284:0;rm reptile_few_shot_optuna.py
: 1597808465:0;for lamb in 0.1 0.01 0.001 0.0001 0.00001; do python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 64 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/"bert_base_"$lamb  --per_device_eval_batch_size 64 --do_train --lamb $lamb --dataloader_drop_last; done
: 1597808490:0;for lamb in 0.1 0.01 0.001 0.0001 0.00001 0.000001; do python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 64 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/"bert_base_"$lamb  --per_device_eval_batch_size 64 --do_train --lamb $lamb --dataloader_drop_last; done
: 1597808577:0;for lamb in 0.1 0.01 0.001 0.0001 0.00001 0.000001; do python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/"bert_base_"$lamb  --per_device_eval_batch_size 128 --do_train --lamb $lamb --dataloader_drop_last; done
: 1597808658:0;for lamb in 0.1 0.01 0.001 0.0001 0.00001 0.000001; do python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/"bert_base_"$lamb  --per_device_eval_batch_size 256 --do_train --lamb $lamb --dataloader_drop_last; done
: 1597809809:0;vim core
: 1597811271:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4
: 1597812438:0;:wq
: 1597812985:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597816931:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 256  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597817004:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 32  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597817073:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 8  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597818838:0;pid
: 1597825425:0;vim meta_dataset.py
: 1597825456:0;vim tests/test_meta.py
: 1597829834:0;ls experiments/meta/bert_base
: 1597837041:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 8  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir
: 1597837106:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 8  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --train_task --test_task hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir
: 1597837134:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 8  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --train_task mnli --test_task hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir
: 1597837283:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 8  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_name mnli --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir
: 1597839290:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 8  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir /home/nlp/data/glue_data/MNLI --task_name mnli --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.004 --overwrite_output_dir
: 1597840939:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir /home/nlp/data/glue_data/MNLI --task_name mnli --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597841231:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-3  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir /home/nlp/data/glue_data/MNLI --task_name mnli --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597841799:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 16  --learning_rate 2e-3  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 4096 --data_dir /home/nlp/data/glue_data/MNLI --task_name mnli --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597911431:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_list mnli --eval_task_list hans --eval_steps=100 --save_steps=3000 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597911641:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597912999:0;git merge origin/master
: 1597913014:0;git checkout trainer_prepare_inputs
: 1597913026:0;git branch prepare_inputs
: 1597913041:0;git checkout prepare_inputs
: 1597913048:0;cd src/transformers
: 1597913053:0;vim trainer.py
: 1597914408:0;git commit -m "removed redundant arg in prepare_inputs"
: 1597915488:0;vim src/transformers/trainer.py
: 1597915555:0;git add src/transformers/trainer.py
: 1597915578:0;git commit -m "made same change in prediction_loop"
: 1597915584:0;git push origin prepare_inputs
: 1597915607:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR/MNLI --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=0.4 --overwrite_output_dir
: 1597919049:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 1  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 2048 --data_dir $GLUE_DIR/MNLI --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir
: 1597920030:0;python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir
: 1597920470:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir
: 1597920693:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 1 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/blah   --fp16 --per_device_eval_batch_size 128 --do_train --evaluate_during_training --eval_steps 2
: 1597920705:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 1 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/blah   --fp16 --per_device_eval_batch_size 4096 --do_train --evaluate_during_training --eval_steps 2
: 1597921135:0;CUDA_VISIBLE_DEVICES=1 python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 2 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/blah   --fp16 --per_device_eval_batch_size 4096 --do_train --evaluate_during_training --eval_steps 2
: 1597922563:0;git commit -m "new MAML implementationl improved code"
: 1597922626:0;echo "CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir" >> README.md
: 1597923229:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir
: 1597923575:0;CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/1/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir
: 1597923710:0;echo "CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/1/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir" >> README.md
: 1597923779:0;echo "CUDA_VISIBLE_DEVICES=0 python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/1/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5 --overwrite_output_dir" >> meta.sh
: 1597923966:0;vim meta2.sh
: 1597929669:0;cp meta.sh meta_3.sh
: 1597929675:0;vim meta_3.sh
: 1597929788:0;rm meta_
: 1597929793:0;rm meta_3.sh
: 1597934872:0;cat meta.sh
: 1597935875:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/1/checkpoint-2048 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/1/checkpoint-2048/
: 1597935912:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/1/checkpoint-2048 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/1/checkpoint-2048/ --tokenizer_name bert-base-uncased
: 1597936004:0;for val in 1 2 3 4 5 ; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/$val/checkpoint-2048 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/$val/checkpoint-2048/ --tokenizer_name bert-base-uncased; done
: 1597936399:0;mkdir bert_base_
: 1597936402:0;mv * bert_base_
: 1597936461:0;sh meta_2.sh
: 1597938477:0;python3 evaluate_heur_output.py ~/experiments/meta/2/checkpoint-2048/hans_predictions.txt
: 1597938488:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_base_/2/checkpoint-2048/hans_predictions.txt
: 1597938532:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_base_/3/checkpoint-2048/hans_predictions.txt
: 1597938560:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_base_/4/checkpoint-2048/hans_predictions.txt
: 1597938579:0;python3 evaluate_heur_output.py ~/experiments/meta/bert_base_/5/checkpoint-2048/hans_predictions.txt
: 1597939196:0;vim meta_2.sh
: 1597939329:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/1/checkpoint-2048 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/$val/checkpoint-2048/ --tokenizer_name bert-base-uncased; done
: 1597939347:0;for val in 1 3 ; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/$val/checkpoint-2048 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/$val/checkpoint-2048/ --tokenizer_name bert-base-uncased; done
: 1597939371:0;for val in 1 3 ; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/$val/checkpoint-2048 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/$val/checkpoint-2048/ --tokenizer_name bert-large-uncased; done
: 1597939521:0;python3 evaluate_heur_output.py ~/experiments/meta/1/checkpoint-2048/hans_predictions.txt
: 1597939660:0;python3 evaluate_heur_output.py ~/experiments/meta/3/checkpoint-2048/hans_predictions.txt
: 1597939777:0;vim core/meta_fs.py
: 1597940025:0;chmod +x meta.sh
: 1597940026:0;nohup /home/nlp/transformers-importance-sampling/meta.sh
: 1597982129:0;cd experiments/meta
: 1597982142:0;mkdir seeds
: 1597982146:0;mv * seeds
: 1597990099:0;python3 run_hans
: 1597990173:0;ls ../experiments/meta
: 1597990176:0;ls ../experiments/meta/main
: 1597990208:0;for val in 2 4 6 8 16 32 64 128 256 512 1024 2048 4096; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/main/checkpoint-$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/main/checkpoint-$val/ --tokenizer_name bert-large-uncased; done
: 1597991915:0;ls experiments/meta/main/checkpoint-512
: 1597991919:0;ls experiments/meta/main/checkpoint-1024
: 1597991923:0;ls experiments/meta/main/checkpoint-2048
: 1597991929:0;ls experiments/meta/main/checkpoint-4096
: 1597991956:0;ls ../experiments/meta/
: 1597991959:0;ls ../experiments/meta/seeds
: 1597992016:0;for val in 2 4 6 8 16 32 64 128 256 512 1024 2048 4096; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/seeds/1/checkpoint-$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/seeds/1/checkpoint-$val/ --tokenizer_name bert-large-uncased; done
: 1597992121:0;for val in 2 4 8 16 32 64 128 256 512 1024 2048 4096; do echo $val && python3 evaluate_heur_output.py ~/experiments/meta/main/checkpoint-$val/hans_predictions.txt; done
: 1597993508:0;vim meta.sh
: 1597993515:0;sh meta.sh
: 1597993736:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/meta/main/checkpoint-2048 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/meta/main/checkpoint-2048   --fp16 --per_device_eval_batch_size 4096
: 1597993751:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/meta/main/checkpoint-2048 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/meta/main/checkpoint-2048   --fp16 --per_device_eval_batch_size 4096 --tokenizer_name bert-large-uncased
: 1597993807:0;for val in 2 4 6 8 16 32 64 128 256 512 1024 2048 4096; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/meta/seeds/2/checkpoint-$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/meta/seeds/2/checkpoint-$val/ --tokenizer_name bert-large-uncased; done
: 1597993971:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/meta/main/checkpoint-4096 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/meta/main/checkpoint-4096   --fp16 --per_device_eval_batch_size 4096 --tokenizer_name bert-large-uncased
: 1597994133:0;python3 run_glue.py   --model_name_or_path /home/nlp/experiments/meta/main/checkpoint-1024 --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/meta/main/checkpoint-1024   --fp16 --per_device_eval_batch_size 4096 --tokenizer_name bert-large-uncased
: 1597994673:0;for val in 2 4 8 16 32 64 128 256 512 1024 2048 4096; do echo $val && python3 evaluate_heur_output.py ~/experiments/meta/seed/1/checkpoint-$val/hans_predictions.txt; done
: 1597994690:0;for val in 2 4 8 16 32 64 128 256 512 1024 2048 4096; do echo $val && python3 evaluate_heur_output.py ~/experiments/meta/seeds/1/checkpoint-$val/hans_predictions.txt; done
: 1597997544:0;for val in 2 4 8 16 32 64 128 256 512 1024 2048 4096; do echo $val && python3 evaluate_heur_output.py ~/experiments/meta/seeds/2/checkpoint-$val/hans_predictions.txt; done
: 1598012336:0;cd fluence/meta
: 1598012340:0;cd fluence/
: 1598012504:0;git commmit -m "fmodel"
: 1598012511:0;git commit -m "fmodel"
: 1598012572:0;git commit -m "updated code"
: 1598012671:0;cd core
: 1598012678:0;rm meta.py
: 1598012684:0;mv meta_fs.py meta.py
: 1598012744:0;git commit -m "formatting"
: 1598014012:0;cp train_orthogonal.py train_sbert.py
: 1598014287:0;python3 train_sbert.py  --model_name_or_path bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/1   --fp16 --per_device_eval_batch_size 4096
: 1598014348:0;python3 train_sbert.py  --model_name_or_path sentence_transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/1   --fp16 --per_device_eval_batch_size 4096
: 1598015507:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/1   --fp16 --per_device_eval_batch_size 4096
: 1598016165:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/2   --fp16 --per_device_eval_batch_size 4096 --model_weights_path /home/nlp/experiments/sbert/1
: 1598016189:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 4096 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/2   --fp16 --per_device_eval_batch_size 4096 --model_weights_path /home/nlp/experiments/sbert/1
: 1598016558:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 4096 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/3   --fp16 --per_device_eval_batch_size 4096 --model_weights_path /home/nlp/experiments/sbert/2
: 1598016930:0;cd ../experiments/sbert
: 1598016936:0;mkdir frozen
: 1598016940:0;mv * frozen
: 1598016945:0;ls frozen/1
: 1598017022:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 4096 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/1   --fp16 --per_device_eval_batch_size 4096
: 1598017116:0;mv frozen frozen_bert_base
: 1598017158:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 4096 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/1   --fp16 --per_device_eval_batch_size 4096
: 1598018445:0;for val in 1 2; do python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 4096 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/$((val+1))   --fp16 --per_device_eval_batch_size 4096 --model_weights_path /home/nlp/experiments/sbert/$val; done
: 1598019935:0;vim Makefile
: 1598019985:0;cd d transformers-importance-sampling/
: 1598020009:0;vim core/orthogonal_trainer.py
: 1598020164:0;rm core/orthogonal_trainer.py
: 1598020265:0;flake8 core/
: 1598020296:0;git commit -m "rm redundancy"
: 1598020315:0;vim reptile_few_shot.py
: 1598064744:0;cd experiments/sbert
: 1598064754:0;mkdir frozen_bert_large
: 1598064759:0;mv 1 frozen_bert_large
: 1598064762:0;mv 2 frozen_bert_large
: 1598064765:0;mv 3 frozen_bert_large
: 1598064825:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 4096 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/1   --fp16 --per_device_eval_batch_size 4096
: 1598064884:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/1   --fp16 --per_device_eval_batch_size 1024
: 1598064958:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/1   --fp16 --per_device_eval_batch_size 512
: 1598065131:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_large/1   --fp16 --per_device_eval_batch_size 512
: 1598068737:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_large/$((val+1))   --fp16 --per_device_eval_batch_size 512; done
: 1598068769:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_large/2   --fp16 --per_device_eval_batch_size 512 --model_weights_path /home/nlp/experiments/sbert/bert_large/1
: 1598071850:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_large/3   --fp16 --per_device_eval_batch_size 512 --model_weights_path /home/nlp/experiments/sbert/bert_large/2
: 1598085285:0;for val in 1 2 3; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/sbert/frozen_bert_base/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --tokenizer_name bert-base-uncased; done
: 1598085327:0;ls experiments/meta
: 1598085337:0;ls experiments/sbert/frozen_bert_base/1
: 1598085386:0;for val in 1 2 3; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/sbert/frozen_bert_base/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --tokenizer_name bert-base-uncased --config_; done
: 1598085507:0;cp run_hex_hans.py run_sbert_hans.py
: 1598085709:0;python3 run_hex_hans.py --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/$val; done
: 1598085762:0;for val in 1 2 3; do python3 run_hex_hans.py --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/$val; done
: 1598085859:0;for val in 1 2 3; do python3 run_sbert_hans.py --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/$val; done
: 1598086195:0;vim run_sbert_hans.py
: 1598086243:0;for val in 1 2 3; do python3 run_sbert_hans.py --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/sbert/frozen_bert_large/$val --model_weights_path /home/nlp/experiments/sbert/frozen_bert_large/$val; done
: 1598086762:0;for val in 1 2 3; do python3 run_sbert_hans.py --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/$val; done
: 1598086855:0;cat experiments/sbert/frozen_bert_base/1/eval_results_mnli.txt
: 1598086864:0;cat experiments/sbert/frozen_bert_base/1/eval_results_mnli-mm.txt
: 1598086883:0;cat experiments/sbert/frozen_bert_base/2/eval_results_mnli.txt
: 1598086892:0;cat experiments/sbert/frozen_bert_base/2/eval_results_mnli-mm.txt
: 1598086902:0;cat experiments/sbert/frozen_bert_base/3/eval_results_mnli.txt
: 1598086910:0;cat experiments/sbert/frozen_bert_base/3/eval_results_mnli-mm.txt
: 1598086966:0;cat experiments/sbert/frozen_bert_large/1/eval_results_mnli.txt
: 1598086982:0;cat experiments/sbert/frozen_bert_large/1/eval_results_mnli-mm.txt
: 1598086996:0;cat experiments/sbert/frozen_bert_large/2/eval_results_mnli.txt
: 1598087017:0;cat experiments/sbert/frozen_bert_large/2/eval_results_mnli-mm.txt
: 1598087026:0;cat experiments/sbert/frozen_bert_large/3/eval_results_mnli.txt
: 1598087033:0;cat experiments/sbert/frozen_bert_large/3/eval_results_mnli-mm.txt
: 1598087112:0;expport TASK_NAME=MNLI
: 1598087121:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/1   --fp16 --per_device_eval_batch_size 512 
: 1598087205:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 768 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/1   --fp16 --per_device_eval_batch_size 768
: 1598087271:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/1   --fp16 --per_device_eval_batch_size 512
: 1598087869:0;python3 evaluate_heur_output.py ~/experiments/sbert/frozen_bert_base/1/hans_predictions.txt
: 1598087943:0;python3 evaluate_heur_output.py ~/experiments/sbert/frozen_bert_base/2/hans_predictions.txt
: 1598088028:0;python3 evaluate_heur_output.py ~/experiments/sbert/frozen_bert_base/3/hans_predictions.txt
: 1598089103:0;for val in 1 2; do python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/bert_base/$((val+1))   --fp16 --per_device_eval_batch_size 512 --model_weights_path /home/nlp/experiments/sbert/bert_base/$val; done
: 1598089112:0;ls ../experiments/sbert
: 1598089121:0;ls ../../../experiments/sbert
: 1598091482:0;for val in 1 2 3; do python3 run_sbert_hans.py --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/sbert/bert_base/$val --model_weights_path /home/nlp/experiments/sbert/bert_base/$val; done
: 1598096381:0;python3 evaluate_heur_output.py ~/experiments/sbert/frozen_bert_large/1/hans_predictions.txt
: 1598096391:0;python3 evaluate_heur_output.py ~/experiments/sbert/frozen_bert_large/2/hans_predictions.txt
: 1598096397:0;python3 evaluate_heur_output.py ~/experiments/sbert/frozen_bert_large/3/hans_predictions.txt
: 1598096580:0;python3 evaluate_heur_output.py ~/experiments/sbert/bert_base/1/hans_predictions.txt
: 1598096872:0;python3 evaluate_heur_output.py ~/experiments/sbert/bert_base/2/hans_predictions.txt
: 1598096902:0;python3 evaluate_heur_output.py ~/experiments/sbert/bert_base/3/hans_predictions.txt
: 1598096968:0;for val in 1 2 3; do python3 run_sbert_hans.py --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/sbert/bert_large/$val --model_weights_path /home/nlp/experiments/sbert/bert_large/$val; done
: 1598096986:0;cat ../../../experiments/sbert/bert_base/1/eval_results_mnli
: 1598096989:0;cat ../../../experiments/sbert/bert_base/1/eval_results_mnli.txt
: 1598097001:0;cat ../../../experiments/sbert/bert_base/1/eval_results_mnli-mm.txt
: 1598097012:0;cat ../../../experiments/sbert/bert_base/2/eval_results_mnli.txt
: 1598097016:0;cat ../../../experiments/sbert/bert_base/2/eval_results_mnli-mm.txt
: 1598097021:0;cat ../../../experiments/sbert/bert_base/3/eval_results_mnli.txt
: 1598097024:0;cat ../../../experiments/sbert/bert_base/3/eval_results_mnli-mm.txt
: 1598097163:0;cat ../../../experiments/sbert/bert_large/1/eval_results_mnli.txt
: 1598097211:0;cat ../../../experiments/sbert/bert_large/1/eval_results_mnli-mm.txt
: 1598097219:0;cat ../../../experiments/sbert/bert_large/2/eval_results_mnli.txt
: 1598097223:0;cat ../../../experiments/sbert/bert_large/2/eval_results_mn-mmli.txt
: 1598097229:0;cat ../../../experiments/sbert/bert_large/2/eval_results_mnli-mm.txt
: 1598097241:0;cat ../../../experiments/sbert/bert_large/3/eval_results_mnli.txt
: 1598097246:0;cat ../../../experiments/sbert/bert_large/3/eval_results_mnli-mm.txt
: 1598097418:0;python3 evaluate_heur_output.py ~/experiments/sbert/bert_large/1/hans_predictions.txt
: 1598097427:0;python3 evaluate_heur_output.py ~/experiments/sbert/bert_large/2/hans_predictions.txt
: 1598097437:0;python3 evaluate_heur_output.py ~/experiments/sbert/bert_large/3/hans_predictions.txt
: 1598264014:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/0001  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps 767 --do_train --lamb 0.0001 --dataloader_drop_last --overwrite_output_dir
: 1598264030:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/0001  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps 767 --do_train --lamb 0.0001 --dataloader_drop_last
: 1598264075:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/0001  --per_device_eval_batch_size 256 --evaluate_during_training --eval_steps 383 --do_train --lamb 0.0001 --dataloader_drop_last
: 1598264286:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/0001  --per_device_eval_batch_size 768 --evaluate_during_training --eval_steps 383 --do_train --lamb 0.0001 --dataloader_drop_last
: 1598264324:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/0001  --per_device_eval_batch_size 768 --evaluate_during_training --eval_steps 340 --do_train --lamb 0.0001 --dataloader_drop_last
: 1598264380:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/orthogonal/trials/0001/1  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last
: 1598264523:0;cat bert_base_0.001
: 1598264528:0;ls bert_base_0.001
: 1598264642:0;ls orthogonal_albert
: 1598264654:0;rm orthogonal_albert/
: 1598264659:0;rm -r orthogonal_albert/
: 1598264665:0;ls orthogonal_bert_large
: 1598264693:0;rm -r orthogonal_bert_large
: 1598264702:0;cd orthogonal
: 1598264709:0;cd bert_base_0.001
: 1598264714:0;cd trials
: 1598265435:0;chmod +x hex_all.sh
: 1598270583:0;cat ../experiments/orthogonal/bert_base_0001/1/eval_results_mnli.txt
: 1598270615:0;cat ../experiments/orthogonal/bert_base_0001/2/eval_results_mnli.txt
: 1598270622:0;cat ../experiments/orthogonal/bert_base_0001/2/
: 1598270624:0;cat ../experiments/orthogonal/bert_base_0001/
: 1598270638:0;ls ../experiments/orthogonal/bert_base_0001/2/
: 1598270655:0;cd bert_base_0001/ls
: 1598270659:0;cd bert_base_0001/
: 1598270670:0;cd bert_base_0003
: 1598271782:0;ls ../experiments/orthogonal/bert_base_0002
: 1598271785:0;ls ../experiments/orthogonal/bert_base_0003
: 1598273989:0;rm pytorch_model.bin training_args.bin 
: 1598274000:0;rm special_tokens_map.json tokenizer_config.json 
: 1598274003:0;cd 1
: 1598274020:0;rm bert_base_0003
: 1598274024:0;rm -rf bert_base_0003
: 1598274026:0;rm -rf bert_base_0005
: 1598322022:0;cat bert_base_0.001/eval_results_mnli.txt
: 1598322070:0;cat bert_base_0.005/eval_results_mnli.txt
: 1598322079:0;cat bert_base_0.006/eval_results_mnli.txt
: 1598322083:0;cat bert_base_0.007/eval_results_mnli.txt
: 1598322088:0;cat bert_base_0.009/eval_results_mnli.txt
: 1598322233:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/001  --per_device_eval_batch_size 768 --do_train --lamb 0.001 --dataloader_drop_last--evaluate_during_training --eval_steps 200
: 1598322252:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.001 --dataloader_drop_last--evaluate_during_training --eval_steps 200
: 1598322262:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.001 --dataloader_drop_last --evaluate_during_training --eval_steps 200
: 1598322537:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 200
: 1598322737:0;git diff
: 1598322969:0;git clone https://github.com/huggingface/nlp.git
: 1598323281:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 50
: 1598323413:0;pip install optuna
: 1598325927:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 50 
: 1598326151:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 576 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search
: 1598327420:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   ---data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search
: 1598327444:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search
: 1598328319:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 50  
: 1598328537:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.001 --dataloader_drop_last --evaluate_during_training --eval_steps 50  
: 1598329358:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search --lamb 0.0001
: 1598329597:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search --lamb 0.0001 --do_train --do_eval
: 1598330144:0;CUDA_VISIBLE_DEVICES=0 python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search --lamb 0.0001 --do_train --do_eval --per_device_train_batch_size 512 --per_device_eval_batch_size 512
: 1598330444:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search --lamb 0.0001 --do_train --do_eval --per_device_train_batch_size 512 --per_device_eval_batch_size 512
: 1598331857:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 50  
: 1598331869:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 100  
: 1598333613:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 100  --overwrite_output_dir
: 1598333836:0;history
: 1598333907:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 100  --overwrite_output_dir
: 1598334172:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 384 --learning_rate 2e-5  --num_train_epochs 3.0   --output_dir /home/nlp/experiments/orthogonal/trials/  --per_device_eval_batch_size 768 --do_train --lamb 0.0001 --dataloader_drop_last --evaluate_during_training --eval_steps 100  --overwrite_output_dir
: 1598335062:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search --lamb 0.0001 --do_train --do_eval --per_device_train_batch_size 384 --per_device_eval_batch_size 384
: 1598335075:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 50 --hyperparam_search --lamb 0.0001 --do_train --do_eval --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir
: 1598335439:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 100 --hyperparam_search --lamb 0.0001 --do_train --do_eval --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir
: 1598335995:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 100 --hyperparam_search --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir
: 1598336070:0;rm bert_base_0.0001 bert_base_0.0003 bert_base_0.0005 bert_base_0.0007 bert_base_0.0009 bert_base_0.001 bert_base_0.003 bert_base_0.005 bert_base_0.007 bert_base_0.009 
: 1598336076:0;rm -rf bert_base_0.0001 bert_base_0.0003 bert_base_0.0005 bert_base_0.0007 bert_base_0.0009 bert_base_0.001 bert_base_0.003 bert_base_0.005 bert_base_0.007 bert_base_0.009 
: 1598336109:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 25 --hyperparam_search --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir
: 1598345551:0;nv
: 1598346251:0;ls experiments/trial
: 1598346867:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 25 --hyperparam_search --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir 
: 1598347085:0;nohup /home/nlp/transformers-importance-sampling/hup.sh
: 1598349961:0;cp hex_all.sh hex_all_2.sh
: 1598349969:0;rm hex_all_2.sh
: 1598350297:0;vim hex_all_2.sh
: 1598350310:0;sh hex_all_2.sh
: 1598350578:0;chmod +x hex_all_2.sh
: 1598350582:0;nohup /home/nlp/transformers-importance-sampling/hex_all_2.sh
: 1598355564:0;cd bert_base_0.0002
: 1598355575:0;cat eval_results_mnli-mm.txt
: 1598356066:0;cd bert_base_0.0003
: 1598356080:0;cd bert_base_0.0001
: 1598356855:0;vim ../../transformers-importance-sampling/hex_all.sh
: 1598356928:0;vim ../../transformers-importance-sampling/hex_all_2.sh
: 1598356973:0;vim ../../transformers-importance-sampling/nohup.out
: 1598410605:0;ls bert_base_0.0001
: 1598410608:0;ls bert_base_0.0002
: 1598410609:0;ls bert_base_0.0003
: 1598410611:0;ls bert_base_0.0004
: 1598410613:0;ls bert_base_0.0005
: 1598410614:0;ls bert_base_0.0006
: 1598410616:0;ls bert_base_0.0007
: 1598410618:0;ls bert_base_0.0008
: 1598410620:0;ls bert_base_0.0009
: 1598410631:0;ls bert_base_0.00002
: 1598410632:0;ls bert_base_0.00003
: 1598410633:0;ls bert_base_0.00004
: 1598410635:0;ls bert_base_0.00005
: 1598410639:0;ls bert_base_0.00006
: 1598410687:0;nohup /home/nlp/transformers-importance-sampling/hex_all.sh
: 1598415731:0;cd ../experiments/orthogonal/bert_base_000
: 1598415733:0;cd ../experiments/orthogonal/bert_base_0001
: 1598415740:0;cd ../experiments/orthogonal/bert_base_0.0001
: 1598416626:0;vim 
: 1598416632:0;vim hex_all.sh
: 1598416834:0;sh hex_all.sh
: 1598419655:0;cat ../experiments/orthogonal/bert_base_0.00001
: 1598419659:0;cat ../experiments/orthogonal/bert_base_0.00001/eval_results_mnli.txt
: 1598419664:0;cat ../experiments/orthogonal/bert_base_0.0001/eval_results_mnli.txt
: 1598419675:0;cat ../experiments/orthogonal/bert_base_0.0006/eval_results_mnli.txt
: 1598419679:0;cat ../experiments/orthogonal/bert_base_0.0002/eval_results_mnli.txt
: 1598419687:0;cat ../experiments/orthogonal/bert_base_0.0003/eval_results_mnli.txt
: 1598419692:0;cat ../experiments/orthogonal/bert_base_0.0004/eval_results_mnli.txt
: 1598419698:0;cat ../experiments/orthogonal/bert_base_0.0005/eval_results_mnli.txt
: 1598419709:0;cat ../experiments/orthogonal/bert_base_0.0007/eval_results_mnli.txt
: 1598419714:0;cat ../experiments/orthogonal/bert_base_0.0008/eval_results_mnli.txt
: 1598419719:0;cat ../experiments/orthogonal/bert_base_0.0009/eval_results_mnli.txt
: 1598420415:0;echo "python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 25 --hyperparam_search --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir " >> hup.sh
: 1598420421:0;vim hup.sh
: 1598420470:0;sh hup.sh
: 1598435721:0;mv reptile_few_shot.py maml_few_shot.py
: 1598435735:0;rm *.sh
: 1598435745:0;rm *.out
: 1598436009:0;ls ../experiments/orthogonal/bert_base_0001
: 1598436019:0;ls ../experiments/orthogonal/bert_base_0.0001
: 1598436049:0;sh run_hans_all.sh
: 1598436098:0;cd experiments/orthogonal
: 1598436115:0;ls bert_base_0.00001
: 1598436253:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/orthogonal/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/orthogonal/$val ; done
: 1598436291:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/orthogonal/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/orthogonal/$val --config_name bert-base-uncased; done
: 1598436424:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/orthogonal/$val --config_name bert-base-uncased; done
: 1598436511:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=$val --config_name bert-base-uncased; done
: 1598436551:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=$val --config_name bert-base-uncased --tokenizer_name bert-base-uncased; done
: 1598436700:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=$val --config_name bert-base-uncased --tokenizer_name bert-base-uncased --model_weights_path $val; done
: 1598437065:0;vim run_hex_hans.py
: 1598437216:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=$val --config_name bert-base-uncased --tokenizer_name bert-base-uncased --model_weights_path $val; done
: 1598437551:0;vim ../models/orthogonal_transformer.py
: 1598438248:0;cat bert_base_0.0001/eval_results_mnli.txt
: 1598438270:0;cat bert_base_0.0002/eval_results_mnli.txt
: 1598438304:0;cat bert_base_0.0003/eval_results_mnli.txt
: 1598438329:0;cat bert_base_0.0004/eval_results_mnli.txt
: 1598438347:0;cat bert_base_0.0005/eval_results_mnli.txt
: 1598438357:0;cat bert_base_0.0006/eval_results_mnli.txt
: 1598438384:0;cat bert_base_0.0007/eval_results_mnli.txt
: 1598438393:0;cat bert_base_0.0008/eval_results_mnli.txt
: 1598438412:0;cat bert_base_0.0009/eval_results_mnli.txt
: 1598438440:0;cat bert_base_0.00001/eval_results_mnli.txt
: 1598438450:0;cat bert_base_0.00002/eval_results_mnli.txt
: 1598438482:0;cat bert_base_0.00003/eval_results_mnli.txt
: 1598438497:0;cat bert_base_0.00004/eval_results_mnli.txt
: 1598438517:0;cat bert_base_0.00005/eval_results_mnli.txt
: 1598438535:0;cat bert_base_0.00006/eval_results_mnli.txt
: 1598438563:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0001/hans_predictions.txt
: 1598438864:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0002/hans_predictions.txt
: 1598439158:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0003/hans_predictions.txt
: 1598439201:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0004/hans_predictions.txt
: 1598439232:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0005/hans_predictions.txt
: 1598439635:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0006/hans_predictions.txt
: 1598439664:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0007/hans_predictions.txt
: 1598439706:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0008/hans_predictions.txt
: 1598440419:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.0009/hans_predictions.txt
: 1598440781:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.00001/hans_predictions.txt
: 1598440813:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.00002/hans_predictions.txt
: 1598440828:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.00003/hans_predictions.txt
: 1598440888:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.00004/hans_predictions.txt
: 1598440923:0;python3 evaluate_heur_output.py ~/experiments/orthogonal/bert_base_0.00005/hans_predictions.txt
: 1598495387:0;cd sbert
: 1598495510:0;python3 train_sbert.py  --model_name_or_path sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 256 --freeze_encoder
: 1598496492:0;vim datasets/siamese_dataset.py
: 1598498198:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 256 --freeze_encoder
: 1598498237:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 256 --freeze_encoder --overwrite_output_dir
: 1598501455:0;vim train_sbert.py
: 1598501512:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 512 --freeze_encoder --overwrite_output_dir --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/1
: 1598501578:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 512 --freeze_encoder --overwrite_output_dir --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/1
: 1598501620:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 512 --freeze_encoder --overwrite_output_dir --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/1 --overwrite_cache
: 1598501821:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/2   --fp16 --per_device_eval_batch_size 512 --freeze_encoder --overwrite_output_dir --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/1 --do_train
: 1598501895:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/1   --fp16 --per_device_eval_batch_size 512 --freeze_encoder --overwrite_output_dir
: 1598504608:0;for val in 1 2 3; do python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_base/$((val+1))   --fp16 --per_device_eval_batch_size 512 --freeze_encoder --overwrite_output_dir --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/$val; done
: 1598506615:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_large/1   --fp16 --per_device_eval_batch_size 256 --freeze_encoder --overwrite_output_dir
: 1598506626:0;python3 train_sbert.py  --model_name sentence-transformers/bert-base-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_large/1   --fp16 --per_device_eval_batch_size 256 --freeze_encoder
: 1598507379:0;python3 train_sbert.py  --model_name sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_large/1   --fp16 --per_device_eval_batch_size 256 --freeze_encoder --overwrite_output_dir
: 1598508935:0;vim models/sbert.py
: 1598509593:0;for val in 1 2; do python3 train_sbert.py  --model_name sentence-transformers/bert-large-nli-mean-tokens --task_name $TASK_NAME   --do_train --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/sbert/frozen_bert_large/$((val+1))   --fp16 --per_device_eval_batch_size 256 --freeze_encoder --overwrite_output_dir --model_weights_path /home/nlp/experiments/sbert/frozen_bert_large/$val; done
: 1598512678:0;rm siamese_model.py
: 1598512698:0;mv sbert.py siamese_model.py
: 1598512723:0;rm train_sbert.py
: 1598512765:0;rm -r sbert
: 1598512790:0;rm -r siamese
: 1598512959:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/ --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased 
: 1598513120:0;python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_base --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased 
: 1598513175:0;echo "python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_base --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased" >> siamese.sh 
: 1598513545:0;rm hup.sh
: 1598513680:0;chmod +x siamese.sh
: 1598513689:0;ls ../experiments/siamese_add
: 1598515618:0;ls ../experiments/siamese
: 1598515623:0;ls ../experiments/siamese/bert_base
: 1598515629:0;ls ../experiments/siamese/bert_base/1
: 1598515632:0;ls ../experiments/siamese/bert_base/2
: 1598515651:0;cat ../experiments/siamese/bert_base/1/eval_results_mnli.txt
: 1598515786:0;rm -r ../experiments/siamese/bert_base/2
: 1598542112:0;ls experiments/siamese/bert_large/4
: 1598542510:0;nohup /home/nlp/transformers-importance-sampling/siamese.sh
: 1598542550:0;vim siamese.sh
: 1598581704:0;cd experiments/
: 1598581707:0;cd siamese
: 1598581718:0;ls frozen_bert_base
: 1598582213:0;cat frozen_bert_base/1/eval_results_mnli-mm.txt
: 1598582223:0;cat frozen_bert_base/2/eval_results_mnli.txt
: 1598582612:0;cat frozen_bert_base/2/eval_results_mnli-mm.txt
: 1598582623:0;cat frozen_bert_base/3/eval_results_mnli.txt
: 1598582631:0;cat frozen_bert_base/3/eval_results_mnli-mm.txt
: 1598582641:0;cat frozen_bert_base/4/eval_results_mnli.txt
: 1598582655:0;cat frozen_bert_base/4/eval_results_mnli-mm.txt
: 1598582781:0;vim hans/run_hans_all.sh
: 1598584096:0;vim hans/run_siamese_hans.py
: 1598584218:0;rm siamese_hans.ipynb
: 1598584223:0;vim run_siamese_hans.py
: 1598584354:0;for val in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/bert_base/$val --model_weights_path=/home/nlp/experiments/siamese/bert_base/$val/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased; done
: 1598584395:0;for val in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 120 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/bert_base/$val --model_weights_path=/home/nlp/experiments/siamese/bert_base/$val/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased; done
: 1598585586:0;for val in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 120 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/frozen_bert_base/$val --model_weights_path=/home/nlp/experiments/siamese/frozen_bert_base/$val/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased; done
: 1598589135:0;for val in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 120 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/frozen_bert_large/$val --model_weights_path=/home/nlp/experiments/siamese/frozen_bert_large/$val/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1598589461:0;cat bert_base/1/eval_results_mnli.txt
: 1598589546:0;cat bert_base/1/eval_results_mnli-mm.txt
: 1598589562:0;cat bert_base/2/eval_results_mnli.txt
: 1598589570:0;cat bert_base/2/eval_results_mnli-mm.txt
: 1598589581:0;cat bert_base/3/eval_results_mnli.txt
: 1598589589:0;cat bert_base/3/eval_results_mnli-mm.txt
: 1598589614:0;cat bert_base/4/eval_results_mnli.txt
: 1598589624:0;cat bert_base/4/eval_results_mnli-mm.txt
: 1598589796:0;cat frozen_bert_base/1/eval_results_mnli.txt
: 1598591906:0;for val in 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 120 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/frozen_bert_large/$val --model_weights_path=/home/nlp/experiments/siamese/frozen_bert_large/$val/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1598592091:0;cd experiments/siamese
: 1598592100:0;cat frozen_bert_large/1/eval_results_mnli-mm.txt
: 1598592116:0;cat frozen_bert_large/1/eval_results_mnli.txt
: 1598592122:0;cat frozen_bert_large/2/eval_results_mnli.txt
: 1598592131:0;cat frozen_bert_large/2/eval_results_mnli-mm.txt
: 1598592142:0;cat frozen_bert_large/3/eval_results_mnli.txt
: 1598592148:0;cat frozen_bert_large/3/eval_results_mnli-mm.txt
: 1598592156:0;cat frozen_bert_large/4/eval_results_mnli.txt
: 1598592163:0;cat frozen_bert_large/4/eval_results_mnli-mm.txt
: 1598592181:0;cat bert_large/1/eval_results_mnli.txt
: 1598592190:0;cat bert_large/1/eval_results_mnli-mm.txt
: 1598592198:0;cat bert_large/2/eval_results_mnli.txt
: 1598592233:0;cat bert_large/2/eval_results_mnli-mm.txt
: 1598592245:0;cat bert_large/3/eval_results_mnli.txt
: 1598592252:0;cat bert_large/3/eval_results_mnli-mm.txt
: 1598592260:0;cat bert_large/4/eval_results_mnli.txt
: 1598592273:0;cat bert_large/4/eval_results_mnli-mm.txt
: 1598592443:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_base/1/hans_predictions.txt
: 1598592487:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_base/2/hans_predictions.txt
: 1598592538:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_base/3/hans_predictions.txt
: 1598592558:0;for val in 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 120 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/bert_large/$val --model_weights_path=/home/nlp/experiments/siamese/bert_large/$val/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1598592571:0;for val in 1 2 3 4 ; do python3 run_siamese_hans.py --model_name bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 120 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/siamese/bert_large/$val --model_weights_path=/home/nlp/experiments/siamese/bert_large/$val/ --config_name bert-large-uncased --tokenizer_name bert-large-uncased; done
: 1598592581:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_base/4/hans_predictions.txt
: 1598592930:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_base/1/hans_predictions.txt
: 1598592961:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_base/2/hans_predictions.txt
: 1598593006:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_base/3/hans_predictions.txt
: 1598593040:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_base/4/hans_predictions.txt
: 1598593080:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_large/1/hans_predictions.txt
: 1598593110:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_large/2/hans_predictions.txt
: 1598593165:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_large/3/hans_predictions.txt
: 1598593198:0;python3 evaluate_heur_output.py ~/experiments/siamese/frozen_bert_large/4/hans_predictions.txt
: 1598593346:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/1/hans_predictions.txt
: 1598593447:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/2/hans_predictions.txt
: 1598593697:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/3/hans_predictions.txt
: 1598593773:0;python3 evaluate_heur_output.py ~/experiments/siamese/bert_large/4/hans_predictions.txt
: 1598680170:0;python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter
: 1598702562:0;vim train_siamese.py
: 1598702569:0;vim train_adapter.py
: 1598755316:0;vim pooling.py
: 1598755620:0;cd fluence/tests
: 1598755625:0;vim test_adaptive.py
: 1598755981:0;pytest test_clustering.py
: 1598756003:0;pytest test_pooling.py
: 1598756144:0;vim tests/test_pooling.py
: 1598756215:0;pytest tests/test_pooling.py -v
: 1598756239:0;vim test_pooling.py
: 1598756611:0;pytest ./tests --ignore=./tests/test_clustering.py
: 1598757757:0;vim fluence/meta/meta_trainer.py
: 1598758069:0;git commit -m "Added Pooling and compatibility fixes"
: 1598758861:0;vim core/siamese_trainer.py
: 1598759220:0;vim transformers-importance-sampling/core/siamese_trainer.py
: 1598761918:0;pytest ./tests --ignore=./tests/test_clustering.py -v
: 1598762041:0;git commit -m "prediction step in siamese"
: 1598762250:0;make style
: 1598762258:0;make quality
: 1598764075:0;flake8 fluence/utils/siamese_utils.py
: 1598764131:0;rm fluence/utils/*.swn
: 1598764140:0;rm fluence/utils/.siamese_utils.py.swp
: 1598764144:0;rm fluence/utils/.siamese_utils.py.swo
: 1598764162:0;git commit -m "syntax"
: 1598764547:0;git commit -m "install transformers from master"
: 1598766057:0;git commit -m "install transformers with pip"
: 1598766335:0;vim tests/test_optim.py
: 1598766371:0;pytest ./tests/test_optim.py --ignore=./tests/test_clustering.py -v
: 1598766383:0;git commit -m "fix optim test"
: 1598766864:0;pytest ./tests/test_siamese.py --ignore=./tests/test_clustering.py -v
: 1598767231:0;cp tests/test_siamese.py tests/k.py
: 1598767700:0;vim tests/k.py
: 1598768097:0;pip install .
: 1598768116:0;python3 tests/k.py
: 1598768143:0;vim fluence/utils/siamese_utils.py
: 1598843493:0;vim models/cbow.py
: 1598843832:0;cd prajjwal1/transformers
: 1598843839:0;git checkout master
: 1598844003:0;vim src/transformers/modeling_bert.py
: 1598844048:0;git add src/transformers/modeling_bert.py
: 1598844067:0;git branch bert_typo_fix
: 1598844070:0;git checkout bert_typo_fix
: 1598844089:0;git commit -m "fix typo in comments"
: 1598844143:0;git push origin bert_typo_fix
: 1598844240:0;ls ../experiments/orthogonal
: 1598844248:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 25 --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir
: 1598844297:0;vim train_orthogonal.py
: 1598844349:0;python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 25 --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir --do_train --do_eval
: 1598863153:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.5 --do_train
: 1598863195:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.05 --do_train
: 1598863278:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20
: 1598863602:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-mini --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_mini   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20
: 1598863680:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-mini --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_mini   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --per_device_eval_batch_size 256
: 1598863880:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-medium --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_medium   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --per_device_eval_batch_size 256
: 1598865296:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --per_device_eval_batch_size 256
: 1598865371:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 156   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 40 --per_device_eval_batch_size 256
: 1598865387:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 40 --per_device_eval_batch_size 256
: 1598865441:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --per_device_eval_batch_size 256
: 1598866373:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 128   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_large   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --per_device_eval_batch_size 128
: 1598869467:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 128   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_large   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 77 --per_device_eval_batch_size 128
: 1598869479:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 128   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_large   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 77 --per_device_eval_batch_size 128 --overwrite_output_dir
: 1598872720:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 10
: 1598872729:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 10 --overwrite_cache
: 1598872739:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 10 --overwrite_output_dir
: 1598872791:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir
: 1598873109:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-mini --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_mini   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir
: 1598873455:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-small --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_small   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir
: 1598873774:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-medium --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_medium   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir
: 1598874085:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-small --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_small   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --per_device_eval_batch_size 256
: 1598874096:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-small --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_small   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --per_device_eval_batch_size 256 --overwrite_output_dir
: 1598874368:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir
: 1598874466:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 10 --overwrite_output_dir
: 1598874495:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 19 --overwrite_output_dir
: 1598874556:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 10.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 8 --overwrite_output_dir
: 1598875341:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 10 --overwrite_cache
: 1598875351:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 10 --overwrite_output_dir
: 1598875405:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --overwrite_output_dir
: 1598875977:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-small --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_small   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --overwrite_output_dir
: 1598876854:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-mini --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_mini   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --overwrite_output_dir
: 1598877670:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-medium --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_medium   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --overwrite_output_dir
: 1598878807:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 20 --overwrite_output_dir
: 1598878896:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 10 --overwrite_output_dir
: 1598878969:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --overwrite_output_dir
: 1598879148:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --overwrite_output_dir --per_device_eval_batch_size 256
: 1598879318:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598883504:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_large   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598883575:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_large   --fp16 --data_pct 0.05 --do_train --evaluate_during_training --eval_steps 39 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598950592:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-mini --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_mini  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598950819:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-tiny --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_tiny  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598951062:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-small --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_small  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598951693:0;python3 subsampling_mnli.py   --model_name_or_path prajjwal1/bert-medium --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_medium  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598952424:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 19 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598952486:0;python3 subsampling_mnli.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_base  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598953078:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_large  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 4 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598953138:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_large  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 19 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598953223:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 25.0   --output_dir /home/nlp/experiments/overfitting/bert_large  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 8 --overwrite_output_dir --per_device_eval_batch_size 512
: 1598957594:0;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/overfitting/bert_large  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 8 --overwrite_output_dir --per_device_eval_batch_size 512
: 1600068111:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.675
: 1600068187:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 128 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.675 --do_train
: 1600068547:0;vim prune.py
: 1600068635:0;cd fixtures
: 1600068644:0;vim lenet.py
: 1600068901:0;vim test_prune.py
: 1600069077:0;vim fixtures/
: 1600069616:0;vim tests/test_prune.py
: 1600069623:0;vim fluence/prune.py
: 1600069680:0;pytest tests/test_prune.py -v
: 1600069689:0;git commit -m "Added Pruner"
: 1600069885:0;cd prune
: 1600069896:0;cd 0
: 1600070381:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.675 --do_train
: 1600073467:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.5 --do_train
: 1600078513:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.4 --do_train --overwrite_output_dir
: 1600084240:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.3 --do_train --overwrite_output_dir
: 1600084247:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.5 --do_train --overwrite_output_dir
: 1600087908:0;cd exp
: 1600087912:0;ed experiments
: 1600087926:0;cd big_small
: 1600087941:0;cat epoch_1/eval_results_mnli.txt
: 1600087948:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --do_train
: 1600091853:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.665 --do_train --overwrite_output_dir
: 1600093113:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.675 --do_train --overwrite_output_dir
: 1600097125:0;cat experiments/prune/bert_large/0/eval_results_mnli.txt
: 1600097156:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.6 --do_train --overwrite_output_dir
: 1600100275:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.62 --do_train --overwrite_output_dir
: 1600100428:0;echo "python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.6 --do_train --overwrite_output_dir" >> prune.sh
: 1600100432:0;vim prune.sh
: 1600139818:0;rm prune.sh
: 1600139838:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.65 --do_train --overwrite_output_dir
: 1600143126:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.63 --do_train --overwrite_output_dir
: 1600146152:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/0 --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.61 --do_train --overwrite_output_dir
: 1600150392:0;python3 run_hans.py --model_name_or_path bert-large-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/prune/bert_large/0
: 1600150448:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/prune/bert_large/0 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/prune/bert_large/0
: 1600150604:0;python3 evaluate_heur_output.py ~/experiments/prune/bert_large/0/hans_predictions.txt
: 1600152320:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/prune/bert_large/$$((epoch+1)) --fp16 --per_device_eval_batch_size 256 --do_train; done
: 1600152434:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/prune/bert_large/ --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.61 --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600152453:0;\
python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/prune/bert_large/ --fp16 --per_device_eval_batch_size 256 --tokenizer_name bert-large-uncased --prune --prune_pct 0.61 --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir
: 1600166341:0;ctags -R .
: 1600166418:0;vim tags
: 1600272069:0;cat experiments/big_small/bert_large/epoch_1/eval_results_mnli.txt
: 1600272077:0;cat experiments/big_small/bert_large/epoch_4/eval_results_mnli.txt
: 1600272087:0;cat experiments/big_small/bert_small/epoch_1/eval_results_mnli.txt
: 1600272103:0;cat experiments/big_small/bert_base/epoch_1/eval_results_mnli.txt
: 1600272171:0;cat experiments/big_small/bert_base/epoch_5/eval_results_mnli.txt
: 1600272174:0;cat experiments/big_small/bert_base/epoch_4/eval_results_mnli.txt
: 1600405120:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/random/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600405248:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0  --output_dir /home/nlp/experiments/random/bert_base/0 --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600406860:0;python3 run_glue.py   --model_name_or_path bert-base --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600406869:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600406934:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 250 --save_steps 250
: 1600406987:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 250 --save_steps 250
: 1600407039:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 768 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 250 --save_steps 250
: 1600407085:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 768 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 256 --save_steps 256
: 1600407102:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 768 --learning_rate 2e-4  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 256 --save_steps 256
: 1600407426:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676 --learning_rate 2e-4  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 256 --save_steps 256
: 1600407490:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676 --learning_rate 2e-4  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 291 --save_steps 291
: 1600408511:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 291 --save_steps 291
: 1600408526:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 291 --save_steps 291 --overwrite_output_dir
: 1600412259:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600418240:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-4  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767
: 1600418254:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-4  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir
: 1600424266:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600430551:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600430656:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 196 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 196 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600432335:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 132 --save_steps 132 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600439037:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 17 --save_steps 17 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600443347:0;echo "python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir --tokenizer_name bert-large-uncased" >> k.sh
: 1600443349:0;vim k.sh
: 1600443370:0;chmod +x k.sh
: 1600443372:0;nohup k.sh
: 1600443409:0;nohup /home/nlp/transformers-importance-sampling/k.sh
: 1600482912:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 767 --save_steps 767 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600483290:0;export TASK_NAME=SNLI
: 1600483329:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 5 --save_steps 5 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600483683:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 12 --save_steps 12 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600487708:0;ls ../data/glue_data
: 1600487727:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 205 --save_steps 205 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600487796:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 8 --save_steps 8 --overwrite_output_dir --tokenizer_name bert-large-uncased
: 1600491340:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 8 --save_steps 8 --overwrite_output_dir
: 1600491390:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 12 --save_steps 12 --overwrite_output_dir
: 1600491727:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 6 --save_steps 6 --overwrite_output_dir
: 1600491810:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 3 --save_steps 3 --overwrite_output_dir
: 1600516532:0;ls experiments/random/bert_large/
: 1600516680:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 103 --save_steps 103 --overwrite_output_dir
: 1600516709:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 66 --save_steps 66 --overwrite_output_dir
: 1600517495:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --evaluate_during_training --eval_steps 132 --save_steps 132 --overwrite_output_dir
: 1600517799:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --evaluate_during_training --eval_steps 132 --save_steps 132 --overwrite_output_dir
: 1600761145:0;vim test_m
: 1600761230:0;pytest test_siamese.py
: 1600761254:0;pytest tests/test_siamese.py
: 1600761315:0;vim tests/test_siamese.py
: 1600761396:0;git commit -m "siamese with pooling"
: 1600764743:0;export TASK_NAME=CoLA
: 1600765542:0;export TASK_NAME=SST-B
: 1600765946:0;transformers --info
: 1600765950:0;transformers 
: 1600765965:0;transformers-cli
: 1600830092:0;cat experiments/random/MNLI/bert_large/eval_results_mnli-mm.txt
: 1600835481:0;export TASK_NAME=WNLI
: 1600835483:0;python3 run_glue.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_large --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --overwrite_output_dir
: 1600836075:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 256 --random_weights --do_train --overwrite_output_dir
: 1600836450:0;export TASK_NAME=RTE
: 1600836576:0;export TASK_NAME=QNLI
: 1600841128:0;export TASK_NAME=QQP
: 1600844593:0;export TASK_NAME=MRPC
: 1600845417:0;export TASK_NAME=SST-2
: 1600849479:0;export TASK_NAME=STS-B
: 1601022719:0;git pull upstream master
: 1601022802:0;pip install . --upgrade
: 1601022948:0;pip install datasets
: 1601356618:0;ls models
: 1601356852:0;rm tags
: 1601356856:0;rm k.sh
: 1601356862:0;rm siamese.sh
: 1601356879:0;git commit -m "updated"
: 1601530512:0;cd random
: 1601530528:0;cd bert_large
: 1601530556:0;cat experiments/random/MNLI/bert_large/eval_results_mnli.txt
: 1601530564:0;cat experiments/random/MNLI/bert_base/eval_results_mnli.txt
: 1601530648:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/random/MNLI/bert_large/checkpoint-2301 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/random/MNLI/bert_large
: 1601530669:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/random/MNLI/bert_large/ --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/random/MNLI/bert_large
: 1601530881:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/random/MNLI/bert_base/ --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/random/MNLI/bert_base
: 1601530964:0;python3 evaluate_heur_output.py ~/experiments/random/MNLI/bert_base/hans_predictions.txt
: 1601530972:0;python3 evaluate_heur_output.py ~/experiments/random/MNLI/bert_large/hans_predictions.txt
: 1601643583:0;wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip
: 1601643590:0;unzip wikitext-2-v1.zip
: 1601643659:0;rm -r wikitext-2
: 1601643661:0;rm -r wikitext-2.
: 1601643671:0;wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip
: 1601643677:0;unzip wikitext-2-raw-v1.zip
: 1601643711:0;export TRAIN_FILE=/home/nlp/data/wikitext-2-raw/wiki.train.raw
: 1601643726:0;vim run_lm.py
: 1601956969:0;vim test_clustering.py
: 1601957596:0;pytest tests/test_clustering.py -v
: 1601957872:0;git commit -m "added diverse stream samplng"
: 1601957879:0;git commit -m "added diverse stream sampling"
: 1601959047:0;export TEST_FILE=/home/nlp/data/wikitext-2-raw/wiki.test.raw
: 1601960018:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --batch_size 512 --use_diverse_stream --data_pct 0.1 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048 --tokenizer_name bert-base-uncased
: 1601960321:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --batch_size 512 --use_diverse_stream --data_pct 0.1 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 2048
: 1601960370:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --use_diverse_stream --data_pct 0.1 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512
: 1601961003:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --use_diverse_stream --data_pct 0.1 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256
: 1601961410:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 1.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --use_diverse_stream --data_pct 10 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256
: 1601961865:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --use_diverse_stream --data_pct 10 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256
: 1601961975:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/10_pct  --fp16  --use_diverse_stream --data_pct 10 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601962502:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/20_pct  --fp16  --use_diverse_stream --data_pct 20 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601963540:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/30_pct  --fp16  --use_diverse_stream --data_pct 30 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601964846:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/40_pct  --fp16  --use_diverse_stream --data_pct 40 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601966847:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/50_pct  --fp16  --use_diverse_stream --data_pct 50 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601969008:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/60_pct  --fp16  --use_diverse_stream --data_pct 60 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601971729:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/70_pct  --fp16  --use_diverse_stream --data_pct 70 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 256 --overwrite_output_dir
: 1601972488:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 432   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/70_pct  --fp16  --use_diverse_stream --data_pct 70 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 432 --overwrite_output_dir
: 1601972883:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/70_pct  --fp16  --use_diverse_stream --data_pct 70 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 384 --overwrite_output_dir
: 1601975748:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/80_pct  --fp16  --use_diverse_stream --data_pct 80 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 384 --overwrite_output_dir
: 1601979041:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/90_pct  --fp16  --use_diverse_stream --data_pct 90 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 384 --overwrite_output_dir
: 1601982716:0;python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/100_pct  --fp16  --use_diverse_stream --data_pct 100 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 384 --overwrite_output_dir
: 1601987456:0;for val in /home/nlp/experiments/clustering/diverse_stream/100_pct /home/nlp/experiments/clustering/diverse_stream/10_pct /home/nlp/experiments/clustering/diverse_stream/20_pct /home/nlp/experiments/clustering/diverse_stream/30_pct /home/nlp/experiments/clustering/diverse_stream/40_pct /home/nlp/experiments/clustering/diverse_stream/50_pct /home/nlp/experiments/clustering/diverse_stream/60_pct /home/nlp/experiments/clustering/diverse_stream/70_pct /home/nlp/experiments/clustering/diverse_stream/80_pct /home/nlp/experiments/clustering/diverse_stream/90_pct ;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=$val; done
: 1601987487:0;for val in /home/nlp/experiments/clustering/diverse_stream/100_pct /home/nlp/experiments/clustering/diverse_stream/10_pct /home/nlp/experiments/clustering/diverse_stream/20_pct /home/nlp/experiments/clustering/diverse_stream/30_pct /home/nlp/experiments/clustering/diverse_stream/40_pct /home/nlp/experiments/clustering/diverse_stream/50_pct /home/nlp/experiments/clustering/diverse_stream/60_pct /home/nlp/experiments/clustering/diverse_stream/70_pct /home/nlp/experiments/clustering/diverse_stream/80_pct /home/nlp/experiments/clustering/diverse_stream/90_pct ;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1601988504:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/10_pct
: 1601988508:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/10_pct/hans_predictions.txt
: 1601988641:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/20_pct/hans_predictions.txt
: 1601988680:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/30_pct/hans_predictions.txt
: 1601988714:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/40_pct/hans_predictions.txt
: 1601988745:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/50_pct/hans_predictions.txt
: 1601988775:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/60_pct/hans_predictions.txt
: 1601988803:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/70_pct/hans_predictions.txt
: 1601988835:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/80_pct/hans_predictions.txt
: 1601988867:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/90_pct/hans_predictions.txt
: 1601988899:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/9100_pct/hans_predictions.txt
: 1601988903:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/100_pct/hans_predictions.txt
: 1602034913:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length $val   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512; done
: 1602034952:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length $val   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed7/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --seed 7; done
: 1602037714:0;rm -r ../experiments/clustering/diverse_stream/seed7
: 1602037777:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed7/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --seed 7; done
: 1602037857:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 786   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed7/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 786 --seed 7; done
: 1602037944:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed7/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 676 --seed 7; done
: 1602057304:0;cat experiments/clustering/diverse_stream/seed7/100_pct/
: 1602057343:0;for val in 100; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed7/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 676 --seed 7; done
: 1602058992:0;for val in 100; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 676   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed7/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 676 --seed 7 --overwrite_output_dir; done
: 1602061944:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed81/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --seed 81; done
: 1602072245:0;cat experiments/clustering/diverse_stream/seed7/
: 1602072255:0;cat experiments/clustering/diverse_stream/seed7/10_pct/eval_results_mnli.txt
: 1602072286:0;cat experiments/clustering/diverse_stream/seed7/20_pct/eval_results_mnli.txt
: 1602072297:0;cat experiments/clustering/diverse_stream/seed7/30_pct/eval_results_mnli.txt
: 1602072307:0;cat experiments/clustering/diverse_stream/seed7/40_pct/eval_results_mnli.txt
: 1602072319:0;cat experiments/clustering/diverse_stream/seed7/50_pct/eval_results_mnli.txt
: 1602072328:0;cat experiments/clustering/diverse_stream/seed7/60_pct/eval_results_mnli.txt
: 1602072337:0;cat experiments/clustering/diverse_stream/seed7/70_pct/eval_results_mnli.txt
: 1602072347:0;cat experiments/clustering/diverse_stream/seed7/80_pct/eval_results_mnli.txt
: 1602072355:0;cat experiments/clustering/diverse_stream/seed7/90_pct/eval_results_mnli.txt
: 1602072381:0;cat experiments/clustering/diverse_stream/seed7/100_pct/eval_results_mnli.txt
: 1602072439:0;cat experiments/clustering/diverse_stream/seed81/10_pct/eval_results_mnli.txt
: 1602072450:0;cat experiments/clustering/diverse_stream/seed81/20_pct/eval_results_mnli.txt
: 1602072499:0;cat experiments/clustering/diverse_stream/seed81/30_pct/eval_results_mnli.txt
: 1602072508:0;cat experiments/clustering/diverse_stream/seed81/40_pct/eval_results_mnli.txt
: 1602072518:0;cat experiments/clustering/diverse_stream/seed81/50_pct/eval_results_mnli.txt
: 1602072527:0;cat experiments/clustering/diverse_stream/seed81/60_pct/eval_results_mnli.txt
: 1602072537:0;cat experiments/clustering/diverse_stream/seed81/70_pct/eval_results_mnli.txt
: 1602072548:0;cat experiments/clustering/diverse_stream/seed81/80_pct/eval_results_mnli.txt
: 1602072570:0;cat experiments/clustering/diverse_stream/seed81/90_pct/eval_results_mnli.txt
: 1602076365:0;for
: 1602076619:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/10_pct/hans_predictions.txt
: 1602076757:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/20_pct/hans_predictions.txt
: 1602076797:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/30_pct/hans_predictions.txt
: 1602076824:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/40_pct/hans_predictions.txt
: 1602076920:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/50_pct/hans_predictions.txt
: 1602076951:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/60_pct/hans_predictions.txt
: 1602076984:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/70_pct/hans_predictions.txt
: 1602077014:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/80_pct/hans_predictions.txt
: 1602077102:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/90_pct/hans_predictions.txt
: 1602077159:0;for val in /home/nlp/experiments/clustering/diverse_stream/100_pct /home/nlp/experiments/clustering/diverse_stream/seed7/10_pct /home/nlp/experiments/clustering/diverse_stream/seed7/20_pct /home/nlp/experiments/clustering/diverse_stream/seed7/30_pct /home/nlp/experiments/clustering/diverse_stream/seed7/40_pct /home/nlp/experiments/clustering/diverse_stream/seed7/50_pct /home/nlp/experiments/clustering/diverse_stream/seed7/60_pct/ /home/nlp/experiments/clustering/diverse_stream/seed7/70_pct /home/nlp/experiments/clustering/diverse_stream/seed7/80_pct /home/nlp/experiments/clustering/diverse_stream/seed7/90_pct ;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1602077207:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering/diverse_stream/100_pct --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/clustering/diverse_stream/seed7/100_pct/
: 1602077368:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed7/100_pct/hans_predictions.txt
: 1602077603:0;for val in /home/nlp/experiments/clustering/diverse_stream/seed81/10_pct /home/nlp/experiments/clustering/diverse_stream/seed81/20_pct /home/nlp/experiments/clustering/diverse_stream/seed81/30_pct /home/nlp/experiments/clustering/diverse_stream/seed81/40_pct /home/nlp/experiments/clustering/diverse_stream/seed81/50_pct /home/nlp/experiments/clustering/diverse_stream/seed81/60_pct/ /home/nlp/experiments/clustering/diverse_stream/seed81/70_pct /home/nlp/experiments/clustering/diverse_stream/seed81/80_pct /home/nlp/experiments/clustering/diverse_stream/seed81/90_pct /home/nlp/experiments/clustering/diverse_stream/seed81/100_pct;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1602077673:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/10_pct/hans_predictions.txt
: 1602077720:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/20_pct/hans_predictions.txt
: 1602077750:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/30_pct/hans_predictions.txt
: 1602077842:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/40_pct/hans_predictions.txt
: 1602077874:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/50_pct/hans_predictions.txt
: 1602077908:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/60_pct/hans_predictions.txt
: 1602078414:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/70_pct/hans_predictions.txt
: 1602078446:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/80_pct/hans_predictions.txt
: 1602078476:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/90_pct/hans_predictions.txt
: 1602078505:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed81/100_pct/hans_predictions.txt
: 1602119394:0;"python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/" << README.MD
: 1602119401:0;"python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/" >> README.MD
: 1602119416:0;echo "python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/" << README.MD
: 1602119478:0;echo "python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/" >> README.MD
: 1602119524:0;rm README.MD
: 1602119530:0;echo "python3 get_embeddings.py --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME --max_seq_len 128 --per_device_train_batch_size 512 --output_dir /home/nlp/experiments/" >> README.md
: 1602119727:0;echo "python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/overfitting/bert_large  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 8 --overwrite_output_dir --per_device_eval_batch_size 512" << README.md
: 1602119731:0;echo "python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/overfitting/bert_large  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 8 --overwrite_output_dir --per_device_eval_batch_size 512" >> README.md
: 1602119799:0;vim subsampling_mnli.py
: 1602120013:0;echo "python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 128   --per_device_train_batch_size 384   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/100_pct  --fp16  --use_diverse_stream --data_pct 100 --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 384 --overwrite_output_dir" >> README.md
: 1602120609:0;echo "python3 train_orthogonal.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_len 80 --output_dir /home/nlp/experiments/orthogonal/trials/  --dataloader_drop_last --evaluate_during_training --eval_steps 25 --lamb 0.0001 --per_device_train_batch_size 384 --per_device_eval_batch_size 384 --overwrite_output_dir --do_train --do_eval" >> README.md
: 1602121409:0;echo "python3 reptile_few_shot.py   --model_name_or_path bert-base-uncased  --do_train  --do_eval --max_seq_length 80   --per_device_train_batch_size 2  --learning_rate 2e-5  --output_dir /home/nlp/experiments/meta/bert_base/   --per_device_eval_batch_size 4096 --data_dir $GLUE_DIR/MNLI --task_name mnli --eval_steps=100 --save_steps=1024 --num_train_epochs=1 --max_sample_limit 2048 --step_size=2e-5" >> README.md
: 1602121693:0;echo "python3 train_siamese.py   --model_name bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 60   --per_device_train_batch_size 512  --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/siamese/bert_base --per_device_eval_batch_size 512 --do_train --fp16 --config_name bert-base-uncased --tokenizer_name bert-base-uncased" >> README.md 
: 1602121784:0;echo "python3 train_adapter.py --model_name_or_path bert-large-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 1.0   --output_dir /home/nlp/experiments/adapter_big/epoch_1   --fp16 --per_device_eval_batch_size 128 --do_train --adapter_config pfeiffer --train_adapter" >> README.md
: 1602121992:0;vim run_hans_adapter.py
: 1602122043:0;echo "python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering/diverse_stream/100_pct --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/clustering/diverse_stream/seed7/100_pct/ --tokenizer_name bert-base-uncased" >> ../README.md
: 1602122174:0;echo "python3 run_siamese_hans.py --model_name bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/siamese/hans --model_weights_path=/home/nlp/experiments/siamese/epoch_4/ --config_name bert-base-uncased --tokenizer_name bert-base-uncased" >> ../README.md
: 1602122295:0;echo "python3 run_hex_hans.py --model_name_or_path sentence-transformers/bert-large-nli-mean-tokens --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=/home/nlp/experiments/sbert/frozen_bert_base/$val --model_weights_path /home/nlp/experiments/sbert/frozen_bert_base/$val" >> ../README.md
: 1602122356:0;for val in /home/nlp/experiments/orthogonal/bert_base_0.00001 /home/nlp/experiments/orthogonal/bert_base_0.00002 /home/nlp/experiments/orthogonal/bert_base_0.00003 /home/nlp/experiments/orthogonal/bert_base_0.00004 /home/nlp/experiments/orthogonal/bert_base_0.00005 /home/nlp/experiments/orthogonal/bert_base_0.0001 /home/nlp/experiments/orthogonal/bert_base_0.0002 /home/nlp/experiments/orthogonal/bert_base_0.0003 /home/nlp/experiments/orthogonal/bert_base_0.0004 /home/nlp/experiments/orthogonal/bert_base_0.0005 /home/nlp/experiments/orthogonal/bert_base_0.0006 /home/nlp/experiments/orthogonal/bert_base_0.0007 /home/nlp/experiments/orthogonal/bert_base_0.0008 /home/nlp/experiments/orthogonal/bert_base_0.0009 ; do python3 run_hex_hans.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 384 --output_dir=$val --config_name bert-base-uncased --tokenizer_name bert-base-uncased --model_weights_path $val --fp16; done
: 1602122494:0;echo "CUDA_VISIBLE_DEVICES=0 python3 run_hans_adapter.py --model_name_or_path bert-base-uncased --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 4096 --output_dir=/home/nlp/experiments/adapters/epoch_6 --load_task_adapter /home/nlp/experiments/adapters/epoch_6/mnli" >> ../README.md
: 1602123742:0;mv figs heatmaps ../
: 1602123756:0;mv nbs ../
: 1602123778:0;git commit -m "code release for eacl submission"
: 1602142981:0;for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed48/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --seed 48; done
: 1602143076:0;echo "for val in {10..100..10}; do python3 train_clustering.py   --model_name_or_path bert-base-uncased  --task_name $TASK_NAME   --do_train   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512   --learning_rate 2e-5   --num_train_epochs 3.0   --output_dir /home/nlp/experiments/clustering/diverse_stream/seed48/$val"_pct"  --fp16  --use_diverse_stream --data_pct $val --cluster_input_path /home/nlp/experiments/cluster_output.pth --per_device_eval_batch_size 512 --seed 48; done" >> run_seed_fig_1.sh
: 1602143193:0;chmod +x run_seed_fig_1.sh
: 1602144670:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/clustering/diverse_stream/100_pct --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/clustering/diverse_stream/seed7/100_pct/ --tokenizer_name bert-base-uncased
: 1602144706:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --do_train --overwrite_output_dir
: 1602144782:0;vim ~/.vimrc
: 1602145036:0;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/random/$TASK_NAME/bert_base --fp16 --per_device_eval_batch_size 512 --random_weights --overwrite_output_dir
: 1602162499:0;cd ../experiments
: 1602162516:0;cd clustering/diverse_stream
: 1602162523:0;cd seed55
: 1602162531:0;cat 100_pct/eval_results_mnli.txt
: 1602162538:0;cd seed81
: 1602162546:0;cd 10_pct
: 1602162562:0;cd ../seed48
: 1602162581:0;vim run_seed_fig_1.sh
: 1602162663:0;rm -r ../experiments/clustering/diverse_stream/seed48
: 1602162668:0;nohup /home/nlp/transformers-importance-sampling/run_seed_fig_1.sh
: 1602216708:0;for val in /home/nlp/experiments/clustering/diverse_stream/seed81/10_pct /home/nlp/experiments/clustering/diverse_stream/seed81/20_pct /home/nlp/experiments/clustering/diverse_stream/seed81/30_pct /home/nlp/experiments/clustering/diverse_stream/seed81/40_pct /home/nlp/experiments/clustering/diverse_stream/seed81/50_pct /home/nlp/experiments/clustering/diverse_stream/seed81/60_pct/ /home/nlp/experiments/clustering/diverse_stream/seed81/70_pct /home/nlp/experiments/clustering/diverse_stream/seed81/80_pct /home/nlp/experiments/clustering/diverse_stream/seed81/90_pct /home/nlp/experiments/clustering/diverse_stream/seed81/100_pct;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1602216743:0;ls ../../experiments/clustering/diverse_stream
: 1602216809:0;for val in /home/nlp/experiments/clustering/diverse_stream/seed55/10_pct /home/nlp/experiments/clustering/diverse_stream/seed55/20_pct /home/nlp/experiments/clustering/diverse_stream/seed55/30_pct /home/nlp/experiments/clustering/diverse_stream/seed55/40_pct /home/nlp/experiments/clustering/diverse_stream/seed55/50_pct /home/nlp/experiments/clustering/diverse_stream/seed55/60_pct/ /home/nlp/experiments/clustering/diverse_stream/seed55/70_pct /home/nlp/experiments/clustering/diverse_stream/seed55/80_pct /home/nlp/experiments/clustering/diverse_stream/seed55/90_pct /home/nlp/experiments/clustering/diverse_stream/seed55/100_pct;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1602217583:0;for val in /home/nlp/experiments/clustering/diverse_stream/seed48/10_pct /home/nlp/experiments/clustering/diverse_stream/seed48/20_pct /home/nlp/experiments/clustering/diverse_stream/seed48/30_pct /home/nlp/experiments/clustering/diverse_stream/seed48/40_pct /home/nlp/experiments/clustering/diverse_stream/seed48/50_pct /home/nlp/experiments/clustering/diverse_stream/seed48/60_pct/ /home/nlp/experiments/clustering/diverse_stream/seed48/70_pct /home/nlp/experiments/clustering/diverse_stream/seed48/80_pct /home/nlp/experiments/clustering/diverse_stream/seed48/90_pct /home/nlp/experiments/clustering/diverse_stream/seed48/100_pct;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1602220107:0;cat experiments/clustering/diverse_stream/seed48/10_pct/eval_results_mnli.txt
: 1602220155:0;cat experiments/clustering/diverse_stream/seed48/20_pct/eval_results_mnli.txt
: 1602220165:0;cat experiments/clustering/diverse_stream/seed48/30_pct/eval_results_mnli.txt
: 1602220175:0;cat experiments/clustering/diverse_stream/seed48/40_pct/eval_results_mnli.txt
: 1602220184:0;cat experiments/clustering/diverse_stream/seed48/50_pct/eval_results_mnli.txt
: 1602220192:0;cat experiments/clustering/diverse_stream/seed48/60_pct/eval_results_mnli.txt
: 1602220201:0;cat experiments/clustering/diverse_stream/seed48/70_pct/eval_results_mnli.txt
: 1602220243:0;cat experiments/clustering/diverse_stream/seed48/80_pct/eval_results_mnli.txt
: 1602220252:0;cat experiments/clustering/diverse_stream/seed48/90_pct/eval_results_mnli.txt
: 1602220262:0;cat experiments/clustering/diverse_stream/seed48/100_pct/eval_results_mnli.txt
: 1602220277:0;cat experiments/clustering/diverse_stream/seed55/10_pct/eval_results_mnli.txt
: 1602220309:0;cat experiments/clustering/diverse_stream/seed55/20_pct/eval_results_mnli.txt
: 1602220318:0;cat experiments/clustering/diverse_stream/seed55/30_pct/eval_results_mnli.txt
: 1602220326:0;cat experiments/clustering/diverse_stream/seed55/40_pct/eval_results_mnli.txt
: 1602220334:0;cat experiments/clustering/diverse_stream/seed55/50_pct/eval_results_mnli.txt
: 1602220343:0;cat experiments/clustering/diverse_stream/seed55/60_pct/eval_results_mnli.txt
: 1602220351:0;cat experiments/clustering/diverse_stream/seed55/70_pct/eval_results_mnli.txt
: 1602220361:0;cat experiments/clustering/diverse_stream/seed55/80_pct/eval_results_mnli.txt
: 1602220368:0;cat experiments/clustering/diverse_stream/seed55/90_pct/eval_results_mnli.txt
: 1602220378:0;cat experiments/clustering/diverse_stream/seed55/100_pct/eval_results_mnli.txt
: 1602220490:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/10_pct/hans_predictions.txt
: 1602220540:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/20_pct/hans_predictions.txt
: 1602220576:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/30_pct/hans_predictions.txt
: 1602220609:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/40_pct/hans_predictions.txt
: 1602220637:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/50_pct/hans_predictions.txt
: 1602220679:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/60_pct/hans_predictions.txt
: 1602220706:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/70_pct/hans_predictions.txt
: 1602220740:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/80_pct/hans_predictions.txt
: 1602220772:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/90_pct/hans_predictions.txt
: 1602220807:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed48/100_pct/hans_predictions.txt
: 1602220931:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/10_pct/hans_predictions.txt
: 1602220965:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/20_pct/hans_predictions.txt
: 1602220994:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/30_pct/hans_predictions.txt
: 1602221025:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/40_pct/hans_predictions.txt
: 1602221057:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/50_pct/hans_predictions.txt
: 1602221096:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/60_pct/hans_predictions.txt
: 1602221126:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/70_pct/hans_predictions.txt
: 1602221260:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/80_pct/hans_predictions.txt
: 1602221320:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/90_pct/hans_predictions.txt
: 1602221356:0;python3 evaluate_heur_output.py ~/experiments/clustering/diverse_stream/seed55/100_pct/hans_predictions.txt
: 1602310626:0;ls meta
: 1602310641:0;mv meta/meta_dataset.py datasets
: 1602310651:0;cd meta
: 1602310655:0;vim meta_args.py
: 1602310672:0;rm -r meta
: 1602310684:0;ls sampling
: 1602310690:0;ls utils
: 1602310694:0;cd utils
: 1602310697:0;vim siamese_utils.py
: 1602310719:0;rm -r utils
: 1602310767:0;cd ../fluence
: 1602310769:0;cd datasets
: 1602310773:0;rm siamese_dataset.py
: 1602310845:0;cd tests
: 1602310849:0;vim test_meta.py
: 1602310917:0;mv test_meta.py test_datasets.py
: 1602310936:0;vim test_siamese.py
: 1602311057:0;rm test_siamese.py
: 1602311335:0;vim test_models.py
: 1602311344:0;pytest test_models.py -v
: 1602311405:0;vim fluence/siamese_model.py
: 1602311417:0;vim models
: 1602311526:0;cd fluence/models
: 1602311625:0;cd models
: 1602311669:0;vim __init__.py
: 1602311708:0;vim siamese_model.py
: 1602311775:0;vim fluence/models/__init__.py
: 1602312729:0;vim fluence/pooling.py
: 1602312741:0;vim models/siamese_model.py
: 1602312788:0;pip install --user .
: 1602312848:0;vim fluence/models/siamese_model.py
: 1602312868:0;pytest tests/test_models.py -v
: 1602312887:0;vim tests/test_clustering.py
: 1602312972:0;git commit -m "removed trainer support"
: 1602313185:0;vim se
: 1602313193:0;vim setu
: 1602313211:0;vim setup.py
: 1602313644:0;git commit -m "added torch in workflow.yml"
: 1602313893:0;vim tests/test_models.py
: 1602313925:0;vim tests/test_datasets.py
: 1602313954:0;git commit -m "fix model id in test_datasets"
: 1602315096:0;rm -r examples
: 1602315110:0;git commit -m "removed non working example"
: 1602656111:0;cd fluence
: 1602656118:0;vim .github/workflows/main.yml
: 1602656149:0;git commit -m "made clustering test functional"
: 1602656155:0;git push origin meta
: 1603983076:1;rm /home/nlp/.cache/huggingface/datasets/json/*
: 1603983125:3;lsof
: 1603983257:1;rm -rf /home/nlp/.cache/huggingface/datasets/json/*
: 1603983389:0;lsof +D /home/nlp/.cache/huggingface/datasets/json/default-b95a9025f82e1846
: 1603983420:0;rm -rf /home/nlp/.cache/huggingface/datasets/json/default-b95a9025f82e1846
: 1603983887:0;ls data/cache
: 1603983894:0;ls data/cache/json
: 1603983898:0;ls data/cache/json/default-a388c06928907a90
: 1603983901:0;ls data/cache/json/default-a388c06928907a90/0.0.0
: 1603982583:0;git clone https://github.com/prajjwal1/transformer-editorialhttps://github.com/huggingface/nlp.git
: 1603982589:7;git clone https://github.com/prajjwal1/transformer-editorial
: 1603982632:0;mv transformer-editorial apex
: 1604039427:0;rm -r data/cache
: 1604123166:25;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2
: 1604123283:32;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval
: 1604123438:29;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size -1 --per_device_eval_batch_size 1 --do_eval
: 1604123491:410;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval
: 1604123922:14;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --evaluation_strategy epoch
: 1604124679:59;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --evaluation_strategy steps --eval_steps 100
: 1604124770:16;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train
: 1604125757:9;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --evaluate_during_training --eval_steps 371
: 1604125774:70;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --num_train_epochs 3 --evaluate_during_training --eval_steps 371
: 1604126005:2673;python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3
: 1604129265:0;echo "python3 sanity_check.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3" >> run.sh
: 1604130602:1;nohup /home/nlp/apex/transformer-editorial/run.sh
: 1604135666:60;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --gradient_accumulation_steps 5
: 1604136083:58;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval 
: 1604145441:81;vi run_edit.py
: 1604162884:1;for val in /home/nlp/experiments/clustering/diverse_stream/seed55/10_pct /home/nlp/experiments/clustering/diverse_stream/seed55/20_pct /home/nlp/experiments/clustering/diverse_stream/seed55/30_pct /home/nlp/experiments/clustering/diverse_stream/seed55/40_pct /home/nlp/experiments/clustering/diverse_stream/seed55/50_pct /home/nlp/experiments/clustering/diverse_stream/seed55/60_pct/ /home/nlp/experiments/clustering/diverse_stream/seed55/70_pct /home/nlp/experiments/clustering/diverse_stream/seed55/80_pct /home/nlp/experiments/clustering/diverse_stream/seed55/90_pct /home/nlp/experiments/clustering/diverse_stream/seed55/100_pct;do python3 run_hans.py --model_name_or_path $val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=$val --tokenizer_name bert-base-uncased; done
: 1604129220:0;mv sanity_check.py run_edit.py
: 1604130637:0;mv run.sh run_glue.sh
: 1604135798:0;cat /home/nlp/experiments/edit/merges.txt
: 1604237638:1;python3 run_edit.py --model_name_or_path allenai/longformer-base-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3
: 1604239251:0;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --start_train_idx 85 --end_train_idx
: 1604247393:0;gdb python
: 1604248429:26;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 2 --fold 5
: 1604249118:24;python3 -q -X faulthandler run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 2 --fold 5
: 1604249816:23;python3 -q -X faulthandler run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 0 --fold 5
: 1604250218:1;python3 -q -X faulthandler run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 0 --fold 5 --no_cuda
: 1604250432:49;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 0 --fold 5 --no_cuda
: 1604250484:78;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 0 --fold 5 
: 1604250574:105;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --model_name_or_path allenai/longformer-base-4096 --k 0 --fold 5 
: 1604250716:0;echo "python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 5 --model_name_or_path allenai/longformer-base-4096 --k 0 --fold 5" >> run_glue.sh 
: 1604243873:31;python3 run_edit.py --model_name_or_path allenai/longformer-base-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604244092:500;pip install --user torch==1.7.0+cu101 torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html
: 1604244983:6;pip install --user sentencepiece==0.1.91
: 1604245035:2;pip install --user sentencepiece
: 1604245098:10;pip uninstall adapter-transformers
: 1604245133:52;pip install --user transformers
: 1604245645:105;pip uninstall torch
: 1604245782:377;pip install --user torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html --upgrade
: 1604246311:27;python3 run_edit.py --model_name_or_path allenai/longformer-base-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604246421:1;pip uninstall sentencepience
: 1604246430:5;pip uninstall sentencepiece
: 1604246461:0;pip unsintall -ransformers
: 1604246478:1;pip uninstall -rransformers
: 1604246496:1;pip list
: 1604246538:0;pip uninstall ransformers
: 1604246548:0;pip uninstall -r-ransformers
: 1604246635:1;nvcc -V
: 1604246737:2;pip install --user sentencepiece==0.1.91 --upgrade
: 1604247588:5;pip install --user gdb
: 1604247596:0;gdb
: 1604247604:2;pip uninstall gdb
: 1604247627:37;python3 run_edit.py --model_name_or_path allenai/longformer-large-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604248335:26;python3 run_edit.py --model_name_or_path bert-base-uncased --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604331163:0;mv nohup.out lf_headline_5_10.txt
: 1604331220:41;python3 run_edit.py --model_name_or_path roberta-base --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604331272:23;python3 run_edit.py --model_name_or_path roberta-base --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604335172:0;mv nohup.out roberta_headline_5_10.txt
: 1604335320:0;cat k.l
: 1604335329:2;vim klo
: 1604335334:0;mv klo p
: 1604335336:0;rm klo
: 1604375602:0;mv nohup.out roberta_abstract_5_10.txt
: 1604414850:0;mv nohup.out lf_abstract_5_10.txt
: 1604414901:750;vim lf_abstract_5_10.txt
: 1604416057:1095;	vim roberta_abstract_5_10.txt
: 1604043030:2;pip install fluence --upgrade
: 1604045252:99;python3 sanity_check.py
: 1604045353:9221;vim sanity_check.py
: 1604054858:16;vim edit_data.json
: 1604199826:239;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --gradient_accumulation_steps 20
: 1604200307:1;python3 run_edit.py --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --gradient_accumulation_steps 20
: 1604039585:0;lsof +D /home/nlp/.cache/huggingface/datasets/json/
: 1604321057:28;python3 run_edit.py --model_name_or_path allenai/longformer-base-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1604321114:35;python3 run_edit.py --model_name_or_path allenai/longformer-base-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 8 --per_device_eval_batch_size 16 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5
: 1605015731:627;vim lf_headline_5_10.txt
: 1605016362:2289;vim roberta_headline_5_10.txt
: 1605113442:2;nvidia-smi  -v
: 1605112951:0;cd edit
: 1605112966:0;cd fold_5_headline
: 1605113258:0;rm -r 
: 1605113262:22;rm -rf *
: 1605148260:0;cd ../../experiments/edit
: 1605148264:0;cd lf_body
: 1605193055:0;ls experiments/edit
: 1605193061:0;ls ../../experiments/edit
: 1605193066:0;ls ../../experiments/edit/lf_abstract
: 1605282327:0;rm abstract.pdf
: 1605282329:0;rm headline.pdf
: 1605282333:0;rm p
: 1605282349:0;rm body.pdf
: 1605282361:0;mv edit_data.json data
: 1605282500:1;git branch alpha
: 1605282505:0;git checkout alpha
: 1605282519:1;git commit -m "proper update"
: 1605282803:1;git commit -m "linting ci"
: 1605283446:16;vim .github/workflows/pylint.yml
: 1605619023:4;vim eval_metrics_mnli_dev_in_training.json
: 1605619034:9;vim cartography_config_train.json
: 1605631804:0;ls cartography/filtered/bert_hard_mnli
: 1605631843:0;ls cartography/filtered/bert_hard_mnli/cartography_confidence_0.01
: 1605633876:0;mv cartography_confidence_0.* bert_easy_mnli
: 1605637125:0;chmod +x carto.sh
: 1605637178:0;mv carto cartography/bert_base
: 1605637295:48;pip install git+https://github.com/huggingface/transformers@189113d8910308b9f3509c6946b2147ce57a0bf7
: 1605637548:0;rm -r roberta_large
: 1605637551:0;nohup /home/nlp/cartography/carto.sh
: 1605598610:0;rm samples.pth
: 1605598622:2;git clone https://github.com/allenai/cartography.githttps://github.com/prajjwal1/transformer-editorial
: 1605598634:9;git clone https://github.com/allenai/cartography.git
: 1605598669:0;cd configs
: 1605598835:57;pip install --user jsonnet 
: 1605599526:138;pip install transformers==2.0.0
: 1605599749:2;vim req
: 1605599805:1;pip install \
git+git://github.com/huggingface/transformers@189113d8910308b9f3509c6946b2147ce57a0bf7
: 1605599876:38;pip install --user git+https://github.com/huggingface/transformers@189113d8910308b9f3509c6946b2147ce57a0bf7
: 1605600275:3;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1605600566:3;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto \\
-- overwrite_output_dir
: 1605600761:1;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto \\
--overwrite_output_dir
: 1605602019:1;rm -r carto
: 1605602211:10;vim cartography/classification/params.py
: 1605602228:26;vim cartography/classification/run_glue.py
: 1605602317:20973;CUDA_VISIBLE_DEVICES=0 python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1605627075:103;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto --metric confidence --data_dir /home/nlp/data/glue_data/MNLI/train.tsv
: 1605628081:1;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto --metric confidence --data_dir /home/nlp/data/glue_data/
: 1605628140:102;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto --metric variability --data_dir /home/nlp/data/glue_data/MNLI/train.tsv
: 1605628294:376;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto --metric variability --data_dir /home/nlp/data/glue_data/
: 1605628984:491;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto --metric confidence --data_dir /home/nlp/data/glue_data/ 
: 1605629509:0;mkdir bert_hard_mnli
: 1605629520:0;mv cartography_confidence_0.* bert_hard_mnli
: 1605629530:0;mkdir bert_ambiguous_mnli
: 1605629538:1;mv cartography_variability_0.* bert_ambiguous_mnli
: 1605629547:0;mkdir bert_easy_mnli
: 1605629563:433;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto --metric confidence --data_dir /home/nlp/data/glue_data/ --worst
: 1605630831:0;echo "CUDA_VISIBLE_DEVICES=0 python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval -o /home/nlp/carto" >> carto.sh
: 1605631331:46;pip install transformers==3.1
: 1605631751:0;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_hard_mnli/"cartography_confidence_"$val  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 
: 1605631755:15;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_hard_mnli/"cartography_confidence_"$val  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512; done
: 1605632494:45;pip install transformers==3.0
: 1605632544:27;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_hard_mnli/"cartography_confidence_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512; done
: 1605632706:3;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_hard_mnli/"cartography_confidence_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train; done
: 1605632772:659;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_hard_mnli/"cartography_confidence_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605633455:14;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_hard_mnli/"cartography_variability_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605633507:339;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_ambiguous_mnli/"cartography_variability_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605633904:53;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_easy_mnli/"cartography_confidence_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605634118:4;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_easy_mnli/"cartography_confidence_"$val/MNLI  --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 8.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605634143:84;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_ambiguous_mnli/"cartography_variability_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 8.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605634808:3;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/blah  --fp16 --data_pct 0.01 --do_train --evaluate_during_training --eval_steps 8 --overwrite_output_dir --per_device_eval_batch_size 512
: 1605634851:18;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/blah  --fp16 --data_pct 0.01 --do_train  --overwrite_output_dir --per_device_eval_batch_size 512
: 1605635027:19;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/blah  --fp16 --data_pct 0.01 --do_train  --overwrite_output_dir --per_device_eval_batch_size 512 --overwrite_cache
: 1605635400:6;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/blah  --fp16 --data_pct 0.01 --do_train  --overwrite_output_dir --per_device_eval_batch_size 512 --overwrite_cache --do_train
: 1605635411:108;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 50.0   --output_dir /home/nlp/experiments/blah  --fp16 --data_pct 0.01 --do_train  --overwrite_output_dir --per_device_eval_batch_size 512 --do_train
: 1605635537:351;python3 subsampling_mnli.py   --model_name_or_path bert-large-uncased --task_name $TASK_NAME  --do_eval  --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80  --per_device_train_batch_size 256   --learning_rate 2e-5   --num_train_epochs 5.0   --output_dir /home/nlp/experiments/blah  --fp16 --data_pct 0.05 --do_train  --overwrite_output_dir --per_device_eval_batch_size 512 --do_train
: 1605636354:385;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_ambiguous_mnli/"cartography_variability_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/bert_base_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605703640:437;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/cartography/roberta_large --metric confidence --data_dir /home/nlp/data/glue_data/
: 1605704147:0;mkdir roberta_large_hard
: 1605704155:0;mv cartography_confidence_0.* roberta_large_hard
: 1605704163:0;mkdir roberta_large_ambiguous
: 1605704169:0;mkdir roberta_large_easy
: 1605704192:633;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/cartography/roberta_large --metric variability --data_dir /home/nlp/data/glue_data/
: 1605705391:0;mv cartography_variability_0.* roberta_large_ambiguous
: 1605705408:1394;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/cartography/roberta_large --metric confidence --data_dir /home/nlp/data/glue_data/ --worst
: 1605706873:0;mv cartography_confidence_0.* roberta_large_easy
: 1605707006:6;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_hard/"cartography_variability_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605707050:37;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_hard/"cartography_confidence_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_hard/$val/ --fp16 --per_device_eval_batch_size 512 --do_train --overwrite_output_dir; done
: 1605707125:474;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_hard/"cartography_confidence_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_hard/$val/ --fp16 --per_device_eval_batch_size 256 --do_train --overwrite_output_dir; done
: 1605707612:0;cd ../cartography/filtered/roberta_large_hard
: 1605707636:42;vim train.tsv
: 1605707685:15;vim dev_matched.tsv
: 1605707731:6;vim ../../../../../data/glue_data/MNLI/dev_matched.tsv
: 1605707756:0;//..
: 1605707760:0;cd nl
: 1605707767:0;cd /home
: 1605707769:0;cd blackbird
: 1605707774:0;cd projects_heavy
: 1605707778:0;cd NLP
: 1605707783:0;cd ../../../
: 1605707786:0;cd nlp
: 1605707887:22;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir $GLUE_DIR/$TASK_NAME/   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/random_large --fp16 --per_device_eval_batch_size 256 --overwrite_output_dir
: 1605707959:19;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_easy/cartography_confidence_0.25   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 2.0  --output_dir /home/nlp/experiments/cartography/random_large --fp16 --per_device_eval_batch_size 256 --overwrite_output_dir
: 1605708016:78;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_easy/cartography_confidence_0.25/MNLI   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 2.0  --output_dir /home/nlp/experiments/cartography/random_large --fp16 --per_device_eval_batch_size 256 --overwrite_output_dir
: 1605708112:662;python3 run_glue.py   --model_name_or_path roberta-large --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_easy/cartography_confidence_0.25/MNLI   --max_seq_length 80   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 2.0  --output_dir /home/nlp/experiments/cartography/random_large --fp16 --per_device_eval_batch_size 256 --overwrite_output_dir --do_train
: 1605709167:520;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/cartography/roberta_large_easy_pct_025_epoch_2 --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_hard/"cartography_confidence_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_hard/$val/ --fp16 --per_device_eval_batch_size 256 --do_train --overwrite_output_dir; done
: 1605709725:111;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/cartography/roberta_large_easy_pct_025_epoch_2 --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_hard/"cartography_variability_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_ambiguous/$val/ --fp16 --per_device_eval_batch_size 256 --do_train --overwrite_output_dir; done
: 1605709895:0;for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/cartography/roberta_large_easy_pct_025_epoch_2 --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_ambiguous/"cartography_variability_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_ambiguous/$val/ --fp16 --per_device_eval_batch_size 256 --do_train --overwrite_output_dir; done
: 1605721667:0;cd roberta_large_ambiguous
: 1605721673:0;cd 0.75
: 1605721679:0;cd 0.50
: 1605721729:0;echo "for val in 0.01 0.05 0.10 0.17 0.25 0.33 0.50 0.75; do python3 run_glue.py   --model_name_or_path /home/nlp/experiments/cartography/roberta_large_easy_pct_025_epoch_2 --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/roberta_large_ambiguous/"cartography_variability_"$val/MNLI  --max_seq_length 90   --per_device_train_batch_size 256 --learning_rate 2e-5  --num_train_epochs 4.0  --output_dir /home/nlp/experiments/cartography/roberta_large_ambiguous/$val/ --fp16 --per_device_eval_batch_size 256 --do_train --overwrite_output_dir; done" >> run_glue.sh
: 1605721760:0;chmod +x run_glue.sh
: 1605721830:0;ls ../experiments/cartography/roberta_large_ambiguous
: 1605721833:0;ls ../experiments/cartography/roberta_large_ambiguous/0.01
: 1605721847:0;cat ../experiments/cartography/roberta_large_ambiguous/0.01/eval_results_mnli
: 1605759523:0;cd bert_base_ambiguous
: 1605759615:0;cd ../cartography/filtered
: 1605759643:0;ls bert_base_ambiguous_mnli
: 1605766076:0;ls experiments/cartography/bert_base_hard
: 1605766087:0;ls experiments/cartography/bert_base_hard/0.25
: 1605766094:0;ls experiments/cartography/bert_base_hard/0.17
: 1605766290:0;ls /home/nlp/cartography/bert_base
: 1605768217:0;ls /home/nlp/cartography/filtered/bert_base_
: 1605777484:0;ls ../experiments/cartography/roberta_large_
: 1605844566:0;mv nohup.out abstract.txt
: 1605851961:0;mv nohup.out headline.txt
: 1605665207:33;vim cartography/carto.sh
: 1605746163:0;cd roberta_large_hard
: 1605752426:0;ls ../experiments/cartography/roberta_large_hard
: 1605752829:11;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_base_easy/cartography_confidence_0.25/MNLI   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 2.0  --output_dir /home/nlp/experiments/cartography/bert-base-easy_pct_025_epoch_2 --fp16 --per_device_eval_batch_size 512 --overwrite_output_dir --do_train
: 1605752893:10;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_base_easy/cartography_confidence_0.25/MNLI   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 2.0  --output_dir /home/nlp/experiments/cartography/bert-base-easy_pct_025_epoch_2 --fp16 --per_device_eval_batch_size 512 --overwrite_output_dir --do_train --overwrite_cache
: 1605753066:263;python3 run_glue.py   --model_name_or_path bert-base-uncased --task_name $TASK_NAME   --do_eval   --data_dir /home/nlp/cartography/filtered/bert_base_easy_mnli/cartography_confidence_0.25/MNLI   --max_seq_length 80   --per_device_train_batch_size 512 --learning_rate 2e-5  --num_train_epochs 2.0  --output_dir /home/nlp/experiments/cartography/bert-base-easy_pct_025_epoch_2 --fp16 --per_device_eval_batch_size 512 --overwrite_output_dir --do_train
: 1605754670:0;cat ../experiments/cartography/roberta_large_ambiguous/0.01/eval_results_mnli.txt
: 1605754682:0;cat ../experiments/cartography/roberta_large_ambiguous/0.05/eval_results_mnli.txt
: 1605754694:0;cat ../experiments/cartography/roberta_large_ambiguous/0.10/eval_results_mnli.txt
: 1605754703:0;cat ../experiments/cartography/roberta_large_ambiguous/0.17/eval_results_mnli.txt
: 1605754712:0;cat ../experiments/cartography/roberta_large_ambiguous/0.25/eval_results_mnli.txt
: 1605754720:0;cat ../experiments/cartography/roberta_large_ambiguous/0.33/eval_results_mnli.txt
: 1605754729:0;cat ../experiments/cartography/roberta_large_ambiguous/0.50/eval_results_mnli.txt
: 1605754738:0;cat ../experiments/cartography/roberta_large_ambiguous/0.75/eval_results_mnli.txt
: 1605754787:0;cat ../experiments/cartography/bert_base_ambiguous/0.01/eval_results_mnli.txt
: 1605754800:0;cat ../experiments/cartography/bert_base_ambiguous/0.05/eval_results_mnli.txt
: 1605754813:0;cat ../experiments/cartography/bert_base_ambiguous/0.10/eval_results_mnli.txt
: 1605756465:0;cat ../experiments/cartography/bert_base_ambiguous/0.17/eval_results_mnli.txt
: 1605756478:0;cat ../experiments/cartography/bert_base_ambiguous/0.25/eval_results_mnli.txt
: 1605759445:4;python3 k.py
: 1605759752:10;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/cartography/filtered/bert_base_ambiguous_mnli/"cartography_variability_"$val/MNLI --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/bert_base_ambiguous/$val\
; done
: 1605759803:11;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/bert_base_ambiguous/$val\
; done
: 1605759834:9;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/bert_base_ambiguous/$val\
; done
: 1605760094:326;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/bert_base_ambiguous/$val --overwrite_cache\
; done
: 1605761421:677;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/roberta_large_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/roberta_large_ambiguous/$val --overwrite_cache\
; done
: 1605763829:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.01/hans_predictions.txt
: 1605763866:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.05/hans_predictions.txt
: 1605763876:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.10/hans_predictions.txt
: 1605763889:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.17/hans_predictions.txt
: 1605763961:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.25/hans_predictions.txt
: 1605764005:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.50/hans_predictions.txt
: 1605764030:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.75/hans_predictions.txt
: 1605764071:0;cd ../../transformers-importance-sampling/
: 1605764096:97;for val in 0.33; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/roberta_large_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/roberta_large_ambiguous/$val --overwrite_cache\
; done
: 1605764218:48;for val in 0.33; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_ambiguous/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/cartography/bert_base_ambiguous/$val --overwrite_cache\
; done
: 1605764334:0;ls ../../experiments/cartography/bert_base_ambiguous/0.33
: 1605764351:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_ambiguous/0.33/hans_predictions.txt
: 1605764414:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.01/hans_predictions.txt
: 1605764424:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.10/hans_predictions.txt
: 1605764450:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.17/hans_predictions.txt
: 1605764474:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.25/hans_predictions.txt
: 1605764499:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.33/hans_predictions.txt
: 1605764519:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.50/hans_predictions.txt
: 1605764540:0;M\
python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.75/hans_predictions.txt
: 1605764836:0;cat ../experiments/cartography/bert_base_ambiguous/0.50/eval_results_mnli.txt
: 1605764969:0;cat experiments/cartography/bert_base_ambiguous/0.01
: 1605764975:0;cat experiments/cartography/bert_base_ambiguous/0.01/eval_results_mnli.txt
: 1605764980:0;cat experiments/cartography/bert_base_ambiguous/0.05/eval_results_mnli.txt
: 1605764986:0;cat experiments/cartography/bert_base_ambiguous/0.10/eval_results_mnli.txt
: 1605764994:0;cat experiments/cartography/bert_base_ambiguous/0.17/eval_results_mnli.txt
: 1605765000:0;cat experiments/cartography/bert_base_ambiguous/0.25/eval_results_mnli.txt
: 1605765011:0;cat experiments/cartography/bert_base_ambiguous/0.50/eval_results_mnli.txt
: 1605765021:0;cat experiments/cartography/bert_base_ambiguous/0.75/eval_results_mnli.txt
: 1605765060:0;cat experiments/cartography/bert_base_ambiguous/0.33/eval_results_mnli.txt
: 1605765136:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_ambiguous/0.05/hans_predictions.txt
: 1605766054:2;vim run_glue.
: 1605770010:0;ls ../experiments/cartography/roberta_large_hard/0.50
: 1605770015:0;ls ../experiments/cartography/roberta_large_hard/0.33
: 1605777492:9;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/roberta_large_hard/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 512 --output_dir=/home/nlp/experiments/cartography/roberta_large_hard/$val --overwrite_cache\
; done
: 1605777506:648;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/roberta_large_hard/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 512 --output_dir=/home/nlp/experiments/cartography/roberta_large_hard/$val\
; done
: 1605778724:260;for val in 0.01 0.05 0.10 0.17 0.25 0.50 0.75; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_hard/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 512 --output_dir=/home/nlp/experiments/cartography/bert_base_hard/$val\
; done
: 1605779060:1;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.01/hans_predictions.txt
: 1605779110:1;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.05/hans_predictions.txt
: 1605779129:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.10/hans_predictions.txt
: 1605779149:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.17/hans_predictions.txt
: 1605779180:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.25/hans_predictions.txt
: 1605779218:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.50/hans_predictions.txt
: 1605779254:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.75/hans_predictions.txt
: 1605779307:0;cd ../transformers-importance-sampling/hans
: 1605779408:1;for val in 0.33; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/bert_base_hard/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 512 --output_dir=/home/nlp/experiments/cartography/bert_base_hard/$val\
; done
: 1605779430:92;for val in 0.33; do python3 run_hans.py --model_name_or_path /home/nlp/experiments/cartography/roberta_large_hard/$val --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 80 --per_device_eval_batch_size 512 --output_dir=/home/nlp/experiments/cartography/roberta_large_hard/$val\
; done
: 1605779542:0;python3 evaluate_heur_output.py ~/experiments/cartography/roberta_large_hard/0.33/hans_predictions.txt
: 1605779668:0;cat ../../../experiments/cartography/roberta_large_hard/0.01/eval_results_mnli
: 1605779670:0;cat ../../../experiments/cartography/roberta_large_hard/0.01/eval_results_mnli.txt
: 1605779680:0;cat ../../../experiments/cartography/roberta_large_hard/0.05/eval_results_mnli.txt
: 1605779687:0;cat ../../../experiments/cartography/roberta_large_hard/0.10/eval_results_mnli.txt
: 1605779703:0;cat ../../../experiments/cartography/roberta_large_hard/0.17/eval_results_mnli.txt
: 1605779712:0;cat ../../../experiments/cartography/roberta_large_hard/0.25/eval_results_mnli.txt
: 1605779722:0;cat ../../../experiments/cartography/roberta_large_hard/0.33/eval_results_mnli.txt
: 1605779731:0;cat ../../../experiments/cartography/roberta_large_hard/0.50/eval_results_mnli.txt
: 1605779739:0;cat ../../../experiments/cartography/roberta_large_hard/0.75/eval_results_mnli.txt
: 1605779778:0;cat ../../../experiments/cartography/bert_base_hard/0.01/eval_results_mnli
: 1605779782:0;cat ../../../experiments/cartography/bert_base_hard/0.01/eval_results_mnli.txt 
: 1605779791:0;cat ../../../experiments/cartography/bert_base_hard/0.05/eval_results_mnli.txt 
: 1605779799:0;cat ../../../experiments/cartography/bert_base_hard/0.10/eval_results_mnli.txt 
: 1605779807:0;cat ../../../experiments/cartography/bert_base_hard/0.17/eval_results_mnli.txt 
: 1605779816:0;cat ../../../experiments/cartography/bert_base_hard/0.25/eval_results_mnli.txt 
: 1605779825:0;cat ../../../experiments/cartography/bert_base_hard/0.33/eval_results_mnli.txt 
: 1605779835:0;cat ../../../experiments/cartography/bert_base_hard/0.50/eval_results_mnli.txt 
: 1605779844:0;cat ../../../experiments/cartography/bert_base_hard/0.75/eval_results_mnli.txt 
: 1605779866:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.01/hans_predictions.txt
: 1605779885:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.05/hans_predictions.txt
: 1605779895:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.10/hans_predictions.txt
: 1605779916:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.17/hans_predictions.txt
: 1605779926:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.25/hans_predictions.txt
: 1605779935:0;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.33/hans_predictions.txt
: 1605779943:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.50/hans_predictions.txt
: 1605779965:1;python3 evaluate_heur_output.py ~/experiments/cartography/bert_base_hard/0.75/hans_predictions.txt
: 1605780985:1;pip install transformers
: 1605854022:671;vim headline.txt
: 1605859429:4;jupyter notebook stop 8888
: 1605859436:0;jupyter notebook stop 8889
: 1605859470:0;jupyter notebook stop 8890
: 1605859472:1;jupyter notebook list
: 1605746104:0;ls ../experiments/cartography/roberta_large_ambiguous/0.75
: 1605746373:0;mv nohup.out roberta_ambi.txt
: 1605746387:6024;nohup /home/nlp/transformers-importance-sampling/run_glue.sh
: 1605752617:0;cd ../../cartography
: 1605752625:0;ls filtered
: 1605752751:0;mv bert_easy_mnli bert_base_easy_mnli
: 1605752768:0;mv bert_ambiguous_mnli bert_base_ambiguous_mnli
: 1605752780:1;mv bert_hard_mnli bert_base_hard_mnli
: 1605752854:0;ls bert_base_mn
: 1605752864:0;ls bert_base_easy_mnli
: 1605752929:0;cd bert_base_easy_mnli/cartography_confidence_0.25
: 1605753616:0;mv bert-base-easy_pct_025_epoch_2 bert_base_easy_pct_025_epoch_2
: 1605753652:0;ls ../
: 1605753658:0;ls ../../cartography/filtered
: 1605758866:0;vim k.py
: 1605768345:0;cd cartography/roberta_large
: 1605709123:0;cd experiments/cartography
: 1605709151:0;mv random_large roberta_large_easy_pct_025_epoch_2
: 1607051124:1;git commit -m "upload "
: 1607052598:0;tad tfmr
: 1607052620:0;pip install transformers --upgrade
: 1607063145:0;ls apex/transformer-editorial
: 1607063217:0;mkdir nbs
: 1607063222:0;mv *.ipynb nbs
: 1607063231:0;mv *.json data
: 1607063237:0;vim abstract.txt
: 1607063272:0;git commit -m "synthetic datasets"
: 1607063726:0;bash --version
: 1607070491:0;vim run_edit.py
: 1607070574:0;vim data/synthetic_neg.json
: 1607136237:0;mv nohup.out body.txt
: 1607151378:0;vim body.txt
: 1607157409:0;cd nbs
: 1607157413:0;rm *.pdf
: 1607157425:0;rm body.txt
: 1607157435:0;git commit -m "synthetic results"
: 1607165473:0;ls ../../experiments/edit_synthetic/third_option/lf_body/0
: 1607166032:0;cd experiments/edit_synthetic
: 1607166039:0;mv third_option neg
: 1607167675:0;jupyter stop 8889
: 1607220528:0;cd ../../experiments/edit_synthetic
: 1607220532:0;cd third_option
: 1607220548:0;rm -rf body
: 1607252063:0;ls ../../experiments/edit_synthetic/third_option/
: 1607252090:0;nohup /home/nlp/apex/transformer-editorial/run_glue.sh
: 1607257483:0;sh runrun_glue.sh
: 1607314478:0;ls nbs
: 1607314526:0;mv synthetic_thesis.json data
: 1609052423:0;pip install datasets --upgrade
: 1609056289:0;pip uninstall datasets
: 1609056969:0;vim discourse.ipynb
: 1609056979:0;vim discovery.py
: 1610001676:0;git addd .
: 1610001727:0;echo "python3 run_edit.py --model_name_or_path allenai/longformer-base-4096 --output_dir /home/nlp/experiments/edit --per_device_train_batch_size 8 --per_device_eval_batch_size 16 --do_eval --do_train --evaluation_strategy epoch --num_train_epochs 3 --k 2 --fold 5" >> README.md
: 1610001759:0;git commit -m "update"
: 1610934806:0;vim dis.py
: 1610935392:0;jupyter notebook --no-browser --port=8889
: 1610999098:0;cd apex/transformer-editorial
: 1610999151:0;p3 run.py
: 1610999185:0;vim run.py
: 1610999198:0;vim run.sh
: 1610999215:0;chmod +x run.sh
: 1610999222:0;nohup /home/nlp/apex/run.sh
: 1611066111:0;vim fuse_con.txt
: 1611148197:0;cd roberta_large
: 1611148218:0;cd sample
: 1611148250:0;cd bert_base_easy_mnli
: 1611148415:0;cd cartography_confidence_0.01
: 1611148421:0;cd MNLI
: 1611148431:0;cd ../../..
: 1611148440:0;vim carto.sh
: 1611148487:0;ls roberta_large
: 1611148501:0;ls roberta_large/training_
: 1611148503:0;ls roberta_large/training_dynamics
: 1611169402:0;pip install --user torch
: 1611169410:0;pip install --user torch --upgrade
: 1611270590:0;git commit -m "initial nb"
: 1611345812:0;mkdir clm
: 1611345942:0;python3 run_clm.py \\
    --model_name_or_path gpt2 \\
    --dataset_name discofuse \\
    --dataset_config_name discofuse \\
    --do_train \\
    --do_eval \\
    --output_dir /home/nlp/apex/commonsense-discourse/output_of_train
: 1611345961:0;python3 run_clm.py \\
    --model_name_or_path gpt2 \\
    --dataset_name discofuse \\
    --dataset_config_name discofuse-wikipedia \\
    --do_train \\
    --do_eval \\
    --output_dir /home/nlp/apex/commonsense-discourse/output_of_train
: 1611346666:0;python3 run_clm.py \\
    --model_name_or_path gpt2-large \\
    --dataset_name discofuse \\
    --dataset_config_name discofuse-wikipedia \\
    --do_train \\
    --do_eval \\
    --output_dir /home/nlp/apex/commonsense-discourse/output_of_train
: 1611346689:0;python3 run_clm.py \\
    --model_name_or_path gpt2-large \\
    --dataset_name discofuse \\
    --dataset_config_name discofuse-wikipedia \\
    --do_train \\
    --do_eval \\
    --output_dir /home/nlp/apex/commonsense-discourse/output_of_train \\
--use_fast_tokenizer
: 1611346919:0;vim run_clm.py
: 1611349334:0;mv run_clm.py run_clm_discofuse.py
: 1611349452:0;python3 run_clm.py \\
    --model_name_or_path gpt2-large \\
    --dataset_name discofuse \\
    --dataset_config_name discofuse-wikipedia \\
    --do_train \\
    --do_eval \\
    --output_dir /home/nlp/apex/commonsense-discourse/output_of_train \\
--use_fast_tokenizer=True
: 1611349548:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --use_fast_tokenizer
: 1611350200:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment 
: 1611353657:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_batch_size 4
: 1611353763:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 4
: 1611353818:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 2
: 1611354847:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 2 --deepspeed
: 1611355007:0;pip install --user deepspeed
: 1611355171:0;deepspeed --num_gpus=2 ./run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 2 --deepspeed
: 1611355350:0;deepspeed --num_gpus=2 ./run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 2 --deepspeed ds_config_1gpu.json
: 1611361138:0;deepspeed --num_gpus=2 ./run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 4 --deepspeed ds_config_1gpu.json
: 1611362339:0;python3 run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 1
: 1611362345:0;deepspeed --num_gpus=2 ./run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 4 --deepspeed ds_config_1gpu.json --overwrite_cache
: 1611363858:0;deepspeed --num_gpus=2 ./run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment --per_device_train_batch_size 4 --deepspeed ds_config_1gpu.json 
: 1611364466:0;echo "deepspeed --num_gpus=2 ./run_clm_discofuse.py --model_name_or_path gpt2-large --dataset_name discofuse --dataset_config_name discofuse-wikipedia --do_train --do_eval --output_dir /home/nlp/apex/experiment/train_gpt2_discofuse --per_device_train_batch_size 4 --deepspeed ds_config_1gpu.json" >> train_fuse.py 
: 1611364476:0;mv train_fuse.sh
: 1611364483:0;mv train_fuse.py train_fuse.sh
: 1611364493:0;chmod +x train_fuse.sh
: 1611439175:0;cd train_gpt2_discofuse
: 1611439192:0;cd ../../commonsense-discourse/clm
: 1611450821:0;git commit -m "gpt2_train"
: 1611589755:0;pip installl --user transformers=3.3
: 1611589760:0;pip install --user transformers=3.3
: 1611589764:0;pip install --user transformers==3.3
: 1611590126:0;ls bert_base
: 1611590428:0;ls filtered/bert_base_easy_mnli
: 1611590538:0;ls filtered/bert_base_easy_mnli/cartography_confidence_0.10
: 1611593195:0;ls filtered/bert_base_hard_mnli/cartography_confidence_0.10
: 1611598793:0;pip install --user nlpaug
: 1611599083:0;wget https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\?usp\=sharing
: 1611599114:0;rm edit\?usp=sharing
: 1611611295:0;pip install --user nltk
: 1611618966:0;cp run_clm_discofuse.py run_clm_disovery.py
: 1611618985:0;mv run_clm_disovery.py run_clm_discovery.py
: 1611619490:0;vim clm/run_clm_discofuse.py
: 1611619948:0;pip install --user transformers --upgrade
: 1611620424:0;pip install --user transformers 
: 1611620943:0;pip install --user transformers  install git+https://github.com/huggingface/transformers.git
: 1611621023:0;pip uninstall transformers install git+https://github.com/huggingface/transformers.git
: 1611621042:0;pip install transformers install git+https://github.com/huggingface/transformers.git
: 1611622348:0;vim ../data/discovery_con.py
: 1611674714:0;ls experiment/train_gpt2_discovery
: 1611674741:0;cd experiment/train_gpt2_discovery
: 1611674747:0;pwdd
: 1611678877:0;ls clm
: 1611678883:0;cd clm
: 1611679114:0;mv clm training
: 1611681482:0;pip install transformers install git+https://github.com/huggingface/transformers.git --upgrade
: 1611681625:0;pip uninstall -ransformers
: 1611681662:0;pip install transformers install git+https://github.com/huggingface/transformers.git --upgrade --no-cache-dir
: 1611681889:0;python3 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_batch_size 64 --output_dir /home/nlp/apex/experiment/seq_clas 
: 1611683376:0;python3 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 64 --output_dir /home/nlp/apex/experiment/seq_clas 
: 1611684638:0;python3 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 64 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16
: 1611685512:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed 
: 1611685541:0;vim ds_config_1gpu.json
: 1611685658:0;mv ds_config_1gpu.json ds_confi.json
: 1611685666:0;mv ds_confi.json ds_config.json
: 1611685806:59;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 288 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json
: 1611685873:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 272 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json
: 1611685998:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json
: 1611686703:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json --master_port 29500
: 1611686738:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json --master_port 29501
: 1611687020:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json --master_port 5001
: 1611687111:0;fuser -k 29500/tcp
: 1611687154:0;fuser 29500/tcp
: 1611687157:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 196 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json 
: 1611687335:0;kill -9 92495
: 1611687342:0;kill -9 96193
: 1611687368:0;deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json 
: 1611688214:0;echo "deepspeed --num_gpus=2 run_seq_clas.py --model_name_or_path microsoft/DialoGPT-large --do_train --do_eval --max_seq_length 32 --per_device_train_batch_size 256 --output_dir /home/nlp/apex/experiment/seq_clas  --fp16 --deepspeed ds_config.json" >> train_fuse.sh 
: 1611688229:0;nohup /home/nlp/apex/commonsense-discourse/clm/train_fuse.sh
: 1611761026:0;pip install transformers==3.3.1
: 1611761133:0;pip uninstall transformers
: 1611761166:0;pip install transformers==3.3.1 --no-cache-dir
: 1611761307:0;vim /home/nlp/transformers-importance-sampling/run_glue.
: 1611761567:0;vim /home/nlp/transformers-importance-sampling/run_glue.py
: 1611768721:0;rm wikitext-2-v1.zip
: 1611768733:0;rm wikitext-2raw--v1.zip
: 1611768736:0;rm wikitext-2raw-v1.zip
: 1611768747:0;rm wikitext-2-raw-v1.zip
: 1611769095:0;unzip GoogleNews-vectors-negative300.zip
: 1611769535:0;rm GoogleNews-vectors-negative300.zip
: 1611769539:0;wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz 
: 1611769887:0;tar -xzvf GoogleNews-vectors-negative300.bin.gz
: 1611769915:0;rm '*
: 1611769927:0;rm $*
: 1611769931:0;rm \$*
: 1611769937:0;rm 274
: 1611769939:0;rm *274
: 1611769953:0;rm \= $'\017'=
: 1611769983:0;rm $'\201'$'\276' $'\274' $'\275' $'\357'$'\275' \? 5$'\276'
: 1611769993:0;rm d$'\276'
: 1611770002:0;rm 'Sigalla '
: 1611770008:0;rm 'ternational '
: 1611770037:0;gunzip GoogleNews-vectors-negative300.bin.gz
: 1611775597:0;chmod +x /home/nlp/apex/commonsense-discourse/script.sh
: 1611775607:0;nohup /home/nlp/apex/commonsense-discourse/script.sh
: 1611790226:0;mkdir runs
: 1611790272:0;kill -9 97435
: 1611790288:0;kill -9 97394
: 1611790308:0;kill -9 97436
: 1611790663:0;git commit -m "heuristics nb"
: 1611790687:0;git push origin alpha
: 1611791805:0;git clone https://github.com/huggingface/transformers
: 1611792232:0;mv transformers/src/transformers l
: 1611792269:0;mv l transformers
: 1611792308:0;git clone https://github.com/huggingface/tokenizers
: 1611792348:0;mv tokenizers/tokenizers l
: 1611792365:0;mv l tokenizers
: 1611792380:0;rm -r tokenizers
: 1611792391:0;pip install tokenizers==0.9.4
: 1611792702:0;ls runs
: 1611792707:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh
: 1611805432:0;ls /home/nlp/data
: 1611805543:0;rm nohup.out
: 1611805553:0;ls
: 1611805560:0;vim get_heuristics_stats.py
: 1611805575:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611805584:0;vim nohup.out
: 1611805587:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611805633:0;nvidia-smi  
: 1611805636:0;cd training
: 1611805639:0;vim nohup.out
: 1611843931:0;cd apex/commonsense-discourse
: 1611843934:0;vim nohup.out
: 1611843967:0;rm nohup.out
: 1611843968:0;ls
: 1611843973:0;vim get_heuristics_stats.py
: 1611844028:0;ls data
: 1611844058:0;rm nohup.out
: 1611844069:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611844075:0;vim nohup.out
: 1611844080:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611844105:0;nvidia-smi  
: 1611845548:0;cd apex/commonsense-discourse/training
: 1611845553:0;vim nohup.out
: 1611846106:0;ls
: 1611846110:0;vim train_fuse.sh
: 1611846121:0;jupyter notebook --no-browser --port=8888
: 1611846169:0;cd ..
: 1611846175:0;jupyter notebook --no-browser --port=8888
: 1611846218:0;cd apex/commonsense-discourse/training
: 1611846219:0;ls
: 1611846222:0;cd ..
: 1611846231:0;cp training/transformers .
: 1611846241:0;cp -r training/transformers .
: 1611851934:0;rm nohup.out
: 1611851939:0;vim get_heuristics_stats.py
: 1611851960:0;vim nohup.out
: 1611851978:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611861138:0;vim nohup.out
: 1611861156:0;htop
: 1611861180:0;vim nohup.out
: 1611861236:0;vim get_heuristics_stats.py
: 1611861257:0;rm nohup.out
: 1611861265:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611861268:0;vim nohup.out
: 1611861274:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611866310:0;ls
: 1611866315:0;cd training
: 1611866316:0;ls
: 1611866321:0;vim run_clm_discofuse.py
: 1611866326:0;vim run_clm_discovery.py
: 1611867110:0;cd apex/commonsense-discourse/training
: 1611867111:0;ls
: 1611867116:0;vim run_seq_clas.py
: 1611867206:0;ls
: 1611867369:0;cd /home/nlp/transformers-importance-sampling
: 1611867370:0;ls
: 1611867402:0;cd ..
: 1611867405:0;cd commonsense-discourse
: 1611867406:0;ls
: 1611867411:0;cd apex/commonsense-discourse/training
: 1611867413:0;cd ..
: 1611867414:0;ls
: 1611867416:0;vim get_heuristics_stats.py
: 1611867820:0;sh train_fuse.sh
: 1611867825:0;vim train_fuse.sh
: 1611870396:0;sh train_fuse.sh
: 1611870517:0;vim train_fuse.sh
: 1611870568:0;sh train_fuse.sh
: 1611870690:0;vim train_fuse.sh
: 1611870700:0;vim run_clm_discovery.py
: 1611870722:0;sh train_fuse.sh
: 1611870739:0;vim train_fuse.sh
: 1611870879:0;sh train_fuse.sh
: 1611870969:0;vim train_fuse.sh
: 1611870978:0;vim run_clm_discovery.py
: 1611871010:0;sh train_fuse.sh
: 1611871121:0;vim run_clm_discovery.py
: 1611871165:0;sh train_fuse.sh
: 1611871385:0;cd training
: 1611871388:0;vim run_clm_discovery.py
: 1611871452:0;sh train_fuse.sh
: 1611871688:0;vim run_clm_discovery.py
: 1611871704:0;sh train_fuse.sh
: 1611876178:0;cd ..
: 1611876179:0;ls
: 1611876182:0;vim get_heuristics_stats.py
: 1611876815:0;sh train_fuse.sh
: 1611876824:0;cd training
: 1611876827:0;sh train_fuse.sh
: 1611878463:0;ls
: 1611878469:0;vim train_fuse.sh
: 1611878813:0;sh train_fuse.sh
: 1611880363:33;vim nohup.out
: 1611880400:0;vim script.sh
: 1611880405:0;vim get_heuristics_stats.py
: 1611880525:0;sh script.sh
: 1611880529:0;vim get_heuristics_stats.py
: 1611880538:0;sh script.sh
: 1611880565:0;vim get_heuristics_stats.py
: 1611880583:0;sh script.sh
: 1611880911:0;sh train_fuse.sh
: 1611888309:0;git add .
: 1611888333:0;git status
: 1611888339:0;git add .
: 1611895373:0;vim get_heuristics_stats.py
: 1611895472:0;ls
: 1611895476:0;rm nohup.out
: 1611895485:0;nohup /home/nlp/apex/commonsense-discourse/script.sh 
: 1611930947:0;cd apex/commonsense-discourse/
: 1611930950:0;vim nohup.out
: 1611930983:0;rm nohup.out
: 1611930986:0;vim nohup.out
: 1611930992:0;ls
: 1611931002:0;vim get_heuristics_stats.py
: 1611931044:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611935583:0;cd apex/commonsense-discourse/training
: 1611935584:0;ls
: 1611935593:0;vim run_clm_discovery.py
: 1611935931:0;cd apex/commonsense-discourse/training
: 1611935933:0;sh train_fuse.sh
: 1611936733:0;jupyter notebook --no-browser --port=8888
: 1611937907:0;sh train_fuse.sh
: 1611941881:0;vim train_fuse.sh
: 1611941901:0;sh train_fuse.sh
: 1611941926:0;vim train_fuse.sh
: 1611941933:0;vim run_clm_discovery.py
: 1611942066:0;vim train_fuse.sh
: 1611942100:0;sh train_fuse.sh
: 1611942299:0;vim train_fuse.sh
: 1611942569:0;jupyter notebook --no-browser --port=8888
: 1611943061:0;cd apex/commonsense-discourse/training
: 1611943075:0;vim run_clm_discovery.py
: 1611943368:0;cd apex/commonsense-discourse/training
: 1611943370:0;sh train_fuse.sh
: 1611943403:0;vim train_fuse.sh
: 1611943443:0;vim run_clm_discovery.py
: 1611943475:0;vim ../get_heuristics_stats.py 
: 1611943511:0;vim run_clm_discovery.py
: 1611943549:0;sh train_fuse.sh
: 1611946690:0;cd apex/commonsense-discourse/
: 1611946692:0;vim nohup.out
: 1611946810:0;ls
: 1611946813:0;vim get_heuristics_stats.py
: 1611946913:0;ls
: 1611946915:0;rm nohup.out
: 1611946918:0;vim nohup.out
: 1611946926:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611946978:0;vim train_fuse.sh
: 1611947616:0;sh train_fuse.sh
: 1611948723:0;vim train_fuse.sh
: 1611948928:0;sh train_fuse.sh
: 1611949236:0;vim train_fuse.sh
: 1611949263:0;sh train_fuse.sh
: 1611949510:0;vim train_fuse.sh
: 1611949529:0;sh train_fuse.sh
: 1611950034:0;vim train_fuse.sh
: 1611950393:0;sh train_fuse.sh
: 1611951328:0;vim train_fuse.sh
: 1611951372:0;sh train_fuse.sh
: 1611951744:0;nvidia-smi  
: 1611952012:0;sh train_fuse.sh
: 1611952343:0;pip instal lmpi4y
: 1611952358:0;pip install --user mpi4y
: 1611952447:0;sh train_fuse.sh
: 1611952819:0;pip install --user mpi4y
: 1611952846:0;pip install --user mpi4py
: 1611952890:0;pip install mpi4py
: 1611952931:0;vim train_fuse.sh
: 1611952974:0;pip install mpi4py
: 1611952978:0;sh train_fuse.sh
: 1611953612:0;vim train_fuse.sh
: 1611953645:0;vim run_clm_discovery.py
: 1611953720:0;sh train_fuse.sh
: 1611963527:0;cd apex/commonsense-discourse/
: 1611963528:0;ls
: 1611963530:0;vim nohup.out
: 1611968095:0;cd apex/commonsense-discourse/
: 1611968098:0;ls
: 1611968104:0;cd training
: 1611968127:0;ls
: 1611968132:0;vim run_clm_discovery.py
: 1611968357:0;cd apex/commonsense-discourse/
: 1611968360:0;ls
: 1611968367:0;vim get_heuristics_stats.py
: 1611968426:0;cd training
: 1611968429:0;sh train_fuse.sh
: 1611969179:0;vim train_fuse.sh
: 1611969204:0;sh train_fuse.sh
: 1611969514:0;vim train_fuse.sh
: 1611969558:0;sh train_fuse.sh
: 1611969835:0;vim train_fuse.sh
: 1611969878:0;sh train_fuse.sh
: 1611970089:0;nvidia-smi  
: 1611970112:0;vim train_fuse.sh
: 1611970142:0;sh train_fuse.sh
: 1611970337:0;nvidia-smi  
: 1611970356:0;vim train_fuse.sh
: 1611970377:0;nvidia-smi  
: 1611970382:0;sh train_fuse.sh
: 1611970560:0;vim train_fuse.sh
: 1611970580:0;sh train_fuse.sh
: 1611970875:0;nvidia-smi  
: 1611970893:0;ls
: 1611970903:0;rm nohup.out
: 1611970908:0;vim nohup.out
: 1611970936:0;nohup /home/nlp/apex/commonsense-discourse/script.sh & tail -f nohup.out
: 1611970960:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1611970967:0;rm nohup.out
: 1611970969:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1611970976:0;ls
: 1611970988:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612020034:0;nvidia-smi  
: 1612020042:0;cd apex/commonsense-discourse/training
: 1612020044:0;ls
: 1612020047:0;vim nohup.out
: 1612054159:0;nvidia-smi  
: 1612054162:0;vim nohup.out
: 1612054176:0;git status
: 1612054193:0;ls
: 1612054197:0;cd ..
: 1612054198:0;ls
: 1612054203:0;vim .gitignore
: 1612054216:0;git status
: 1612054226:0;git add AF
: 1612054230:0;git add AF.ipynb
: 1612054238:0;git add data/discovery_con.py
: 1612054252:0;git add training/run_clm_discovery.py
: 1612054264:0;git add training/train_fuse.sh
: 1612054269:0;git status
: 1612054340:0;git reset
: 1612054346:0;git status
: 1612054356:0;git add AF.ipynb
: 1612054363:0;git add training/run_clm_discovery.py
: 1612054377:0;git add data/discovery_con.py
: 1612054381:0;git status
: 1612054393:0;git add training/run_seq_clas.py
: 1612054399:0;git add training/train_fuse.sh
: 1612054404:0;git add data/discovery_con.py
: 1612054407:0;git status
: 1612054424:0;git commit -m mackup"\
"
: 1612054441:0;git commit -m "backup"
: 1612054447:0;git push
: 1612054503:0;git status
: 1612054514:0;ls
: 1612061621:0;nvidia-smi  
: 1612061642:0;vim training/nohup.out
: 1612069100:0;nvidia-smi  
: 1612069104:0;vim training/nohup.out
: 1612071360:0;nvidia-smi  
: 1612071363:0;vim training/nohup.out
: 1612103672:0;cd apex/commonsense-discourse/training
: 1612103676:0;vim nohup.out
: 1612103807:0;ls
: 1612103815:0;vim run_clmm_discovery.py
: 1612103826:0;vim run_clm_discovery.py
: 1612104194:0;vim train_fuse.sh
: 1612104223:0;sh train_fuse.sh
: 1612104233:0;vim train_fuse.sh
: 1612104271:0;sh train_fuse.sh
: 1612105487:0;cd apex/commonsense-discourse/training
: 1612105490:0;vim nohup.out
: 1612106094:0;cd ..
: 1612106099:0;jupyter notebook --no-browser --port=8888
: 1612106430:0;cd ..
: 1612106430:0;ls
: 1612106444:0;cd ..
: 1612106445:0;ls
: 1612106465:0;cd ..
: 1612106481:0;cd apex
: 1612106482:0;ls
: 1612107222:0;cd training
: 1612107224:0;ls
: 1612107231:0;cd commonsense-discourse
: 1612107232:0;ls
: 1612107243:0;cd training
: 1612107243:0;ls
: 1612107248:0;vim run_clm_discovery.py
: 1612107323:0;rm -r /home/nlp/apex/experiment
: 1612107356:0;cd ../../experiment/
: 1612107356:0;ls
: 1612107364:0;rm -r *
: 1612107461:0;ls
: 1612107465:0;cd ..
: 1612107470:0;cd commonsense-discourse/training
: 1612107474:0;rm nohup.out
: 1612107479:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612107482:0;vim nohup.out
: 1612107492:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612107521:0;vim train_fuse.sh
: 1612107544:0;vim run_clm_discovery.py
: 1612107590:0;rm nohup.out
: 1612107593:0;vim nohup.out
: 1612107597:0;vim run_clm_discovery.py
: 1612107634:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612109272:0;vim run_clm_discovery.py
: 1612109307:0;vim train_fuse.sh
: 1612109340:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612113313:0;vim run_clm_discovery.py
: 1612113680:0;rm nohup.out
: 1612113684:0;vim nohup.out
: 1612113690:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612114542:0;vim run_clm_discovery.py
: 1612114569:0;rm nohup.out
: 1612114571:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612114575:0;vim nohup.out
: 1612114584:0;rm nohup.out
: 1612114587:0;vim nohup.out
: 1612114592:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612114740:0;vim run_clm_discovery.py
: 1612114759:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612115942:0;vim nohup.out
: 1612115947:0;vim train_fuse.sh
: 1612115972:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612116449:0;vim train_fuse.sh
: 1612116464:0;rm nohup.out
: 1612116467:0;vim nohup.out
: 1612116470:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612116940:0;nvidia-smi  
: 1612116951:0;htop
: 1612116986:0;ps -ef|grep python
: 1612117000:0;kill -9 1453035
: 1612117008:0;nvidia-smi  
: 1612117017:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612117031:0;vim train_fuse.sh
: 1612117052:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612117349:0;vim train_fuse.sh
: 1612117371:0;nvidia-smi  
: 1612117375:0;vim train_fuse.sh
: 1612117391:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612118227:0;nvidia-smi  
: 1612118233:0;vim train_fuse.sh
: 1612118254:0;vim run_clm_discovery.py
: 1612118479:0;rm nohup.out
: 1612118481:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612118484:0;vim nohup.out
: 1612118488:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612118695:0;vim run_clm_discovery.py
: 1612118710:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612118745:0;vim run_clm_discovery.py
: 1612118804:0;rm nohup.out
: 1612118807:0;vim nohup.out
: 1612118810:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612119010:0;vim run_clm_discovery.py
: 1612119074:0;rm nohup.out
: 1612119077:0;cat nohup.out
: 1612119109:0;touch nohup.out
: 1612119113:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612119140:0;vim run_clm_discovery.py
: 1612119143:0;vim train_fuse.sh
: 1612119264:0;rm nohup.out
: 1612119266:0;touch nohup.out
: 1612119296:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612119435:0;nvidia-smi  
: 1612119447:0;ps -ef|grep python
: 1612119457:0;kill -9 1571818
: 1612119460:0;nvidia-smi  
: 1612119465:0;rm nohup.out
: 1612119467:0;touch nohup.out
: 1612119469:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612119658:0;nvidia-smi  
: 1612119671:0;ps -ef|grep python
: 1612119681:0;kill -9 1575416
: 1612119683:0;nvidia-smi  
: 1612119690:0;vim train_fuse.sh
: 1612119705:0;rm nohup.out
: 1612119713:0;touch nohup.out
: 1612119718:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612123178:0;nvidia-smi  
: 1612123217:0;vim run_clm_discovery.py
: 1612123387:0;rm nohup.out
: 1612123392:0;touch nohup.out
: 1612123395:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612124292:0;vim run_clm_discovery.py
: 1612124343:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612129495:0;vim run_clm_discovery.py
: 1612129954:0;rm nohup.out
: 1612129956:0;touch nohup.out
: 1612129959:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612130103:0;vim run_clm_discovery.py
: 1612130118:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612130301:0;vim run_clm_discovery.py
: 1612130409:0;rm nohup.out
: 1612130410:0;touch nohup.out
: 1612130412:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612131367:0;vim run_clm_discovery.py
: 1612131378:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612131543:0;vim run_clm_discovery.py
: 1612131580:0;rm nohup.out
: 1612131583:0;touch nohup.out
: 1612131586:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612131751:0;vim run_clm_discovery.py
: 1612131835:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612139109:0;cd apex/experiment
: 1612139110:0;ls
: 1612139113:0;cd ctrl
: 1612139113:0;ls
: 1612139122:0;cd checkpoint-100
: 1612139127:0;cd checkpoint-1000
: 1612139129:0;ls
: 1612139138:0;vim merges.txt
: 1612139184:0;nvidia-smi  
: 1612139190:0;ps -ef|grep python
: 1612139200:0;kill -9 1594922
: 1612139239:0;vim run_clm_discovery.py
: 1612139453:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-1000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-1000 --per_device_eval_batch_size 32
: 1612139461:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-1000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-1000 --per_device_eval_batch_size 32 --fp16
: 1612144367:0;vim
: 1612144371:0;nvidia-smi  
: 1612144759:0;ls
: 1612144763:0;vim train_fuse.sh
: 1612144817:0;gitstatus
: 1612144820:0;git status
: 1612144829:0;git add.
: 1612144834:0;git add .
: 1612144846:0;git commit -m "fixed training"
: 1612144850:0;git push
: 1612144913:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612145198:0;nvidia-smi  
: 1612145208:0;vim train_fuse.sh
: 1612145226:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612189923:0;cd apex/experiment
: 1612189934:0;cd ..
: 1612189937:0;cd commonsense-discourse
: 1612189940:0;ls
: 1612189948:0;cd training
: 1612189953:0;vim nohup.out
: 1612189995:0;vim script.sh
: 1612189999:0;ls
: 1612190005:0;vim train_fuse.sh
: 1612190056:0;sh train_fuse.sh
: 1612190229:0;vim train_fuse.sh
: 1612190250:0;sh train_fuse.sh
: 1612190371:0;nvidia-smi  
: 1612190378:0;ps -ef|grep python
: 1612190387:0;kill -9 1917252
: 1612190393:0;sh train_fuse.sh
: 1612190404:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612194577:0;ls
: 1612194583:0;jupyter notebook --no-browser --port=8888
: 1612196526:0;ls
: 1612196533:0;vim run_clm_discovery.py
: 1612196892:0;cd ..
: 1612196897:0;git status
: 1612196899:0;ls
: 1612196918:0;mv get_heuristics_stats.py /home/nlp/transformers-importance-sampling
: 1612196933:0;vim script.sh
: 1612196938:0;rm script.sh
: 1612196943:0;ls
: 1612196951:0;git status
: 1612196956:0;git add .
: 1612196963:0;git commit -m "fixed training"
: 1612196967:0;git push
: 1612197112:0;ls
: 1612197114:0;cd training
: 1612197115:0;ls
: 1612197126:0;rm run_clm_discofuse.py
: 1612197137:0;ls
: 1612197141:0;rm nohup.out
: 1612197142:0;ls
: 1612197147:0;wget https://github.com/salesforce/ctrl/blob/master/ctrl-vocab.json\?raw\=true
: 1612197152:0;ls
: 1612197175:0;rm 'ctrl-vocab.json?raw=true'
: 1612197178:0;wget https://raw.githubusercontent.com/salesforce/ctrl/master/ctrl-vocab.json
: 1612197181:0;ls
: 1612197213:0;wget https://raw.githubusercontent.com/salesforce/ctrl/master/ctrl-merges.txt
: 1612197216:0;ls
: 1612197460:0;vim run_clm_discovery.py
: 1612201887:0;vim train_fuse.sh
: 1612202121:0;nvidia-smi  
: 1612202159:0;rm nohup.out
: 1612202162:0;touch nohup.out
: 1612202167:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612202203:0;rm nohup.out
: 1612202209:0;ls
: 1612202214:0;vim run_clm_discovery.py
: 1612202271:0;touch nohup.out
: 1612202275:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612202288:0;touch nohup.out
: 1612202291:0;vim nohup.out
: 1612202296:0;rm nohup.out
: 1612202298:0;touch nohup.out
: 1612202300:0;vim run_clm_discovery.py
: 1612202319:0;touch nohup.out
: 1612202323:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612202358:0;nvidia-smi  
: 1612202363:0;vim train_fuse.sh
: 1612202388:0;rm -r /home/nlp/apex/experiment/ctrl
: 1612202448:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612202520:0;vim train_fuse.sh
: 1612202535:0;nvidia-smi  
: 1612202544:0;ps -ef|grep python
: 1612202557:0;kill -9 2951966
: 1612202568:0;kill -9 2951338
: 1612202571:0;ps -ef|grep python
: 1612202582:0;kill -9 2952338
: 1612202590:0;kill -9 2952795
: 1612202595:0;kill -9 2952796
: 1612202600:0;ps -ef|grep python
: 1612202609:0;rm -r /home/nlp/apex/experiment/ctrl
: 1612202622:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612212426:0;nvidia-smi  
: 1612212435:0;cd apex/experiment
: 1612212437:0;ls
: 1612212446:0;cd ../commonsense-discourse/training
: 1612212463:0;vim train_fuse.sh
: 1612212593:0;CUDA_VISIBLE_DEVICES=1 python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-2000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-2000 --per_device_eval_batch_size 8 --fp16
: 1612215613:0;CUDA_VISIBLE_DEVICES=1 python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-4000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-4000 --per_device_eval_batch_size 8 --fp16
: 1612221533:0;CUDA_VISIBLE_DEVICES=1 python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-6000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-6000 --per_device_eval_batch_size 8 --fp16
: 1612236849:0;CUDA_VISIBLE_DEVICES=1 python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-10000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-10000 --per_device_eval_batch_size 8 --fp16
: 1612237472:0;nvidia-smi  
: 1612277546:0;cd apex/commonsense-discourse/training
: 1612277547:0;ls
: 1612277566:0;ls ../../experiment/ctrl
: 1612277601:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-18000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-18000 --per_device_eval_batch_size 128 --fp16
: 1612279631:0;vim run_clm_discovery.py
: 1612279662:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl/checkpoint-18000 --do_eval --output_dir /home/nlp/apex/experiment/ctrl/checkpoint-18000 --per_device_eval_batch_size 128 --fp16
: 1612280710:0;jupyter notebook --no-browser --port=8888
: 1612280750:0;cd ..
: 1612280756:0;jupyter notebook --no-browser --port=8888
: 1612282473:0;cd transformers-importance-sampling/
: 1612282476:0;git status
: 1612282479:0;git add .
: 1612282489:0;git commit -m "added heuristics"
: 1612282492:0;git push
: 1612282497:0;git push origin new
: 1612282507:0;cd ..
: 1612282509:0;ls
: 1612282515:0;cd apex/commonsense-discourse/
: 1612282516:0;ls
: 1612282589:0;rm nohup.out
: 1612282591:0;ls
: 1612282603:0;rm -r transformers
: 1612282632:0;ls
: 1612282641:0;cd training
: 1612282641:0;ls
: 1612282652:0;rm ctrl-merges.txt
: 1612282660:0;rm ctrl-vocab.json
: 1612282663:0;rm nohup.out
: 1612282664:0;ls
: 1612282671:0;rm run_seq_clas.py
: 1612282674:0;ls
: 1612282680:0;rm ds_config.json
: 1612282682:0;ls
: 1612282692:0;rm -r transformers
: 1612282713:0;vim run_clm_discovery.py
: 1612283708:0;ls
: 1612283712:0;cd ..
: 1612283716:0;cd ../experiment
: 1612283722:0;rm -r ctrl
: 1612283778:0;cd ..
: 1612283783:0;cd commonsense-discourse/training
: 1612283784:0;ls
: 1612283791:0;vim train_fuse.sh
: 1612283897:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612283901:0;touch nohup.out
: 1612283904:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612283989:0;pip install git+https://github.com/huggingface/transformers.git --upgrade --no_cache_dir
: 1612283997:0;pip install git+https://github.com/huggingface/transformers.git --upgrade 
: 1612284204:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612284215:0;rm nohup.out
: 1612284223:0;vim train_fuse.sh
: 1612284231:0;vim run_clm_discovery.py
: 1612284249:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612284251:0;touch nohup.out
: 1612284253:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612285520:0;nvidia-smi  
: 1612285539:0;rm nohup.out
: 1612285541:0;touch nohup.out
: 1612285544:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612323524:0;cd apex/commonsense-discourse/
: 1612323525:0;ls
: 1612323538:0;cd training
: 1612323553:0;vim nohup.out
: 1612363718:0;nvidia-smi  
: 1612363727:0;cd apex/commonsense-discourse/training
: 1612363740:0;vim nohup.out
: 1612393864:0;nvidia-smi  
: 1612393868:0;cd apex/commonsense-discourse/training
: 1612393872:0;vim nohup.out
: 1612401842:0;nvidia-smi  
: 1612401845:0;vim nohup.out
: 1612451338:0;cd apex/commonsense-discourse
: 1612451339:0;ls
: 1612451342:0;git status
: 1612451362:0;git add .
: 1612451377:0;git commit -m "working ctrl"
: 1612451381:0;git push
: 1612451393:0;cd training
: 1612451417:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/ctrl --do_eval --output_dir /home/nlp/apex/experiment/ctrl --per_device_eval_batch_size 128 --fp16
: 1612454028:0;jupyter notebook --no-browser --port=8888
: 1612454064:0;cd ..
: 1612454071:0;jupyter notebook --no-browser --port=8888
: 1612458874:0;cd apex/commonsense-discourse
: 1612458875:0;ls
: 1612458878:0;cd training
: 1612458885:0;vim run_clm_discovery.py
: 1612459327:0;vi train_fuse.sh
: 1612459365:0;rm nohup.out
: 1612459370:0;touch nohup.out
: 1612459374:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612459423:0;vim run_clm_discovery.py
: 1612459470:0;rm nohup.out
: 1612459473:0;touch nohup.out
: 1612459477:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612459501:0;vim run_clm_discovery.py
: 1612459628:0;rm nohup.out
: 1612459631:0;touch nohup.out
: 1612459633:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612459657:0;vim run_clm_discovery.py
: 1612459699:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612459851:0;vim run_clm_discovery.py
: 1612459876:0;rm nohup.out
: 1612459878:0;touch nohup.out
: 1612459881:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612461094:0;rm /home/nlp/apex/experiment/gpt2
: 1612461098:0;rm -r /home/nlp/apex/experiment/gpt2
: 1612461111:0;vim train_fuse.sh
: 1612461136:0;rm nohup.out
: 1612461138:0;touch nohup.out
: 1612461140:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612464600:0;cd apex/commonsense-discourse
: 1612464602:0;cd training
: 1612464604:0;nvidia-smi  
: 1612464639:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/gpt2_large/checkpoint-1000 --do_eval --output_dir /home/nlp/apex/experiment/gpt2_large --per_device_eval_batch_size 128 --fp16
: 1612467920:0;nvidia-smi  
: 1612467932:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/gpt2_large/checkpoint-1000 --do_eval --output_dir /home/nlp/apex/experiment/gpt2_large --per_device_eval_batch_size 32 --fp16
: 1612467962:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/gpt2_large/checkpoint-2000 --do_eval --output_dir /home/nlp/apex/experiment/gpt2_large --per_device_eval_batch_size 32 --fp16
: 1612475743:0;nvidia-smi  
: 1612475754:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/gpt2_large/checkpoint-2000 --do_eval --output_dir /home/nlp/apex/experiment/gpt2_large --per_device_eval_batch_size 4 --fp16
: 1612495932:0;nvidia-smi  
: 1612495954:0;vim nohup.out
: 1612537845:0;nvidia-smi  
: 1612537862:0;cd apex/commonsense-discourse/training
: 1612537864:0;vim nohup.out
: 1612538275:0;vim ../../experiment/ctrl/eval_results_clm.txt
: 1612540571:0;nvidia-smi  
: 1612543488:0;python3 run_clm_discovery.py --model_name_or_path /home/nlp/apex/experiment/gpt2_large --do_eval --output_dir /home/nlp/apex/experiment/gpt2_large --per_device_eval_batch_size 128 --fp16
: 1612551617:0;cd ..
: 1612554507:0;cd transformers-importance-sampling/
: 1612554510:0;vim get_heuristics_stats.py
: 1612554538:0;python3 get_heuristics_stats.py
: 1612554613:0;nohup /home/nlp/transformers-importance-sampling/ & tail -f nohup.out
: 1612554615:0;ls
: 1612554625:0;vim heuristics.sh
: 1612554648:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612554667:0;chmod +x /home/nlp/transformers-importance-sampling/heuristics.sh
: 1612554670:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612554679:0;ls
: 1612554687:0;vim heuristics.sh
: 1612554706:0;mv get_heuristics_stats.py get_heuristic_stats.py
: 1612554709:0;rm nohup.out
: 1612554712:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612554720:0;touch nohup.out
: 1612554721:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612562049:0;pip uninstallwandb
: 1612562055:0;pip uninstall wandb
: 1612562072:0;pip install --user wandb
: 1612562232:0;python3
: 1612562272:0;vim get_heuristic_stats.py
: 1612562376:0;rm nohup.out
: 1612562379:0;touch nohup.out
: 1612562391:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612574441:0;vim get_heuristic_stats.py
: 1612574517:0;rm nohup.out
: 1612574520:0;touch nohup.out
: 1612574522:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612627560:0;cd transformers-importance-sampling/
: 1612627563:0;vim nohup.out
: 1612627580:0;vim get_heuristic_stats.py
: 1612627716:0;python3 get_heuristic_stats.py
: 1612628405:0;vim get_heuristic_stats.py
: 1612628439:0;python3 get_heuristic_stats.py
: 1612629537:0;vim get_heuristic_stats.py
: 1612629601:0;rm nohup.out
: 1612629605:0;vim get_heuristic_stats.py
: 1612629623:0;touch nohup.out
: 1612629626:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612629667:0;vim get_heuristic_stats.py
: 1612629681:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612631079:0;vim get_heuristic_stats.py
: 1612631299:0;ls ../cartography/filtered/roberta_large_hard/cartography_confidence_0.01
: 1612631309:0;vim get_heuristic_stats.py
: 1612631343:0;cd ..
: 1612631348:0;cd cartography/filtered
: 1612631349:0;ls
: 1612631362:0;mv roberta_large_hard roberta_large_hard_mnli
: 1612631375:0;cd ..
: 1612631385:0;cd transformers-importance-sampling/
: 1612631389:0;python3 get_heuristic_stats.py
: 1612631394:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612631518:0;vim get_heuristic_stats.py
: 1612631537:0;cd cartography/filtered
: 1612631540:0;ls
: 1612631569:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612631852:0;vim get_heuristic_stats.py
: 1612632105:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612632315:0;vim get_heuristic_stats.py
: 1612631886:0;pwd
: 1612632406:0;cd ..
: 1612632413:0;jupyter notebook --no-browser --port=8888
: 1612633978:0;rm nohup.out
: 1612633980:0;touch nohup.out
: 1612633984:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612634101:0;vim get_heuristic_stats.py
: 1612634115:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612635979:0;vim get_heuristic_stats.py
: 1612636016:0;rm nohup.out
: 1612636020:0;touch nohup.out
: 1612636022:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612646033:0;vim get_heuristic_stats.py
: 1612646097:0;rm nohup.out
: 1612646099:0;touch nohup.out
: 1612646102:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612654598:0;vim get_heuristic_stats.py
: 1612654709:0;rm nohup.out
: 1612654715:0;touch nohup.out
: 1612654717:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612714012:0;cd transformers-importance-sampling/
: 1612714014:0;vim nohup.out
: 1612714076:0;vim get_heuristic_stats.py
: 1612714123:0;jupyter notebook --no-browser --port=8888
: 1612714625:0;vim nohup.out
: 1612714636:0;vim get_heuristic_stats.py
: 1612714665:0;rm nohup.out
: 1612714667:0;touch nohup.out
: 1612715118:0;vim get_heuristic_stats.py
: 1612715143:0;rm nohup.out
: 1612715145:0;touch nohup.out
: 1612715147:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612715167:0;rm nohup.out
: 1612715172:0;vim get_heuristic_stats.py
: 1612715188:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612715191:0;touch nohup.out
: 1612715193:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612715719:0;cd cartography/filtered
: 1612715720:0;ls
: 1612715727:0;cd ..
: 1612715858:0;vim get_heuristic_stats.py
: 1612715878:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612716471:0;vim get_heuristic_stats.py
: 1612716487:0;rm nohup.out
: 1612716491:0;touch nohup.out
: 1612716493:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612717012:0;vim get_heuristic_stats.py
: 1612717033:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612717345:0;ls
: 1612717535:0;vim get_heuristic_stats.py
: 1612717574:0;cd data
: 1612717575:0;ls
: 1612717609:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612717617:0;vim get_heuristic_stats.py
: 1612717634:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612717641:0;vim get_heuristic_stats.py
: 1612717665:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612717675:0;vim get_heuristic_stats.py
: 1612717708:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612718017:0;nvidia-smi  
: 1612722276:0;cd ../cartography
: 1612722360:0;ls
: 1612722363:0;cd cartography
: 1612722363:0;ls
: 1612722370:0;wget https://github.com/huggingface/transformers/archive/v2.5.1.zip
: 1612722374:0;ls
: 1612722379:0;unzip v2.5.1.zip
: 1612722433:0;rm v2.5.1.zip
: 1612722435:0;ls
: 1612722447:0;mv transformers-2.5.1 transformers
: 1612722451:0;cd transformers
: 1612722451:0;ls
: 1612722461:0;cd ..
: 1612722466:0;mv transformers tf
: 1612722472:0;mv tf/src/transformers .
: 1612722474:0;ls
: 1612722481:0;rm -rf tf
: 1612722493:0;cd ..
: 1612722498:0;cd cartography
: 1612722499:0;ls
: 1612722545:0;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722550:0;cd ..
: 1612722552:0;cd carto
: 1612722556:0;cd cartography
: 1612722589:0;cd configs/
: 1612722590:0;s
: 1612722591:0;ls
: 1612722594:0;vim mnli.jsonnet
: 1612722678:0;cd ..
: 1612722683:0;ls
: 1612722687:0;cd filtered
: 1612722688:0;ls
: 1612722690:0;cd ..
: 1612722719:0;mkdir carto
: 1612722722:0;cd cartography
: 1612722735:0;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722763:0;cd cartography/transformers
: 1612722764:0;ls
: 1612722768:0;cd ..
: 1612722770:0;ls
: 1612722783:0;python3 -mclassification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722793:0;python3 -m classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722812:0;ls
: 1612722825:0;cp -r transformers ..
: 1612722841:0;cd ..
: 1612722842:0;ls
: 1612722847:0;python3 -m classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722856:0;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722871:0;export TASK_NAME=MNLI
: 1612722873:0;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722885:0;export TASK_NAME=mnli
: 1612722887:0;python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612722958:0;CUDA_VISIBLE_DEVICES=1 python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612723145:0;nvidia-smi  
: 1612723159:0;vim configs/mnli.jsonnet
: 1612723181:0;CUDA_VISIBLE_DEVICES=1 python3 -m cartography.classification.run_glue \\
    -c configs/$TASK_NAME.jsonnet \\
    --do_train \\
    --do_eval \\
    -o /home/nlp/carto
: 1612723876:0;nvidia-smi  
: 1612754958:0;ls
: 1612755039:0;cd filtered
: 1612755052:0;ls
: 1612755075:0;cd bert_base_ambiguous_mnli
: 1612755086:0;ls
: 1612755107:0;cd ../..
: 1612755122:0;cd ..
: 1612755141:0;cd carto
: 1612755158:0;ls
: 1612755174:0;cd ..
: 1612755201:0;cd cartography
: 1612755209:0;ls
: 1612755461:0;mkdir filtered/roberta_base_hard
: 1612756152:0;ls filtered/roberta_large_easy
: 1612756180:0;cd ..
: 1612756214:0;nvidia-smi  
: 1612756231:0;cd cartography
: 1612756287:0;python3 -m cartography.selection.train_dy_filtering --filter --task_name MNLI --model_dir /home/nlp/carto/ --metric confidence --data_dir /home/nlp/data/glue_data/ 
: 1612757584:0;cd filtered
: 1612757618:0;mv carto* roberta_base_hard
: 1612757731:0;ls roberta_base_hard
: 1612757800:0;ls
: 1612757904:0;cd ..
: 1612759105:0;cd transformers-importance-sampling/
: 1612759215:0;vim get_heuristic_stats.py
: 1612759533:0;cd ..
: 1612759545:0;cd cartography
: 1612759598:0;cd filtered/cartography_confidence_0.10
: 1612759616:0;cd filtered
: 1612759708:0;mv roberta_base_hard roberta_base_hard_mnli
: 1612759764:0;cd ..
: 1612759787:0;cd transformers-importance-sampling/
: 1612759805:0;python3 get_heuristic_stats.py
: 1612759909:0;vim get_heuristic_stats.py
: 1612760093:0;python3 get_heuristic_stats.py
: 1612760509:0;vim get_heuristic_stats.py
: 1612763201:0;python3 get_heuristic_stats.py
: 1612793527:0;cd transformers-importance-sampling/
: 1612793529:0;vim get_heuristic_stats.py
: 1612793565:0;rm nohup.out
: 1612793567:0;touch nohup.out
: 1612793569:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612795413:0;jupyter notebook --no-browser --port=8888
: 1612798108:0;nvidia-smi  
: 1612798746:0;cd apex/commonsense-discourse/training
: 1612798748:0;ls
: 1612798761:0;vim generate_dataset.py
: 1612803085:0;vi generate_dataset.py
: 1612803116:0;black generate_dataset.py
: 1612803118:0;vi generate_dataset.py
: 1612803243:0;black generate_dataset.py
: 1612803245:0;vi generate_dataset.py
: 1612803262:0;rm nohup.out
: 1612803266:0;nvidia-smi  
: 1612803278:0;touch nohup.out
: 1612803283:0;ls
: 1612803292:0;vim train_fuse.sh
: 1612803444:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612803454:0;vim train_fuse.sh
: 1612803469:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612803476:0;ls
: 1612803502:0;vi generate_dataset.py
: 1612803548:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612803555:0;ls ..
: 1612803573:0;vim generate_dataset.py
: 1612803581:0;ls
: 1612803605:0;vim run_clm_discovery.py
: 1612803616:0;vim generate_dataset.py
: 1612803641:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612803695:0;vim generate_dataset.py
: 1612804082:0;rm nohup.out
: 1612804088:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804108:0;touch nohup.out
: 1612804109:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804124:0;vim generate_dataset.py
: 1612804139:0;rm nohup.out
: 1612804145:0;touch nohup.out
: 1612804148:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804173:0;vim generate_dataset.py
: 1612804218:0;rm nohup.out && touch nohup.out
: 1612804220:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804237:0;vim generate_dataset.py
: 1612804260:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804263:0;rm nohup.out && touch nohup.out
: 1612804264:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804398:0;pip install --userd atasets
: 1612804405:0;pip install --user datasets
: 1612804410:0;pip install --user datasets --upgrade
: 1612804431:0;vim generate_dataset.py
: 1612804513:0;rm nohup.out && touch nohup.out
: 1612804520:0;vim generate_dataset.py
: 1612804634:0;vim run_clm_discovery.py
: 1612804808:0;ls
: 1612804814:0;vim train_fuse.sh
: 1612804877:0;nvidia-smi  
: 1612804893:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612804906:0;vim run_clm_discovery.py
: 1612804952:0;rm nohup.out && touch nohup.out
: 1612804954:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612805557:0;nvidia-smi  
: 1612805577:0;vim train_fuse.sh
: 1612805620:0;rm nohup.out && touch nohup.out
: 1612805624:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612805659:0;nvidia-smi  
: 1612805674:0;nvidia-smi  -i
: 1612805693:0;nvidia-smi -l
: 1612805843:0;vim train_fuse.sh
: 1612805857:0;nvidia-smi -l
: 1612805881:0;history | grep train_orthogonal
: 1612805896:0;ps -ef|grep python
: 1612805911:0;kill -93177093
: 1612805916:0;kill -9 3177093
: 1612805920:0;nvidia-smi -l
: 1612805953:0;nvidia-smi 
: 1612805964:0;vim train_fuse.sh
: 1612805983:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612806349:0;cd ..
: 1612806355:0;cd experiment/ctrl
: 1612806355:0;ls
: 1612806365:0;rm -r checkpoint-*
: 1612806399:0;cd 
: 1612806402:0;cd apex/commonsense-discourse/training
: 1612806413:0;rm nohup.out && touch nohup.out
: 1612806420:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612806617:0;ps -ef|grep python
: 1612806628:0;kill -9 95360
: 1612806639:0;kill -9 953960
: 1612806649:0;rm nohup.out && touch nohup.out
: 1612806651:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612806823:0;ps -ef|grep python
: 1612806836:0;kill -9 2221085
: 1612806849:0;ls ../../experiment/ctrl
: 1612806885:0;cd ../../experiment/ctrl
: 1612806889:0;vim trainer_state.json
: 1612806918:0;mv trainer_state.json trainer_state_0.json
: 1612806920:0;cd ..
: 1612806926:0;cd ../commonsense-discourse/training
: 1612806928:0;rm nohup.out && touch nohup.out
: 1612806929:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612807118:0;vim train_fuse.sh
: 1612807132:0;ps -ef|grep python
: 1612807138:0;nvidia-smi 
: 1612807143:0;rm nohup.out && touch nohup.out
: 1612807145:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612807316:0;nvidia-smi 
: 1612807323:0;vim train_fuse.sh
: 1612807355:0;rm nohup.out && touch nohup.out
: 1612807358:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612809108:0;vim get_heuristic_stats.py
: 1612809221:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1612807534:0;nvidia-smi 
: 1612810985:0;nvidia-smi 
: 1612811022:0;tad cs1
: 1612811070:0;tad cs4
: 1612811073:0;tad cs1
: 1612813898:0;vim get_heuristic_stats.py
: 1612813936:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1612819671:0;vim get_heuristic_stats.py
: 1612820372:0;p3 get_heuristic_stats.py
: 1612820923:0;vim get_heuristic_stats.py
: 1612821055:0;vim train_fuse.sh
: 1612821074:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612826477:0;nvidia-smi 
: 1612826482:0;vim train_fuse.sh
: 1612826496:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612826607:0;vim get_heuristic_stats.py
: 1612826637:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612826650:0;python3 get_heuristic_stats.py
: 1612826904:0;vim get_heuristic_stats.py
: 1612827068:0;python3 get_heuristic_stats.py
: 1612827640:0;vim get_heuristic_stats.py
: 1612827770:0;nvidia-smi 
: 1612827774:0;vim get_heuristic_stats.py
: 1612827880:0;p3 get_heuristic_stats.py
: 1612827894:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1612839521:0;htop
: 1612839532:0;nvidia-smi 
: 1612839547:0;cd apex/commonsense-discourse/training
: 1612839549:0;cd ..
: 1612839551:0;git add .
: 1612839559:0;git status
: 1612839564:0;git add .
: 1612839593:0;git commit -m "backup"
: 1612839614:0;cd training
: 1612839617:0;rm -r wandb
: 1612839623:0;git add .
: 1612839626:0;git commit -m "backup"
: 1612839630:0;git push
: 1612839646:0;cd ..
: 1612839648:0;ls
: 1612839653:0;cd training
: 1612839658:0;ls ../../experiment/ctrl
: 1612839668:0;vim nohup.out
: 1612839681:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612839711:0;vim train_fuse.sh
: 1612839729:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612840007:0;nvidia-smi 
: 1612840013:0;ps -ef|grep python
: 1612840026:0;kill -9 2345916
: 1612840029:0;nvidia-smi 
: 1612840051:0;vim train_fuse.sh
: 1612840071:0;rm nohup.out && touch nohup.out
: 1612840074:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612840582:0;nvidia-smi 
: 1612844301:0;cd apex/commonsense-discourse/training
: 1612844302:0;ls
: 1612844308:0;vim train_fuse.sh
: 1612844314:0;vim nohup.out
: 1612844346:0;cd ..
: 1612844350:0;cd experiment/ctrl
: 1612844351:0;ls
: 1612844367:0;cd ..
: 1612844370:0;ls
: 1612844372:0;cd ..
: 1612844377:0;cd apex/commonsense-discourse/training
: 1612844380:0;cd commonsense-discourse/training
: 1612844382:0;ls
: 1612844387:0;vim train_fuse.sh
: 1612844426:0;vim nohup.out
: 1612844470:0;pip install git+https://github.com/huggingface/transformers.git --upgrade 
: 1612844605:0;rm nohup.out && touch nohup.out
: 1612844620:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612845001:0;pip uninstall wandb
: 1612845072:0;nvidia-smi 
: 1612845076:0;ps -ef|grep python
: 1612845084:0;kill -9 2411264
: 1612845092:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612846388:0;export WANDB_DISABLED=1
: 1612846417:0;printenv HOME
: 1612846427:0;printenv WANDB_DISABLED
: 1612846431:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612846439:0;nvidia-smi 
: 1612846443:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612846608:0;nvidia-smi 
: 1612846656:0;vim train_fuse.sh
: 1612846673:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612847339:0;nvidia-smi 
: 1612847354:0;htop
: 1612847386:0;ps -ef|grep python
: 1612847406:0;kill -9 2414572
: 1612847410:0;ps -ef|grep python
: 1612847415:0;nvidia-smi 
: 1612847429:0;vim train_fuse.sh
: 1612847451:0;nvidia-smi 
: 1612847461:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612847480:0;ps -ef|grep python
: 1612847698:0;pip install wandb
: 1612847830:0;nvidia-smi 
: 1612847838:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612848078:0;nvidia-smi -l
: 1612848119:0;htop
: 1612848170:0;nvidia-smi -l
: 1612848256:0;pip install gpustat
: 1612848269:0;gpustats -cp
: 1612848275:0;gpustat -cp
: 1612848290:0;gpustat 
: 1612848364:0;vim run_clm_discovery.py
: 1612881802:0;cd commonsense-discourse/training
: 1612881804:0;nvidia-smi -l
: 1612881813:0;ls
: 1612881819:0;cd apex/commonsense-discourse/training
: 1612881822:0;vim nohup.out
: 1612881868:0;htop
: 1612881882:0;vim train_fuse.sh
: 1612881898:0;rm nohup.out && touch nohup.out
: 1612881902:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612882213:0;vim run_clm_discovery.py
: 1612882290:0;rm nohup.out && touch nohup.out
: 1612882292:0;nvidia-smi -l
: 1612882295:0;ps -ef|grep python
: 1612882305:0;kill -9 2492452=3
: 1612882308:0;kill -9 24924523
: 1612882313:0;kill -9 2492453
: 1612882320:0;nvidia-smi 
: 1612882327:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612882357:0;vim run_clm_discovery.py
: 1612882373:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612884571:0;jupyter notebook --no-browser --port=8888
: 1612895079:0;cd transformers-importance-sampling/
: 1612895122:0;vim get_heuristic_stats.py
: 1612895133:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1612895146:0;ls
: 1612895151:0;vim heuristics.sh
: 1612895172:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612918499:0;nvidia-smi 
: 1612918510:0;vim train_fuse.sh
: 1612918521:0;vim heuristics.sh
: 1612918543:0;ls
: 1612918586:0;cp get_heuristic_stats.py get_heuristic_stat_2.py
: 1612918596:0;vim get_heuristic_stat_2.py
: 1612918686:0;vim heuristics.sh
: 1612918747:0;vim get_heuristic_stat_2.py
: 1612918768:0;vim get_heuristic_stats.py
: 1612918779:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612970022:0;nvidia-smi 
: 1612970030:0;cd transformers-importance-sampling/
: 1612970032:0;vim nohup.out
: 1612970342:0;rm nohup.out && touch nohup.out
: 1612970347:0;vim get_heuristic_stats.py
: 1612970431:0;cd transformers-importance-sampling/
: 1612970436:0;ls ../data
: 1612970488:0;vim get_heuristic_stats.py
: 1612970559:0;vim get_heuristic_stat_2.py
: 1612970598:0;vim get_heuristic_stats.py
: 1612970611:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612972175:0;cd ..
: 1612972177:0;nvidia-smi 
: 1612972181:0;cd apex/commonsense-discourse/training
: 1612972183:0;vim nohup.out
: 1612988177:0;nvidia-smi 
: 1612988189:0;jupyter notebook --no-browser --port=8888
: 1612988198:0;ls
: 1612988203:0;vim train_fuse.sh
: 1612988225:0;rm nohup.out && touch nohup.out
: 1612988236:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612988311:0;vim get_heuristic_stats.py
: 1612988339:0;p3 get_heuristic_stats.py
: 1612988809:0;vim get_heuristic_stats.py
: 1612988823:0;p3 get_heuristic_stats.py
: 1612989316:0;vim get_heuristic_stats.py
: 1612989444:0;ls data
: 1612989470:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612992008:0;jupyter notebook --no-browser --port=8888
: 1612994078:0;nvidia-smi 
: 1612999201:0;vim 0
: 1612999207:0;vim get_heuristic_stats.py
: 1612999229:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612999481:0;ls
: 1612999486:0;vim generate_dataset.py
: 1612999533:0;vim train_fuse.sh
: 1612999542:0;rm nohup.out && touch nohup.out
: 1612999549:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1612999560:0;rm nohup.out && touch nohup.out
: 1612999601:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612999693:0;vim generate_dataset.py
: 1612999734:0;rm nohup.out && touch nohup.out
: 1612999736:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612999749:0;vim generate_dataset.py
: 1612999822:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1612999825:0;rm nohup.out && touch nohup.out
: 1612999831:0;nvidia-smi 
: 1613000151:0;nvidia-smi cd ..
: 1613000152:0;cd ..
: 1613000159:0;cd ../transformers-importance-sampling/
: 1613000166:0;vim get_heuristic_stats.py
: 1613001815:0;cd ..
: 1613001818:0;cd apex/commonsense-discourse/training
: 1613001819:0;ls
: 1613001823:0;cd ../../experiment
: 1613001824:0;ls
: 1613001825:0;cd ctrl
: 1613001826:0;ls
: 1613002228:0;cd ..
: 1613002236:0;ls
: 1613002240:0;cd commonsense-discourse/training
: 1613002247:0;vim train_fuse.sh
: 1613002319:0;y
: 1613002320:0;nvidia-smi cd ..
: 1613002324:0;nvidia-smi 
: 1613002330:0;vim train_fuse.sh
: 1613002390:0;ls apex/experiment
: 1613002393:0;ls apex/experiment/ctrl
: 1613002419:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613002425:0;rm nohup.out && touch nohup.out
: 1613002428:0;nvidia-smi 
: 1613002430:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613002615:0;ls
: 1613002618:0;nvidia-smi 
: 1613002622:0;vim run_clm_discovery.py
: 1613002658:0;vim train_fuse.sh
: 1613002679:0;rm nohup.out && touch nohup.out
: 1613002682:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613007549:0;vim train_fuse.sh
: 1613007565:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613009098:0;vim get_heuristic_stats.py
: 1613009378:0;rm nohup.out && touch nohup.out
: 1613009414:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613011112:0;vim train_fuse.sh
: 1613011123:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613011131:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613018780:0;vim train_fuse.sh
: 1613018803:0;rm nohup.out && touch nohup.out
: 1613018813:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613022025:0;vim train_fuse.sh
: 1613022072:0;rm nohup.out && touch nohup.out
: 1613022074:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613022572:0;vim get_heuristic_stats.py
: 1613022677:0;rm nohup.out && touch nohup.out
: 1613022680:0;vim get_heuristic_stats.py
: 1613022703:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613024502:0;vim train_fuse.sh
: 1613024537:0;rm nohup.out && touch nohup.out
: 1613024541:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613024549:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613057744:0;nvidia-smi 
: 1613057751:0;cd commonsense-discourse/training
: 1613057754:0;cd apex/commonsense-discourse/training
: 1613057757:0;vim nohup.out
: 1613057782:0;vim train_fuse.sh
: 1613057800:0;rm nohup.out && touch nohup.out
: 1613057803:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613057876:0;cd transformers-importance-sampling/
: 1613057879:0;vim nohup.out
: 1613057887:0;vim get_heuristic_stats.py
: 1613058102:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613060337:0;vim train_fuse.sh
: 1613060368:0;rm nohup.out && touch nohup.out
: 1613060370:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613060377:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613063300:0;rm nohup.out && touch nohup.out
: 1613063304:0;vim train_fuse.sh
: 1613063315:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613067521:0;jupyter notebook --no-browser --port=8888
: 1613067562:0;cd ~
: 1613067563:0;jupyter notebook --no-browser --port=8888
: 1613069446:0;ls
: 1613069453:0;cd apex/experiment
: 1613069453:0;ls
: 1613069456:0;cd ctrl
: 1613069459:0;rm -r *
: 1613069644:0;cd ../../commonsense-discourse
: 1613069647:0;cd training
: 1613069649:0;ls
: 1613069654:0;vim run_clm_discovery.py
: 1613069767:0;ls
: 1613069772:0;vim train_fuse.sh
: 1613069892:0;vim ds_config.json
: 1613069996:0;ls
: 1613070000:0;vim train_fuse.sh
: 1613070026:0;rm nohup.out && touch nohup.out
: 1613070032:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613073404:0;vim get_heuristic_stats.py
: 1613073456:0;rm nohup.out && touch nohup.out
: 1613073459:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613073484:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613087128:0;vim get_heuristic_stats.py
: 1613087212:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613087215:0;rm nohup.out && touch nohup.out
: 1613087218:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613141968:0;nvidia-smi 
: 1613141977:0;cd transformers-importance-sampling/
: 1613141980:0;vim nohup.out
: 1613141989:0;vim get_heuristic_stats.py
: 1613142023:0;rm nohup.out && touch nohup.out
: 1613142029:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613162861:0;cd transformers-importance-sampling/
: 1613162864:0;vim heuristics.sh
: 1613162890:0;vim get_heuristic_stats.py
: 1613162949:0;rm nohup.out && touch nohup.out
: 1613162958:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613168754:0;vim get_heuristic_stats.py
: 1613168769:0;rm nohup.out && touch nohup.out
: 1613168771:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613172024:0;vim get_heuristic_stats.py
: 1613172065:0;rm nohup.out && touch nohup.out
: 1613172068:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613172380:0;nvidia-smi 
: 1613172411:0;vim ../apex/commonsense-discourse/training/nohup.out
: 1613182832:0;python3
: 1613182892:0;e
: 1613196030:0;vim get_heuristic_stats.py
: 1613196171:0;rm nohup.out && touch nohup.out
: 1613196174:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613227283:0;cd transformers-importance-sampling/
: 1613227288:0;git status
: 1613227294:0;git commit -m "backup"
: 1613227314:0;git add .
: 1613227319:0;git commit -m "backup"
: 1613227323:0;git push
: 1613227326:0;git push origin new
: 1613227341:0;cd ..
: 1613227349:0;cd apex/commonsense-discourse/
: 1613227352:0;git status
: 1613227360:0;git add .
: 1613227372:0;rm -r training/wandb
: 1613227376:0;git add .
: 1613227383:0;git commit -m "backup"
: 1613227386:0;git push
: 1613227397:0;cd ../..
: 1613227400:0;cd traansformers-importance-sampling/
: 1613227411:0;cd transformers-importance-sampling
: 1613227413:0;ls
: 1613227460:0;vim nohup.out
: 1613227655:0;rm nohup.out && touch nohup.out
: 1613227661:0;vim get_heuristic_stats.py
: 1613227719:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1613241011:0;nvidia-smi 
: 1613241016:0;cd ..
: 1613241026:0;cd apex/commonsense-discourse/training
: 1613241028:0;vim nohup.out
: 1613257427:0;nvidia-smi 
: 1613257432:0;cd apex/commonsense-discourse/training
: 1613257434:0;vim nohup.out
: 1613263236:0;vim train_fuse.sh
: 1613263299:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613265445:0;nvidia-smi 
: 1613265451:0;rm nohup.out && touch nohup.out
: 1613265457:0;vim train_fuse.sh
: 1613265475:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613268964:0;cd ..
: 1613268965:0;cd ~
: 1613268967:0;jupyter notebook --no-browser --port=8888
: 1613345990:0;clear
: 1613346521:0;ls
: 1613346526:0;jupyter notebook --no-browser --port=8888
: 1613347778:0;cd apex/experiment/ctrl
: 1613347779:0;ls
: 1613364923:0;..
: 1613364930:0;cd ../commonsense-discourse
: 1613364934:0;git status
: 1613364942:0;git add .
: 1613364946:0;git commit -m "backup"
: 1613364950:0;git push
: 1613364960:0;cd ~
: 1613364962:0;cd transformers-importance-sampling
: 1613364963:0;ls
: 1613364966:0;git status
: 1613364969:0;git add .
: 1613364973:0;git commit -m "backup"
: 1613364976:0;git push
: 1613364980:0;git push origin new
: 1613364990:0;cd ~
: 1613367014:0;cd apex/commonsense-discourse/
: 1613367014:0;ls
: 1613367025:0;rm -r runs
: 1613367041:0;vim training
: 1613367054:0;cd training
: 1613367054:0;ls
: 1613367061:0;vim generate_dataset.py
: 1613367165:0;black generate_dataset.py
: 1613367169:0;vim generate_dataset.py
: 1613367191:0;vim train_fuse.sh
: 1613367202:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613367208:0;rm nohup.out && touch nohup.out
: 1613367212:0;nvidia-smi 
: 1613367234:0;vim train_fuse.sh
: 1613367239:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613367362:0;cd apex/commonsense-discourse/
: 1613367366:0;cd training
: 1613367369:0;vim generate_dataset.py
: 1613367439:0;nvidia-smi 
: 1613367446:0;ps -ef|grep python
: 1613367455:0;kill -9 920430
: 1613367461:0;kill -9 921075
: 1613367465:0;nvidia-smi 
: 1613367469:0;ps -ef|grep python
: 1613367481:0;kill -9 920659
: 1613367484:0;vim generate_dataset.py
: 1613367575:0;rm nohup.out && touch nohup.out
: 1613367579:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613367762:0;nvidia-smi 
: 1613367768:0;vim generate_dataset.py
: 1613367783:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613367790:0;nvidia-smi 
: 1613367795:0;rm nohup.out && touch nohup.out
: 1613367798:0;nvidia-smi 
: 1613367801:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613367876:0;vim generate_dataset.py
: 1613367890:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613406143:0;nvidia-smi 
: 1613406150:0;cd apex/commonsense-discourse/training
: 1613406153:0;vim nohup.out
: 1613406177:0;ls
: 1613406180:0;htop
: 1613406202:0;vim nohup.out
: 1613407867:0;ls
: 1613407874:0;vim generate_dataset.py
: 1613407889:0;nvidia-smi 
: 1613407921:0;vim nohup.out
: 1613407939:0;vim generate_dataset.py
: 1613407979:0;rm nohup.out && touch nohup.out
: 1613407981:0;nohup /home/nlp/apex/commonsense-discourse/training/train_fuse.sh & tail -f nohup.out
: 1613414967:0;nvidia-smi 
: 1613414971:0;cd apex/commonsense-discourse/training
: 1613414998:0;cp train_fuse.sh train_model.sh
: 1613415014:0;chmod +x /home/nlp/apex/commonsense-discourse/training/train_model.sh
: 1613415065:0;vim train_model.sh
: 1613415212:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh 
: 1613415220:0;nvidia-smi 
: 1613415241:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1613415386:0;nvidia-smi 
: 1613415391:0;ps -ef|grep python
: 1613415408:0;kill -9 925379
: 1613415421:0;vim train_model.sh
: 1613415436:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1613418825:0;nvidia-smi 
: 1613418838:0;cd apex/commonsense-discourse/training
: 1613418840:0;vim run_clm_discovery.py
: 1613420544:0;nvidia-smi 
: 1613420561:0;ls ../data
: 1613421192:0;cd ~
: 1613421195:0;jupyter notebook --no-browser --port=8888
: 1613421440:0;cd apex/commonsense-discourse
: 1613421441:0;ls
: 1613421447:0;mv data/ctrl_main.json .
: 1613421448:0;ls
: 1613421750:0;ls ../data
: 1613421923:0;ls
: 1613422340:0;mv ctrl_main.json data
: 1613427969:0;nvidia-smi 
: 1613427987:0;htop
: 1613428005:0;nvidia-smi 
: 1613428133:0;pip unsintall -transformers
: 1613428146:0;pip uninstall wandb
: 1613428278:0;nvidia-smi 
: 1613428458:0;ls
: 1613428465:0;vim training
: 1613428520:0;nvidia-smi 
: 1613445247:0;ls
: 1613445257:0;vim generate.py
: 1613445278:0;black generate.py
: 1613445281:0;vim generat
: 1613445285:0;vim generate.py
: 1613446058:0;nvidia-smi 
: 1613447787:0;vim generate.py
: 1613447856:0;black generate.py
: 1613447908:0;cd apex/commonsense-discourse
: 1613447912:0;cd training
: 1613447916:0;vim generate.py
: 1613447968:0;vim utils.py
: 1613450752:0;vim generate.py
: 1613452505:0;ls
: 1613452524:0;git add .
: 1613452530:0;git status
: 1613452536:0;ls
: 1613452551:0;rm -r wandb
: 1613452567:0;rm - runs
: 1613452576:0;rm -r runs
: 1613452580:0;git add .
: 1613452598:0;git commit -m "af_init"
: 1613452603:0;git push
: 1613452646:0;ls
: 1613452663:0;mv train_fuse.sh generate_ds.sh
: 1613452676:0;chmod +x /home/nlp/apex/commonsense-discourse/training/generate_dataset.py
: 1613452683:0;chmod +x /home/nlp/apex/commonsense-discourse/training/generate_ds.sh
: 1613452689:0;vim generate_ds.sh
: 1613452710:0;vim generate_dataset.py
: 1613452748:0;cd ..
: 1613452751:0;cd data
: 1613452751:0;ls
: 1613452755:0;rm ctrl_main.json
: 1613452760:0;rm discovery.py
: 1613452764:0;rm discovery.py.lock
: 1613452771:0;rm -r __pycache__
: 1613452774:0;rm synthetic_discovery_1500.json
: 1613452776:0;cd ..
: 1613452778:0;cd training
: 1613452789:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613452795:0;nvidia-smi 
: 1613452800:0;rm nohup.out && touch nohup.out
: 1613452803:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613495036:0;nvidia-smi 
: 1613502185:0;cd apex/commonsense-discourse
: 1613502188:0;cd training
: 1613502189:0;ls
: 1613502203:0;cd ..
: 1613502204:0;ls
: 1613502214:0;vim run_af.py
: 1613502261:0;jupyter notebook --no-browser --port=8888
: 1613504325:0;ls
: 1613504332:0;nvidia-smi 
: 1613504357:0;cd apex/commonsense-discourse
: 1613504365:0;cd data
: 1613504366:0;ls
: 1613504371:0;cd ..
: 1613504484:0;ls
: 1613504525:0;vim run_af.py
: 1613506921:0;cd apex/commonsense-discourse
: 1613506923:0;ls
: 1613506974:0;vim generate.py
: 1613509451:0;jupyter notebook --no-browser --port=8888
: 1613510093:0;black run_af.py
: 1613510110:0;vim run_af.py
: 1613510647:0;sh run_af.sh
: 1613510842:0;vim run_af.sh
: 1613510866:0;sh run_af.sh
: 1613510875:0;vim run_af.sh
: 1613510901:0;sh run_af.sh
: 1613511040:0;vim run_af.sh
: 1613511103:0;git status
: 1613511119:0;rm .run_af.py.swp
: 1613511126:0;rm training/.nfs000000003fa2811a00000090
: 1613511133:0;git add .
: 1613511147:0;git commit -m "af_progress"
: 1613511151:0;git push
: 1613511169:0;vim run_af.sh
: 1613511180:0;ls
: 1613511191:0;vim run_af.py
: 1613511223:0;vim generate.py
: 1613511420:0;sh run_af.sh
: 1613511561:0;vim run_af.sh
: 1613511571:0;sh run_af.sh
: 1613511688:0;nvidia-smi 
: 1613511691:0;vim run_af.sh
: 1613511883:0;sh run_af.sh
: 1613512241:0;vim generate.py
: 1613512321:0;vim run_af.py
: 1613513130:0;vim training/generate_dataset.py
: 1613513168:0;ls
: 1613513173:0;rm -r __pycache__
: 1613513175:0;ls
: 1613513196:0;rm -r runs
: 1613513216:0;vim generate.py
: 1613513245:0;vim training/generate_dataset.py
: 1613513295:0;vim run_af.py
: 1613513367:0;sh run_af.sh
: 1613514663:0;vim run_af.py
: 1613514689:0;sh run_af.sh
: 1613515556:0;vim generate.py
: 1613515622:0;vim run_af.py
: 1613515763:0;sh run_af.sh
: 1613516667:0;vi generate_dataset.py
: 1613516674:0;vim generate.py
: 1613516699:0;vim run_af.py
: 1613516780:0;vim run_af.sh
: 1613516798:0;sh run_af.sh
: 1613517344:0;vim run_af.py
: 1613517552:0;vim generate.py
: 1613517606:0;sh run_af.sh
: 1613521093:0;nvidia-smi 
: 1613521145:0;vim training/nohup.out
: 1613521167:0;htop
: 1613521186:0;vim generate.py
: 1613521297:0;ls
: 1613521324:0;vim training/generate_dataset.py
: 1613521550:0;nvidia-smi 
: 1613521558:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613521566:0;touch nohup.out
: 1613521580:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613521592:0;cd training
: 1613521597:0;rm nohup.out && touch nohup.out
: 1613521603:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613521613:0;vim generate_dataset.py
: 1613521625:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613521647:0;cd ..
: 1613521649:0;cd ~
: 1613521653:0;rm -r exbert
: 1613521691:0;cd apex/commonsense-discourse/training
: 1613521696:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613521795:0;vim generate_dataset.py
: 1613521799:0;vim generate.py
: 1613521829:0;rm nohup.out && touch nohup.out
: 1613521833:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613521928:0;vim generate.py
: 1613521941:0;vim generate_dataset.py
: 1613521960:0;rm nohup.out && touch nohup.out
: 1613521962:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613522032:0;vim generate_dataset.py
: 1613522050:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613522219:0;nvidia-smi 
: 1613522638:0;vim training/generate_dataset.py
: 1613528780:0;nvidia-smi 
: 1613573063:0;cd apex/commonsense-discourse/training
: 1613573066:0;cd ..
: 1613573066:0;ls
: 1613573076:0;vim nohup.out
: 1613573105:0;cd training
: 1613573108:0;vim nohup.out
: 1613573196:0;rm nohup.out && touch nohup.out
: 1613573206:0;vim generate_dataset.py
: 1613573367:0;ls
: 1613573372:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613574108:0;nvidia-smi 
: 1613574117:0;ps -ef|grep python
: 1613574146:0;kill -9 1017173
: 1613574152:0;vim generate_dataset.py
: 1613574248:0;nvidia-smi 
: 1613574254:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613579808:0;cd apex/commonsense-discourse/training
: 1613579813:0;cd ..
: 1613579821:0;vim generate.py
: 1613589052:0;vim run_af.py
: 1613589382:0;cd apex/commonsense-discourse/training
: 1613589383:0;cd ..
: 1613589385:0;vim generate.py
: 1613590569:0;ls
: 1613590575:0;vim run_af.sh
: 1613590658:0;nvidia-smi 
: 1613590663:0;ls
: 1613590670:0;cd training
: 1613590672:0;ls
: 1613590677:0;vim nohup.out
: 1613590693:0;ls
: 1613590705:0;ls ../data
: 1613590715:0;nvidia-smi 
: 1613590721:0;ls
: 1613590728:0;vim generate_dataset.py
: 1613590833:0;vim run_af.py
: 1613591812:0;ls
: 1613591824:0;rm -r __pycache__
: 1613591832:0;rm nohup.out && touch nohup.out
: 1613591842:0;git add .
: 1613591863:0;git commit -m "af_progress"
: 1613591869:0;git push
: 1613591879:0;ls
: 1613591881:0;cd training
: 1613591892:0;vim generate_ds.sh
: 1613592016:0;ls
: 1613592020:0;vim nohup.out
: 1613592050:0;vim generate_dataset.py
: 1613592135:0;vim ../generate.py
: 1613592210:0;vim ../config.py
: 1613592255:0;vim generate_dataset.py
: 1613592276:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613592282:0;rm nohup.out && touch nohup.out
: 1613592291:0;vim generate_dataset.py
: 1613592308:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613592317:0;rm nohup.out && touch nohup.out
: 1613592321:0;vim generate_dataset.py
: 1613592422:0;vim generate_ds.sh
: 1613592455:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613592519:0;nvidia-smi 
: 1613592536:0;nvidia-smi -i
: 1613592543:0;nvidia-smi 
: 1613592554:0;watch nvidia-smi
: 1613592782:0;vim generate_dataset.py
: 1613593007:0;vim generate_ds.sh
: 1613611077:0;ls ../data
: 1613611090:0;vim generate_dataset.py
: 1613611121:0;cd ..
: 1613611122:0;ls
: 1613611128:0;vim run_af.sh
: 1613611138:0;rm nohup.out && touch nohup.out
: 1613611159:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613611165:0;rm nohup.out && touch nohup.out
: 1613611178:0;chmod +x run_af.sh
: 1613611180:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613611198:0;vim run_af.py
: 1613611221:0;vim run_af.sh
: 1613611254:0;vim run_af.py
: 1613611341:0;vim run_af.sh
: 1613611392:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613611450:0;vim run_af.py
: 1613611465:0;rm nohup.out && touch nohup.out
: 1613611468:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613611506:0;vim run_af.py
: 1613611541:0;rm nohup.out && touch nohup.out
: 1613611545:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613611610:0;nvidia-smi 
: 1613611620:0;ps -ef|grep python
: 1613611635:0;kill -9 1041659
: 1613611641:0;vim run_af.sh
: 1613611700:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613612420:0;nvidia-smi 
: 1613612423:0;ps -ef|grep python
: 1613612435:0;kill -91042222
: 1613612441:0;kill -9 1042222
: 1613612445:0;sh run_af.sh
: 1613613298:0;cd ..
: 1613613306:0;vim run_af.py
: 1613613623:0;nvidia-smi 
: 1613617175:0;git add .
: 1613617183:0;ls
: 1613617188:0;git status
: 1613617201:0;git add .
: 1613617213:0;git commit -m "af_progress"
: 1613617219:0;git push
: 1613628539:0;ls
: 1613628543:0;ls data
: 1613628551:0;nvidia-smi 
: 1613662337:0;jupyter notebook --no-browser --port=8888
: 1613663544:0;c
: 1613664344:0;ls
: 1613664657:0;cd apex/commonsense-discourse/training
: 1613664657:0;ls
: 1613664659:0;cd ..
: 1613664663:0;vim config.py
: 1613682837:0;nvidia-smi 
: 1613682866:0;ls ../experiment/ctrl_2
: 1613682877:0;cd ..
: 1613682884:0;cd experiment/ctrl_2
: 1613682901:0;rm -r checkpoint-*
: 1613683002:0;cd apex/commonsense-discourse
: 1613683014:0;cat ../experiment/ctrl_2/eval_results_clm.txt
: 1613683021:0;ls
: 1613683030:0;vim run_af.sh
: 1613683063:0;vim run_af.py
: 1613683152:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613683158:0;ls
: 1613683162:0;cd ..
: 1613683206:0;jupyter notebook --no-browser --port=8888
: 1613687368:0;ls
: 1613687378:0;rm -r gpt2
: 1613691741:0;nvidia-smi 
: 1613691759:0;htop
: 1613691768:0;cd ..
: 1613691771:0;ls
: 1613691775:0;cd commonsense-discourse
: 1613691775:0;ls
: 1613691779:0;cd training
: 1613691781:0;ls
: 1613691784:0;vim train_model.sh
: 1613691814:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1613691827:0;vim train_model.sh
: 1613691840:0;vim run_clm_discovery.py
: 1613692016:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1613692026:0;nvidia-smi 
: 1613692030:0;ps -ef|grep python
: 1613692043:0;kill -9 1080192
: 1613692048:0;ps -ef|grep python
: 1613692064:0;kill -9 1080569
: 1613692068:0;ls
: 1613692078:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1613695608:0;cd apex/commonsense-discourse
: 1613695609:0;ls
: 1613695619:0;vim training/generate_ds.sh
: 1613695627:0;vim training/train_model.sh
: 1613704294:0;ls
: 1613704319:0;vim run_af.py
: 1613704377:0;vim run_af.sh
: 1613704400:0;sh run_af.sh
: 1613704413:0;vim run_af.sh
: 1613704423:0;sh run_af.sh
: 1613704437:0;vim run_af.py
: 1613704475:0;sh run_af.sh
: 1613704918:0;vim training/generate_dataset.py
: 1613705518:0;nvidia-smi 
: 1613705762:0;ls
: 1613705782:0;vim run_af.sh
: 1613705818:0;sh run_af.sh
: 1613705846:0;ls
: 1613705858:0;ls ../experiment/roberta
: 1613705879:0;cd ..
: 1613705880:0;ls
: 1613705887:0;cd experiment
: 1613705888:0;ls
: 1613705890:0;cd roberta
: 1613705891:0;ls
: 1613705893:0;cd ..
: 1613705912:0;cd commonsense-discourse
: 1613705915:0;vim run_af.sh
: 1613705947:0;sh run_af.sh
: 1613705998:0;nvidia-smi 
: 1613706011:0;vim run_af.sh
: 1613706032:0;sh run_af.sh
: 1613706619:0;cd ..
: 1613706620:0;ls
: 1613706627:0;cd commonsense-discourse
: 1613706628:0;ls
: 1613706630:0;ls data
: 1613706855:0;vim run_af.py
: 1613706956:0;jupyter notebook --no-browser --port=8888
: 1613707487:0;vim run_af.py
: 1613707503:0;vim generate.py
: 1613707725:0;ls
: 1613707768:0;vim run_af.sh
: 1613707788:0;ls
: 1613707793:0;cd training
: 1613707795:0;ls
: 1613707799:0;vim generate_ds.sh
: 1613707818:0;cd ..
: 1613707822:0;cd experiment
: 1613707823:0;ls
: 1613707829:0;cd ..
: 1613707835:0;cd commonsense-discourse/data
: 1613707836:0;ls
: 1613707846:0;rm ctrl_valid*
: 1613707848:0;cd ..
: 1613707850:0;cd training
: 1613707852:0;vim generate_ds.sh
: 1613707881:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613707893:0;nvidia-smi 
: 1613707904:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f valid.out
: 1613707909:0;touch valid.out
: 1613707911:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f valid.out
: 1613708074:0;nvidia-smi 
: 1613708079:0;ps -ef|grep python
: 1613708097:0;kill -9 1092396
: 1613708105:0;kill -9 1092634
: 1613708118:0;nvidia-smi 
: 1613708123:0;ps -ef|grep python
: 1613708135:0;kill -9 1092516
: 1613708138:0;nvidia-smi 
: 1613708151:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613708252:0;nvidia-smi 
: 1613713001:0;htop
: 1613713020:0;ps -ef|grep python
: 1613713041:0;kill -9 1092994
: 1613713048:0;nvidia-smi 
: 1613713053:0;cd apex/commonsense-discourse
: 1613713055:0;cd training
: 1613713056:0;ls
: 1613713061:0;vim generate_ds.sh
: 1613713104:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613713161:0;nvidia-smi 
: 1613713171:0;htop
: 1613713190:0;watch nv
: 1613713194:0;watch nvidia-smi
: 1613713201:0;e
: 1613745880:0;c
: 1613745890:0;cd apex/ex/commonsense-discourse
: 1613745895:0;cd apex/commonsense-discourse
: 1613745897:0;ls
: 1613745909:0;ls data
: 1613745915:0;vim run_af.sh
: 1613745967:0;sh run_af.sh
: 1613746050:0;vim run_af.py
: 1613746104:0;vim run_af.sh
: 1613746111:0;sh run_af.sh
: 1613746140:0;ls ../experiment/roberta
: 1613746160:0;vim run_af.sh
: 1613746176:0;sh run_af.sh
: 1613746183:0;vim run_af.sh
: 1613746201:0;sh run_af.sh
: 1613746698:0;cd apex/commonsense-discourse
: 1613746699:0;ls
: 1613746716:0;ls ../experiment/roberta
: 1613746756:0;vim run_af.sh
: 1613746853:0;sh run_af.sh
: 1613746875:0;ls data
: 1613746879:0;vim run_af.sh
: 1613746973:0;cd data
: 1613746973:0;ls
: 1613746982:0;rm ctrl_valid.json
: 1613746984:0;cd ..
: 1613746988:0;cd training
: 1613746992:0;vim generate_ds.sh
: 1613747064:0;cd ..
: 1613747073:0;cd ../experiment
: 1613747074:0;ls
: 1613747081:0;mv ctrl ctrl_1
: 1613747086:0;cd ../commonsense-discourse
: 1613747089:0;cd training
: 1613747092:0;vim generate_ds.sh
: 1613747105:0;ls ../data
: 1613747111:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1613747137:0;vim training/generate_ds.sh
: 1613747907:0;nvidia-smi 
: 1613748459:0;jupyter notebook --no-browser --port=8888
: 1613748747:0;nvidia-smi 
: 1613776853:0;ls
: 1613776856:0;ls data
: 1613777335:0;vim generate.py
: 1613778183:0;git status
: 1613778192:0;git add .
: 1613778211:0;git commit -m "af_progress"
: 1613778216:0;git push
: 1613778231:0;ls
: 1613778245:0;vim run_af.sh
: 1613778321:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613778708:0;ls
: 1613778730:0;vim generate.py
: 1613779058:0;vim run_af.py
: 1613779098:0;rm nohup.out && touch nohup.out
: 1613779102:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613801393:0;vim run_af.sh
: 1613801423:0;sh run_af.sh
: 1613801535:0;ls
: 1613801572:0;vim run_af.sh
: 1613801597:0;nvidia-smi 
: 1613801700:0;git status
: 1613801742:0;git add .
: 1613801748:0;git commit -m "af_progress"
: 1613801752:0;git push
: 1613801879:0;ls
: 1613801884:0;cd training
: 1613801885:0;ls
: 1613801891:0;vim generate_ds.sh
: 1613801943:0;ls
: 1613801950:0;vim train_model.sh
: 1613801997:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1613802046:0;vim apex/commonsense-discourse/training/generate_ds.sh
: 1613802055:0;vim apex/commonsense-discourse/training/train_model.sh
: 1613802064:0;nvidia-smi 
: 1613802071:0;watch nvidia-smi 
: 1613851884:0;jupyter notebook --no-browser --port=8888
: 1613852251:0;cd transformers-importance-sampling
: 1613852252:0;ls
: 1613852267:0;git status
: 1613852271:0;cd ..
: 1613852276:0;cd apex/pex/commonsense-discourse
: 1613852280:0;cd apex/commonsense-discourse
: 1613852280:0;ls
: 1613852303:0;vim rn_af.p
: 1613852311:0;vim run_af.py
: 1613852424:0;ls ../experiment/roberta
: 1613852436:0;vim run_af.sh
: 1613852493:0;vim run_af.py
: 1613852562:0;vim run_af.sh
: 1613852579:0;rm -r ../experiment/roberta
: 1613852584:0;sh run_af.sh
: 1613852700:0;vim run_af.sh
: 1613852714:0;sh run_af.sh
: 1613852760:0;nvidia-smi 
: 1613852768:0;vim run_af.sh
: 1613852799:0;sh run_af.sh
: 1613852859:0;nvidia-smi 
: 1613852868:0;vim run_af.sh
: 1613852885:0;sh run_af.sh
: 1613854826:0;vim run_af.sh
: 1613854890:0;sh run_af.sh
: 1613859610:0;vim run_af.sh
: 1613859695:0;sh run_af.sh
: 1613861532:0;vim run_af.sh
: 1613861569:0;sh run_af.sh
: 1613861832:0;vim training/generate_ds.sh
: 1613861849:0;vim run_af.sh
: 1613861872:0;cd ../
: 1613861886:0;rm -r experiment/roberta/
: 1613861897:0;cd commonsense-discourse
: 1613861900:0;vim run_af.sh
: 1613861961:0;sh run_af.sh
: 1613866950:0;vim run_af.sh
: 1613867342:0;sh run_af.sh
: 1613867354:0;vim run_af.sh
: 1613867371:0;sh run_af.sh
: 1613867819:0;nvidia-smi 
: 1613869195:0;vim config.py
: 1613869402:0;vim run_af.py
: 1613869427:0;vim generate.py
: 1613869671:0;vim config.py
: 1613869797:0;cd ..
: 1613869816:0;rm -r  experiment/roberta
: 1613869890:0;ls
: 1613869893:0;cd commonsense-discourse
: 1613869894:0;ls
: 1613869903:0;nvidia-smi 
: 1613870444:0;cd training
: 1613870448:0;vim nohup.out
: 1613873944:0;nvidia-smi 
: 1613879996:0;vim nohup.out
: 1613880428:0;ls
: 1613880431:0;cd ..
: 1613880431:0;ls
: 1613880440:0;vim run_af.sh
: 1613880472:0;sh run_af.sh
: 1613881393:0;cd apex/commonsense-discourse
: 1613881398:0;vim generate.py
: 1613924216:0;nvidia-smi 
: 1613924225:0;cd apex/commonsense-discourse
: 1613924231:0;vim training/nohup.out
: 1613924259:0;vim generate.py
: 1613924931:0;cd apex/commonsense-discourse
: 1613924937:0;vim run_af.py
: 1613928020:0;black generate.py
: 1613928026:0;vim run_af.py
: 1613928035:0;vim generate.py
: 1613928066:0;black generate.py
: 1613928137:0;vim generate.py
: 1613928230:0;black run_af.py
: 1613928240:0;vim run_af.py
: 1613928630:0;nvvidia-smi 
: 1613928636:0;nvidia-smi 
: 1613929024:0;vim training/nohup.out
: 1613929814:0;git it status
: 1613929819:0;git status
: 1613929825:0;git add .
: 1613929851:0;git commit -m "added replace_one functionality"
: 1613929867:0;git push
: 1613933895:0;nvidia-smi 
: 1613945552:0;vim run_af.sh
: 1613945640:0;sh run_af.sh
: 1613945648:0;vim run_af.sh
: 1613945660:0;sh run_af.sh
: 1613945724:0;vim run_af.sh
: 1613945732:0;vim run_af.py
: 1613945837:0;vim run_af.sh
: 1613945856:0;sh run_af.sh
: 1613946022:0;vim run_af.py
: 1613946031:0;vim generate.py
: 1613946346:0;sh run_af.sh
: 1613949254:0;vim config.py
: 1613949271:0;sh run_af.sh
: 1613949419:0;vim generate.py
: 1613949565:0;sh run_af.sh
: 1613951115:0;vim run_af.sh
: 1613951170:0;ls data
: 1613951199:0;mv data/ctrl_valid_1.json data/ctrl_valid_2.json
: 1613951208:0;mv data/ctrl_valid.json data/ctrl_valid_1.json
: 1613951212:0;vim run_af.sh
: 1613951231:0;vim run_af.py
: 1613951264:0;vim run_af.sh
: 1613951283:0;sh run_af.sh
: 1613951289:0;vim run_af.sh
: 1613951302:0;rm data/ctrl_valid_2.json
: 1613951304:0;sh run_af.sh
: 1613952114:0;vim run_af.py
: 1613952181:0;sh run_af.sh
: 1613952562:0;vim run_af.py
: 1613952568:0;vim generate.py
: 1613952607:0;ls
: 1613952621:0;vim run_af.sh
: 1613952667:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1613957182:0;git add .
: 1613957200:0;git commit -m "added working  replace_one functionality"
: 1613957206:0;git push
: 1613958756:0;vim run_af.sh
: 1613958771:0;nvidia-smi 
: 1613965958:0;vim run_af.sh
: 1613965992:0;sh run_af.sh
: 1613966101:0;vim run_af.sh
: 1613966163:0;nohup /home/nlp/apex/commonsense-discourse/run_af.sh & tail -f nohup.out
: 1614012986:0;cd apex/commonsense-discourse
: 1614012990:0;vim run_af.sh
: 1614013019:0;sh run_af.sh
: 1614051883:0;cd data
: 1614051884:0;ls
: 1614051890:0;rm ctrl_main.json
: 1614051892:0;cd ..
: 1614051898:0;cd training
: 1614051901:0;ls
: 1614051913:0;vim generate_ds.sh
: 1614051938:0;nvidia-smi 
: 1614051942:0;vim generate_ds.sh
: 1614051956:0;sh generate_ds.sh
: 1614051997:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f nohup.out
: 1614052399:0;nvidia-smi 
: 1614052407:0;htop
: 1614052417:0;cd apex/commonsense-discourse
: 1614052419:0;cd training
: 1614052454:0;touch valid.out
: 1614052466:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f valid.out
: 1614052533:0;nvidia-smi 
: 1614052540:0;htop
: 1614052698:0;nvidia-smi 
: 1614052707:0;sh generate_ds.sh
: 1614052820:0;rm nohup.out && touch nohup.out
: 1614052825:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f valid.out
: 1614091875:0;cd apex/commonsense-discourse
: 1614091887:0;vim run_af.sh
: 1614091912:0;sh run_af.sh
: 1614091926:0;ls data
: 1614091935:0;cd training
: 1614091936:0;ls
: 1614091940:0;vim nohup.out
: 1614091950:0;nvidia-smi 
: 1614091966:0;rm nohup.out && touch nohup.out
: 1614091969:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f valid.out
: 1614095060:0;cd apex/commonsense-discourse/training
: 1614095062:0;ls
: 1614095067:0;vim run_clm_discovery.py
: 1614095207:0;cd ..
: 1614095208:0;ls
: 1614095217:0;cd ..
: 1614095220:0;ls
: 1614095226:0;cd experiment
: 1614095227:0;ls
: 1614095231:0;rm -r ctrl_4
: 1614095508:0;rm -r ctrl_3
: 1614095798:0;rm -r ctrl_2
: 1614095809:0;cd ../commonsense-discourse/training
: 1614095813:0;vim generate_ds.sh
: 1614095867:0;vim generate_dataset.py
: 1614095878:0;vim run_clm_discovery.py
: 1614096107:0;nohup /home/nlp/apex/commonsense-discourse/training/generate_ds.sh & tail -f valid.out
: 1614096398:0;nvidia-smi 
: 1614096409:0;ps -ef|grep python
: 1614096442:0;nvidia-smi 
: 1614096446:0;ps -ef|grep python
: 1614096462:0;kill -9 1337962
: 1614096476:0;vim train_model.sh
: 1614096511:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f valid.out
: 1614096540:0;nvidia-smi 
: 1614096582:0;vim train_model.sh
: 1614096605:0;nvidia-smi 
: 1614096652:0;vim train_model.sh
: 1614096677:0;htop
: 1614096686:0;vim train_model.sh
: 1614096696:0;htop
: 1614096772:0;vim train_model.sh
: 1614096780:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f valid.out
: 1614096945:0;nvidia-smi 
: 1614097015:0;htop
: 1614098383:0;nvidia-smi 
: 1614098598:0;ls experiments/big_small/bert_large
: 1614099184:0;jupyter notebook --no-browser --port=8888
: 1614100041:0;nvidia-smi 
: 1614100075:0;cd apex/commonsense-discourse/training
: 1614100077:0;vim run_clm_discovery.py
: 1614100147:0;pip uninstall wandb
: 1614100179:0;vim run_clm_discovery.py
: 1614100354:0;vim ../../../transformers-importance-sampling/get_heuristic_stats.py
: 1614100550:0;nvidia-smi 
: 1614112361:0;vim generate_dataset.py
: 1614112368:0;vim run_clm_discovery.py
: 1614112475:0;ps -ef|grep python
: 1614112483:0;kill -9 1339225
: 1614112500:0;kill -9 1339865
: 1614112506:0;nvidia-smi 
: 1614112521:0;vim run_clm_discovery.py
: 1614112526:0;nvidia-smi 
: 1614112566:0;cd ..
: 1614112572:0;cd ../experiment/
: 1614112573:0;ls
: 1614112579:0;rm -r ctrl_2
: 1614112657:0;rm -r ctrl_3
: 1614112714:0;cd ../commonsense-discourse/training
: 1614112721:0;vim train_model.sh
: 1614112770:0;vim run_clm_discovery.py
: 1614112804:0;vim train_model.sh
: 1614112845:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f valid.out
: 1614112859:0;vim train_model.sh
: 1614112882:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f valid.out
: 1614116838:0;nvidia-smi 
: 1614116848:0;ps -ef|grep python
: 1614116861:0;vim nohup.out
: 1614116885:0;vim run_clm_discovery.py
: 1614116926:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614116955:0;nvidia-smi 
: 1614116976:0;vim train_model.sh
: 1614117004:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614124291:0;nvidia-smi 
: 1614180955:0;c
: 1614180960:0;nvidia-smi 
: 1614180986:0;jupyter notebook --no-browser --port=8888
: 1614229964:0;cd transformers-importance-sampling
: 1614229967:0;ls
: 1614230017:0;vim word_emb.py
: 1614230315:0;vim heuristics.sh
: 1614230344:0;mv heuristics.sh show_ex.py
: 1614230368:0;mv show_ex.py huristics.sh
: 1614230375:0;vim heuristics.sh
: 1614230403:0;mv huristics.sh heuristics.sh
: 1614230406:0;vim heuristics.sh
: 1614230441:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1614231160:0;nvidia-smi 
: 1614265888:0;cd transformers-importance-sampling
: 1614265891:0;vim nohup.out
: 1614265911:0;vim word_emb.py
: 1614265945:0;rm nohup.out && touch nohup.out
: 1614265951:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1614276747:0;vim word_emb.py
: 1614276814:0;python3 word_emb.py
: 1614282889:0;cd apex/commonsense-discourse/
: 1614282892:0;git status
: 1614282898:0;git add .
: 1614282904:0;git commit -m "added working  replace_one functionality"
: 1614282918:0;git push
: 1614287593:0;v ~/.bashrc
: 1614287778:0;vim word_emb.py
: 1614288442:0;p3 word_emb.py
: 1614314444:0;vim word_emb.py
: 1614314611:0;p3 word_emb.py
: 1614314616:0;vim word_emb.py
: 1614314634:0;p3 word_emb.py
: 1614316538:0;nvidia-smi 
: 1614350857:0;cd transformers-importance-sampling
: 1614350859:0;ls
: 1614350865:0;p3 word_emb.py
: 1614355784:0;vim ~/.bashrc
: 1614356554:0;vim ~/.zshrc
: 1614358526:0;vim word_emb.py
: 1614358550:0;p3 word_emb.py
: 1614362894:0;cat /proc/cpuinfo
: 1614362958:0;lscpu
: 1614362972:0;javac
: 1614363293:0;nvidia-smi 
: 1614363300:0;cd apex/commonsense-discourse/
: 1614363303:0;cd training
: 1614363306:0;vim nohup.out
: 1614366404:0;vim ~/.zshrc
: 1614368960:0;cd ~/data
: 1614368961:0;ls
: 1614368973:85;vim word_emb.py
: 1614369060:0;p3 word_emb.py
: 1614373970:0;ds_report
: 1614374518:0;nvidia-smi 
: 1614376158:0;vim word_emb.py
: 1614376180:0;p3 word_emb.py
: 1614397357:0;vim word_emb.py
: 1614401266:0;ls
: 1614401270:0;vim heuristics.sh
: 1614401287:0;rm nohup.out && touch nohup.out
: 1614401291:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1614440695:0;ls
: 1614440698:0;nvidia-smi 
: 1614440708:0;cd apex/experiment
: 1614440708:0;ls
: 1614440714:0;cd ..
: 1614440722:0;cd commonsense-discourse/training
: 1614440723:0;ls
: 1614440730:0;vim run_clm_discovery.py
: 1614440963:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614440998:0;cd apex/commonsense-discourse/training
: 1614441002:0;vim train_model.sh
: 1614441020:0;vim run_clm_discovery.py
: 1614441028:0;vim train_model.sh
: 1614441048:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614441050:0;vim train_model.sh
: 1614441073:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614441106:0;ls
: 1614441111:0;rm k.py
: 1614441115:0;nvidia-smi 
: 1614441120:0;htop
: 1614442327:0;nvidia-smi 
: 1614442332:0;htop
: 1614443703:0;nvidia-smi 
: 1614443710:0;htop
: 1614444103:0;nvidia-smi 
: 1614444114:0;vim apex/commonsense-discourse/training/nohup.out
: 1614444274:0;nvidia-smi 
: 1614444277:0;ps -ef|grep python
: 1614444310:0;kill -9 2704279
: 1614444326:0;kill -9 2704802
: 1614444331:0;kill -9 2704814
: 1614444339:0;kill -9 2704813
: 1614444341:0;nvidia-smi 
: 1614444369:0;ps -ef|grep python
: 1614444379:0;kill -9 2704443
: 1614444387:0;kill -9 2704805
: 1614444401:0;kill -9 2705232
: 1614444404:0;ps -ef|grep python
: 1614444416:0;kill -9 2704804
: 1614444420:0;kill -9 2704815
: 1614444424:0;kill -9 2704816
: 1614444427:0;ps -ef|grep python
: 1614444436:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614448220:0;vim train_model.sh
: 1614448244:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614450628:0;cd transformers-importance-sampling
: 1614450631:0;vim nohup.out
: 1614450665:0;mv nohup.out word_emb_1.txt
: 1614450668:0;vim word_emb.py
: 1614450715:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1614450729:0;touch nohup.out
: 1614450731:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1614458125:0;jupyter notebook --no-browser --port=8888
: 1614461951:0;cd apex/experiment/ctrl_2
: 1614461954:0;ls
: 1614461957:0;rm -r checkpoint-*
: 1614462656:0;cd ../ctrl_3
: 1614462659:0;rm -r checkpoint-*
: 1614488298:0;cd ..
: 1614488300:0;ls
: 1614488330:0;git lfs install
: 1614525295:0;cd transformers-importance-sampling
: 1614525298:0;vim nohup.out
: 1614535673:0;vim *.txt
: 1614535684:0;ls
: 1614535698:0;vim word_emb_1.txt
: 1614535853:0;nvidia-smi 
: 1614535859:0;cd ..
: 1614535866:0;cd apex/commonsense-discourse/training
: 1614535868:0;vim nohup.out
: 1614548002:0;cd ..
: 1614548007:0;cd ../transformers-importance-sampling/
: 1614548008:0;ls
: 1614548019:0;vim word_emb.py
: 1614548089:0;p3 word_emb.py
: 1614551108:0;vim word_emb.py
: 1614551133:0;p3 word_emb.py
: 1614577589:0;vim word_emb_1.txt
: 1614578494:0;vim word_emb.py
: 1614611343:0;nvidia-smi 
: 1614611362:0;cd transformers-importance-sampling
: 1614611371:0;vim word_emb_1.txt
: 1614620953:0;vim word_emb.py
: 1614620971:0;vim ../apex/commonsense-discourse/training/nohup.out
: 1614621006:0;p3 word_emb.py
: 1614630555:0;nvidia-smi 
: 1614649586:0;ls
: 1614649587:0;cd ..
: 1614649648:0;ls
: 1614649656:0;cd apex/experiment
: 1614649657:0;ls
: 1614649664:0;git lfs install
: 1614649703:0;cd ..
: 1614649708:0;mkdir tools
: 1614649710:0;cd tools
: 1614649713:0;wget https://github.com/git-lfs/git-lfs/releases/download/v2.13.2/git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614649723:0;tar -xzvf git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614649733:0;./install.sh
: 1614649786:0;vim install.sh
: 1614649820:0;./install.sh
: 1614649827:0;cd ..
: 1614649830:0;git lfs install
: 1614649834:0;cd tools
: 1614649836:0;git lfs install
: 1614703250:0;nvidia-smi 
: 1614703267:0;cd apex/commonsense-discourse/training
: 1614703273:0;vim nohup.out
: 1614703307:0;cd ../
: 1614703310:0;cd ../experiment
: 1614703311:0;ls
: 1614703314:0;cd ctrl_1
: 1614703329:0;cd ..
: 1614703336:0;ls ctrl_1
: 1614703343:0;cd ctrl_1
: 1614703345:0;ls
: 1614703351:0;rm -r checkpoint-*
: 1614703360:0;cd ..
: 1614703368:0;cd ctrl_2
: 1614703369:0;ls
: 1614703371:0;cd ..
: 1614703381:0;cd ctrl_1_flipped
: 1614703382:0;ls
: 1614703394:0;cd ..
: 1614711242:0;cd apex/commonsense-discourse/data
: 1614711243:0;ls
: 1614711251:0;vim ctrl_valid_1.json
: 1614713983:0;nvidia-smi 
: 1614714260:0;ls
: 1614714262:0;cd ..
: 1614714268:0;cd experiment
: 1614714269:0;ls
: 1614714277:0;cd ctrl_1
: 1614714279:0;ls
: 1614714337:0;git lfs install
: 1614714410:0;cd ..
: 1614714415:0;cd tools
: 1614714415:0;ls
: 1614714419:0;rm -r *
: 1614714427:0;rm -fr *
: 1614714437:0;wget https://github.com/git-lfs/git-lfs/archive/v2.13.2.zip
: 1614714440:0;ls
: 1614714445:0;unzip v2.13.2.zip
: 1614714560:0;ls
: 1614714563:0;rm -fr *
: 1614714626:0;wget https://github.com/git-lfs/git-lfs/archive/v2.13.2.tar.gz
: 1614714633:0;tar -xzvf git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614714646:0;tar -xzvf v2.13.2.tar.gz
: 1614715270:0;go
: 1614715332:0;./configure --prefix=~/tools && make && make install
: 1614715334:0;ls
: 1614715338:0;cd git-lfs-2.13.2
: 1614715342:0;./configure --prefix=~/tools && make && make install
: 1614715344:0;ls
: 1614715363:0;cd ..
: 1614715372:0;rm -r *
: 1614715420:0;wget https://github.com/git-lfs/git-lfs/releases/download/v2.13.2/git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614715427:0;tar -xzvf git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614715451:0;cd git-lfs-2.13.2
: 1614715454:0;cd man
: 1614715455:0;ls
: 1614715463:0;cd ..
: 1614715464:0;ls
: 1614715487:0;vim README.md
: 1614715527:0;cd ..
: 1614715837:0;ls
: 1614716570:0;cd tools
: 1614716575:0;wget https://packagecloud.io/github/git-lfs/packages/debian/buster/git-lfs_2.13.2_amd64.deb/download
: 1614716577:0;ls
: 1614716848:0;rm -r *
: 1614716856:0;wget https://github.com/git-lfs/git-lfs/releases/download/v2.13.2/git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614716865:0;tar -zxvf git-lfs-linux-amd64-v2.13.2.tar.gz
: 1614716893:0;ls
: 1614716899:0;vim ./install.sh
: 1614716940:0;./install.sh
: 1614716946:0;git lfs install
: 1614716953:0;cd ..
: 1614716957:0;echo $PATH
: 1614717008:0;vim ~/.bashrc
: 1614717106:0;ls tools
: 1614717123:0;cd tools
: 1614717126:0;vim install.sh
: 1614717195:0;./install.sh
: 1614717199:0;vim install.sh
: 1614717220:0;./install.sh
: 1614717223:0;ls
: 1614717227:0;cd ..
: 1614717258:0;export PATH=/home/nlp/tools/bin:$PATH
: 1614717261:0;echo $PATH
: 1614717273:0;cd apex/experiment
: 1614717274:0;ls
: 1614717278:0;cd ctrl_1
: 1614717280:0;git lfs install
: 1614717285:0;ls
: 1614717298:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_1
: 1614717306:0;ls
: 1614717311:0;mv * ctrl_discovery_1
: 1614717313:0;ls
: 1614717322:0;mv ctrl_discovery_1 ..
: 1614717324:0;cd ..
: 1614717324:0;ls
: 1614717329:0;ls ctrl_1
: 1614717330:0;ls
: 1614717337:0;rm -r ctrl_1
: 1614717352:0;cd ctrl_discovery_1
: 1614717354:0;ls
: 1614717374:0;git lfs install
: 1614717379:0;transformers-cli lfs-enable-largefiles
: 1614717392:0;transformers-cli lfs-enable-largefiles .
: 1614717398:0;git add .
: 1614717519:0;git commit -m "v1"
: 1614717522:0;git push
: 1614718392:0;ls
: 1614718398:0;rm eval_results_clm.txt
: 1614718409:0;rm trainer_state.json
: 1614718417:0;rm train_results.txt
: 1614718420:0;git add .
: 1614718423:0;git commit -m "v1"
: 1614718426:0;git push
: 1614718510:0;cd ..
: 1614718511:0;ls
: 1614718520:0;cd ctrl_2
: 1614718531:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_2
: 1614718537:0;ls
: 1614718543:0;rm eval_results_clm.txt
: 1614718549:0;rm train_results.txt
: 1614718559:0;rm training_args.bin
: 1614718564:0;mv * ctrl_discovery_2
: 1614718570:0;mv ctrl_discovery_2 ..
: 1614718572:0;cd ..
: 1614718577:0;rm -r ctrl_2
: 1614718582:0;cd ctrl_discovery_2
: 1614718586:0;git lfs install
: 1614718590:0;transformers-cli lfs-enable-largefiles .
: 1614718597:0;git add .
: 1614718741:0;git commit -m "v1"
: 1614718745:0;git push
: 1614719385:0;ls
: 1614719386:0;cd ..
: 1614719388:0;ls
: 1614719393:0;cd ctrl_3
: 1614719424:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_3
: 1614719436:0;mv * ctrl_discovery_3
: 1614719442:0;mv ctrl_discovery_3 ..
: 1614719443:0;cd ..
: 1614719447:0;rm -r ctrl_3
: 1614719452:0;cd ctrl_discovery_3
: 1614719455:0;git lfs install
: 1614719458:0;transformers-cli lfs-enable-largefiles .
: 1614719465:0;git add .
: 1614719546:0;ls
: 1614719552:0;rm eval_results_clm.txt
: 1614719556:0;rm training_args.bin
: 1614719561:0;rm train_results.txt
: 1614719563:0;git add .
: 1614719567:0;git commit -m "v1"
: 1614719570:0;git push
: 1614726134:0;cd ..
: 1614726134:0;ls
: 1614726136:0;cd ..
: 1614726138:0;cd da
: 1614726145:0;cd commonsense-discourse
: 1614726148:0;ls
: 1614726152:0;cd data
: 1614726155:0;vim ctrl_valid_1.json
: 1614726321:0;cd ~
: 1614726324:0;nvidia-smi 
: 1614783583:0;jupyter notebook --no-browser --port=8888
: 1614783877:0;cd apex/commonsense-discourse
: 1614783882:0;vim run_af.sh
: 1614784052:0;git pull
: 1614784071:0;git stash
: 1614784079:0;git pull
: 1614784126:0;ls
: 1614784132:0;cd training
: 1614784136:0;vim generate_dataset.py
: 1614784143:0;vim generate_ds.sh
: 1614784187:0;sh generate_ds.sh
: 1614784222:0;cd ..
: 1614784236:0;cd experiment/ctrl_1_flipped
: 1614784236:0;ls
: 1614784241:0;rm -r checkpoint-*
: 1614786358:0;ls
: 1614786365:0;cd ..
: 1614786370:0;cd ctrl_2_flipped
: 1614786379:0;rm -r checkpoint-*
: 1614787107:0;cd ..
: 1614787112:0;cd ctrl_1_flipped
: 1614787175:0;export PATH=/home/nlp/tools/bin:$PATH
: 1614787181:0;git lfs install
: 1614787190:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_flipped_1
: 1614787198:0;ls
: 1614787204:0;rm eval_results_clm.txt
: 1614787211:0;rm trainer_state.json
: 1614787219:0;rm train_results.txt
: 1614787226:0;transformers-cli lfs-enable-largefiles .
: 1614787245:0;mv * ctrl_discovery_flipped_1
: 1614787256:0;mv ctrl_discovery_flipped_1 ..
: 1614787261:0;lss
: 1614787261:0;ls
: 1614787263:0;cd ..
: 1614787271:0;rm -r ctrl_1_flipped
: 1614787277:0;cd ctrl_discovery_flipped_1
: 1614787282:0;git lfs install
: 1614787286:0;transformers-cli lfs-enable-largefiles .
: 1614787293:0;git add .
: 1614787384:0;git commit -m "v1"
: 1614787388:0;git push
: 1614787951:0;cd ..
: 1614787961:0;ls
: 1614787972:0;cd ctrl_2_flipped
: 1614787976:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_flipped_2
: 1614787983:0;ls
: 1614787990:0;mv * ctrl_discovery_flipped_2
: 1614787994:0;mv ctrl_discovery_flipped_2 ..
: 1614787996:0;cd ..
: 1614788003:0;rm -r ctrl_2_flipped
: 1614788018:0;cd ctrl_discovery_flipped_2
: 1614788020:0;ls
: 1614788024:0;git lfs install
: 1614788032:0;rm eval_results_clm.txt
: 1614788036:0;rm trainer_state.json
: 1614788042:0;rm train_results.txt
: 1614788049:0;transformers-cli lfs-enable-largefiles .
: 1614788083:0;git add .
: 1614788246:0;git commit -m "v1"
: 1614788249:0;git push
: 1614789494:0;cd ..
: 1614789502:0;cd commonsense-discourse/training
: 1614789503:0;ls
: 1614789516:0;vim run_clm_discovery.py
: 1614789615:0;git status
: 1614789620:0;git stash
: 1614789626:0;git pull
: 1614789648:0;vim run_clm_discovery.py
: 1614789775:0;vim train_model.sh
: 1614789790:0;pwd
: 1614789793:0;vim train_model.sh
: 1614789905:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614789916:0;vim train_model.sh
: 1614789941:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614790622:0;nvidia-smi 
: 1614811908:0;ls apex/experiment
: 1614816187:0;nvidia-smi 
: 1614816432:0;echo $HOME
: 1614828388:0;nvidia-smi 
: 1614828399:0;cd apex/commonsense-discourse/training
: 1614828401:0;vim nohup.out
: 1614870939:0;nvidia-smi 
: 1614870944:0;jupyter notebook --no-browser --port=8888
: 1614871088:0;ls apex/experiment
: 1614871094:0;ls apex/experiment/ctrl_discovery_1
: 1614871435:0;cd apex/commonsense-discourse/training
: 1614871438:0;vim train_model.sh
: 1614871469:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614886300:0;nvidia-smi 
: 1614886304:0;cd apex/commonsense-discourse/training
: 1614886309:0;rm nohup.out && touch nohup.out
: 1614886313:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614889978:0;cd apex/experiment
: 1614889979:0;ls
: 1614889983:0;cd ctrl_discovery_1
: 1614889988:0;git status
: 1614889998:0;export PATH=/home/nlp/tools/bin:$PATH
: 1614890001:0;git status
: 1614890004:0;ls
: 1614890010:0;rm -r checkpoint-*
: 1614913491:0;nvidia-smi 
: 1614913501:0;cd apex/commonsense-discourse/training
: 1614913506:0;vim nohup.out
: 1614913515:0;cd ..
: 1614913518:0;cd ...
: 1614913523:0;cd apex/experiment
: 1614913524:0;ls
: 1614913528:0;cd ctrl_discovery_
: 1614913530:0;cd ctrl_discovery_1
: 1614913531:0;ls
: 1614913533:0;git status
: 1614913536:0;export PATH=/home/nlp/tools/bin:$PATH
: 1614913539:0;git status
: 1614913548:0;ls
: 1614913566:0;vim eval_results_clm.txt
: 1614913573:0;rm eval_results_clm.txt
: 1614913580:0;rm train_results.txt
: 1614913585:0;rm trainer_state.json
: 1614913591:0;transformers-cli lfs-enable-largefiles .
: 1614913599:0;git add .
: 1614913683:0;git commit -m "v1.1"
: 1614913688:0;git push
: 1614914335:0;cd ..
: 1614924624:0;nvidia-smi 
: 1614959840:0;cd apex/commonsense-discourse/training
: 1614959842:0;nvidia-smi 
: 1614959850:0;vim generate_ds.sh
: 1614959865:0;vim train_model.sh
: 1614960046:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1614960067:0;cd apex/commonsense-discourse/training
: 1614960069:0;ls
: 1614960077:0;cd ..
: 1614960079:0;ls
: 1614960098:0;cd ..
: 1614960120:0;cd experiment/ctrl_discovery_2
: 1614960134:0;export PATH=/home/nlp/tools/bin:$PATH
: 1614960143:0;transformers-cli lfs-enable-largefiles .
: 1614960150:0;git status
: 1614960154:0;rm -r checkpoint-*
: 1614960214:0;cd ..
: 1614960216:0;ls
: 1614960222:0;cd ctrl_discovery_2
: 1614960233:0;git status
: 1614960239:0;rm eval_results_clm.txt
: 1614960255:0;rm train_results.txt
: 1614960306:0;rm training_args.bin
: 1614960309:0;git add .
: 1614960436:0;git commit -m "v1.1"
: 1614960472:0;git push
: 1614961183:0;nvidia-smi 
: 1614965229:0;cd ~/transformers-importance-sampling/
: 1614965242:0;ls
: 1614965248:0;vim core/clustering.py
: 1614965299:0;ls
: 1614965309:0;rm run_seed_fig_1.sh
: 1614965317:0;vim roberta_ambi.txt
: 1614965324:0;rm roberta_ambi.txt
: 1614965325:0;ls
: 1614965331:0;rm -r wandb
: 1614965381:0;vim word_emb_1.txt
: 1614965839:0;jupyter notebook --no-browser --port=8888
: 1614966040:0;cd training
: 1614966044:0;cd transformers-importance-sampling
: 1614966049:0;vim word_emb_1.txt
: 1614978610:0;nvidia-smi 
: 1614978613:0;htop
: 1615007780:0;nvidia-smi 
: 1615007789:0;cd apex/commonsense-discourse/training
: 1615007790:0;ls
: 1615007795:0;vim train_model.sh
: 1615007860:0;vim run_clm_discovery.py
: 1615007916:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1615046333:0;nvidia-smi 
: 1615046338:0;cd apex/commonsense-discourse/training
: 1615046344:0;vim nohup.out
: 1615046353:0;cd ..
: 1615046566:0;ls
: 1615046576:0;cd ../experiment/ctrl_discovery_3
: 1615046579:0;git status
: 1615046584:0;rm -r checkpoint-*
: 1615046601:0;git status
: 1615046606:0;rm eval_results_clm.txt
: 1615046610:0;rm training_args.bin
: 1615046620:0;rm train_results.txt
: 1615046629:0;rm trainer_state.json
: 1615046633:0;git add .
: 1615046636:0;export PATH=/home/nlp/tools/bin:$PATH
: 1615046640:0;transformers-cli lfs-enable-largefiles .
: 1615046670:0;git commit -m "v1.1"
: 1615046692:0;git add .
: 1615046710:0;rm .git/index.lock\

: 1615046714:0;git add .
: 1615046843:0;git commit -m "v1.1"
: 1615046848:0;git push
: 1615050030:0;nvidia-smi 
: 1615050037:0;cd ..
: 1615050043:0;cd commonsense-discourse/training
: 1615050048:0;vim train_model.sh
: 1615050076:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1615072034:0;cd
: 1615072040:0;cd apex/experiment
: 1615072041:0;ls
: 1615072046:0;cd ctrl_discovery_flipped_1
: 1615072049:0;git status
: 1615072052:0;export PATH=/home/nlp/tools/bin:$PATH
: 1615072054:0;git status
: 1615072068:0;rm -r checkpoint-*
: 1615072103:0;htop
: 1615072116:0;rm eval_results_clm.txt
: 1615072123:0;rm train_results.txt
: 1615072129:0;rm trainer_state.json tate.json
: 1615072132:0;rm trainer_state.json 
: 1615072134:0;ls
: 1615072141:0;rm training_args.bin
: 1615072144:0;transformers-cli lfs-enable-largefiles .
: 1615072152:0;git add .
: 1615072264:0;cd ..
: 1615072268:0;cd ../commonsense-discourse
: 1615072275:0;vim training/train_model.sh
: 1615072287:0;vim training/run_clm_discovery.py
: 1615072659:0;cd training
: 1615072660:0;ls
: 1615072663:0;vim train_model.sh
: 1615072723:0;cd ..
: 1615072726:0;git status
: 1615072743:0;git add AF.ipynb
: 1615072756:0;git add Generation.ipynb
: 1615072765:0;git add.
: 1615072767:0;git add .
: 1615072784:0;git commit -m "pass args to run_clm"
: 1615072788:0;git push
: 1615072814:0;e
: 1615073008:0;cd apex/experiment
: 1615073010:0;ls
: 1615073011:0;cd ..
: 1615073013:0;cd commonsense-discourse
: 1615073016:0;git log
: 1615073045:0;git reset --soft HEAD~1
: 1615073054:0;git log
: 1615073063:0;git status
: 1615073094:0;git add .
: 1615073113:0;git commit -m "revert back"
: 1615073118:0;git push
: 1615073148:0;git push origin HEAD
: 1615073172:0;git checkout -b revert
: 1615073177:0;git status
: 1615073183:0;git add .
: 1615073186:0;git commit -m "revert back"
: 1615073192:0;git push origin HEAD
: 1615073210:0;git checkout main
: 1615073224:0;git stash
: 1615073231:0;git checkout main
: 1615073244:0;git push -f origin HEAD
: 1615073318:0;git log
: 1615073613:0;nvidia-smi 
: 1615073621:0;git status
: 1615079418:0;nvidia-smi 
: 1615091549:0;ls
: 1615092850:0;nvidia-smi 
: 1615092868:0;git stash
: 1615092989:0;git pull
: 1615093301:0;rm training/nohup.out
: 1615093322:0;git pull
: 1615093351:0;rm training/run_clm_discovery.py '
: 1615093361:0;rm training/run_clm_discovery.py 
: 1615093368:0;git pull
: 1615093419:0;git status
: 1615093450:0;rm training/.nfs000000003fa281a0000000aa
: 1615093540:0;git pull
: 1615093927:0;git status
: 1615094023:0;git stash
: 1615094041:0;rm training/nohup.out
: 1615094065:0;git pull --force
: 1615094180:0;git reset --hard HEAD
: 1615094844:0;git pull
: 1615094968:0;git fetch --all
: 1615095006:0;git reset --hard origin/main
: 1615095068:0;git pull
: 1615095099:0;ls
: 1615095112:0;rm -r __pycache__
: 1615095125:0;cd training
: 1615095132:0;vim run_clm_discovery.py
: 1615095396:0;vim run_af.sh
: 1615095431:0;ls
: 1615095443:0;vim generate_ds.sh
: 1615095500:0;vim train_model.sh
: 1615095781:0;vim run_clm_discovery.py
: 1615095840:0;vim train_model.sh
: 1615095889:0;rm nohup.out && touch nohup.out
: 1615095904:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1615095932:0;vim run_clm_discovery.py
: 1615096019:0;rm nohup.out && touch nohup.out
: 1615096033:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1615096073:0;vim run_clm_discovery.py
: 1615096117:0;vim train_model.sh
: 1615096187:0;rm nohup.out && touch nohup.out
: 1615096200:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1615096229:0;vim run_clm_discovery.py
: 1615096306:0;rm nohup.out && touch nohup.out
: 1615096317:0;nohup /home/nlp/apex/commonsense-discourse/training/train_model.sh & tail -f nohup.out
: 1615131946:0;nvidia-smi 
: 1615132009:0;cd apex/commonsense-discourse/training
: 1615132033:0;vim nohup.out
: 1615132176:0;:q
: 1615132206:0;cd ../..
: 1615138885:0;cd experiment/ctrl_discovery_flipped_2
: 1615138888:0;ls
: 1615138894:0;rm -r checkpoint-*
: 1615139231:0;export PATH=/home/nlp/tools/bin:$PATH
: 1615139243:0;rm training_args.bin
: 1615139251:0;rm trainer_state.json
: 1615139254:0;rm train_results.txt
: 1615139260:0;rm eval_results_clm.txt
: 1615139264:0;git add .
: 1615139368:0;git commit -m "v1.1"
: 1615139379:0;git status
: 1615139392:0;git push
: 1615146432:0;cd ..
: 1615146437:0;cd commonsense-discourse/training
: 1615146439:0;vim nohup.out
: 1615146505:0;nvidia-smi 
: 1615168202:0;vim nohup.out
: 1615223295:0;nvidia-smi 
: 1615223303:0;cd apex/commonsense-discourse/training
: 1615223305:0;vim nohup.out
: 1615248285:0;cd ~
: 1615248288:0;cd transformers-importance-sampling
: 1615248293:0;vim get_heuristic_stats.py
: 1615248552:0;sh get_heuristic_stats.py
: 1615248558:0;vim get_heuristic_stats.py
: 1615248570:0;python3 get_heuristic_stats.py
: 1615248574:0;vim get_heuristic_stats.py
: 1615248589:0;python3 get_heuristic_stats.py
: 1615248733:0;vim get_heuristic_stats.py
: 1615248819:0;python3 get_heuristic_stats.py
: 1615250941:0;cd ..
: 1615250944:0;vim
: 1615251029:0;python3 get_heuristic_stats.py
: 1615251300:0;cd transformers-importance-sampling
: 1615251302:0;python3 get_heuristic_stats.py
: 1615269594:0;vim get_heuristic_stats.py
: 1615269625:0;python3 get_heuristic_stats.py
: 1615269691:0;vim get_heuristic_stats.py
: 1615269743:0;ls
: 1615269764:0;vim word_emb.py
: 1615269797:0;mv word_emb.py heuristics_get_examples.py
: 1615269806:0;python3 get_heuristic_stats.py
: 1615271963:0;vim get_heuristic_stats.py
: 1615271974:0;vim heuristics.sh
: 1615272004:0;rm nohup.out && touch nohup.out
: 1615272027:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1615272036:0;rm nohup.out && touch nohup.out
: 1615272041:0;vim heuristics.sh
: 1615272051:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1615272060:0;rm nohup.out && touch nohup.out
: 1615272065:0;vim heuristics.sh
: 1615272074:0;nohup /home/nlp/transformers-importance-sampling/heuristics.sh & tail -f nohup.out
: 1615300996:0;cd transformers-importance-sampling
: 1615301058:0;cp get_heuristic_stats.py train_heuristics.py
: 1615301064:0;vim train_heuristics.py
: 1615301105:0;ls ../experiments/aug
: 1615301108:0;vim train_heuristics.py
: 1615301143:0;rm train_heuristics.py
: 1615301146:0;vim get_heuristic_stats.py
: 1615301211:0;p3 get_heuristic_stats.py
: 1615301462:0;vim get_heuristic_stats.py
: 1615301676:0;p3 get_heuristic_stats.py
: 1615301679:0;vim get_heuristic_stats.py
: 1615301690:0;p3 get_heuristic_stats.py
: 1615301706:0;vim get_heuristic_stats.py
: 1615301746:0;p3 get_heuristic_stats.py
: 1615301867:0;vim get_heuristic_stats.py
: 1615301893:0;p3 get_heuristic_stats.py
: 1615301922:0;ls ~/data/glue
: 1615301929:0;ls ~/data/glue_data
: 1615301933:0;ls ~/data/glue_data/MNLI
: 1615301940:0;vim get_heuristic_stats.py
: 1615301957:0;p3 get_heuristic_stats.py
: 1615301978:0;vim get_heuristic_stats.py
: 1615302001:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615302022:0;vim get_heuristic_stats.py
: 1615302112:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615302194:0;vim get_heuristic_stats.py
: 1615302219:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615302240:0;vim get_heuristic_stats.py
: 1615302506:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615302530:0;ls ~/data/glue_data
: 1615302541:0;ls ~/data/glue_data/MNLI
: 1615302586:0;vim get_heuristic_stats.py
: 1615302677:0;lsp ../experiments/big_small/bert_base/epoch_4
: 1615302679:0;ls ../experiments/big_small/bert_base/epoch_4
: 1615302693:0;vim get_heuristic_stats.py
: 1615302796:0;ls ~/data/glue_data/MNLI
: 1615302824:0;vim get_heuristic_stats.py
: 1615302839:0;ls ~/data/glue_data/MNLI
: 1615302848:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615302897:0;vim get_heuristic_stats.py
: 1615302941:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615303087:0;vim get_heuristic_stats.py
: 1615303116:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615303493:0;vim get_heuristic_stats.py
: 1615303520:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615303549:0;vim get_heuristic_stats.py
: 1615303591:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615308981:0;vim get_heuristic_stats.py
: 1615309071:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615309084:0;vim get_heuristic_stats.py
: 1615309102:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615312303:0;vim get_heuristic_stats.py
: 1615312480:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615312502:0;vim get_heuristic_stats.py
: 1615312524:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615312655:0;vim get_heuristic_stats.py
: 1615312698:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615312711:0;vim get_heuristic_stats.py
: 1615312815:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615323255:0;vim get_heuristic_stats.py
: 1615323284:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615323368:0;vim get_heuristic_stats.py
: 1615323388:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615331129:0;vim get_heuristic_stats.py
: 1615331151:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615341292:0;cd hans
: 1615341294:0;ls
: 1615341334:0;vim ../get_heuristics_stats.py 
: 1615341342:0;vim ../get_heuristic_stats.py 
: 1615341390:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615342008:0;wget https://github.com/huggingface/transformers/archive/v3.3.0.zip
: 1615342016:0;unzip v3.3.0.zip
: 1615342262:0;mv transformers-3.3.0/src/transformers .
: 1615342265:0;ls
: 1615342272:0;rm -r transformers-3.3.0
: 1615342335:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615342396:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615342615:0;cd ~
: 1615342622:0;cd data/glue_data/hans
: 1615342636:0;python3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615342765:0;cd ..
: 1615342769:0;vim get_heuristic_stats.py
: 1615342776:0;cd ~/transformers-importance-sampling/
: 1615342778:0;vim get_heuristic_stats.py
: 1615342815:0;p3 get_heuristic_stats.py
: 1615342837:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615342873:0;vim get_heuristic_stats.py
: 1615342976:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615352588:0;ls
: 1615352593:0;vim augmented_dataset
: 1615352650:0;python3 ~/data/glue_data/hans/evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615352658:0;cd hans
: 1615352673:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615352824:0;cd ..
: 1615352827:0;python3 ~/data/glue_data/hans/evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615352852:0;cd ../data/glue_data/hans
: 1615352857:0;python3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615352913:0;cd ~
: 1615352919:0;ts cs
: 1615352928:0;cd transformers-importance-sampling
: 1615352938:0;vim get_heuristic_stats.py
: 1615352992:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615353000:0;tad cs
: 1615353028:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615356483:0;cd ~
: 1615356490:0;cd transformers-importance-sampling/hans
: 1615356507:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615357112:0;cd ~/data/glue_data/hans
: 1615357124:0;p3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615357174:0;cd ~
: 1615357179:0;cd transformers-importance-sampling/
: 1615357182:0;vim get_heuristic_stats.py
: 1615357225:0;ls
: 1615357239:0;vim get_heuristic_stats.py
: 1615357330:0;p3 get_heuristic_stats.py
: 1615357534:0;nvidia-smi 
: 1615357548:0;vim get_heuristic_stats.py
: 1615357591:0;nvidia-smi 
: 1615357595:0;p3 get_heuristic_stats.py
: 1615357633:0;nvidia-smi 
: 1615357637:0;vim get_heuristic_stats.py
: 1615357661:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615357697:0;nvidia-smi 
: 1615357782:21;vim get_heuristic_stats.py
: 1615357805:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615357845:0;nvidia-smi 
: 1615357855:28;vim get_heuristic_stats.py
: 1615357884:0;nvidia-smi 
: 1615357887:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615357939:0;e
: 1615392784:0;tl
: 1615392787:0;tad cs
: 1615392796:0;cd hans
: 1615392812:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615393049:0;cd ~
: 1615393056:0;cd data/glue_data/hans
: 1615393059:0;p3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615393084:0;cd ~/transformers-importance-sampling/
: 1615393092:0;vim get_heuristic_stats.py
: 1615393138:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615395279:0;cd hans
: 1615395284:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615395441:0;cd ~
: 1615395443:0;cd data/glue_data/hans
: 1615395445:0;p3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615395620:0;cd ~/transformers-importance-sampling/
: 1615395629:0;vim get_heuristic_stats.py
: 1615395773:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615397098:0;cd  hans
: 1615397104:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615397311:0;cd ~/data/glue_data/hans
: 1615397318:0;p3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615397333:0;cd ~/transformers-importance-sampling/
: 1615397335:0;vim get_heuristic_stats.py
: 1615397503:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615397531:0;vim get_heuristic_stats.py
: 1615397555:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1615399524:0;cd hans
: 1615399530:0;nvidia-smi 
: 1615399539:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased
: 1615399713:0;cd ~/data/glue_data/hans
: 1615399715:0;p3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt
: 1615399749:0;cd ~/transformers-importance-sampling/
: 1615399752:0;vim get_heuristic_stats.py
: 1615399787:0;vim check_hans.sh
: 1615399826:0;echo "CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/aug --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/aug --tokenizer_name bert-base-uncased" >> check_hans.sh
: 1615399830:0;vim check_hans.sh
: 1615399898:0;echo "CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py" >>check_hans.sh
: 1615399900:0;vim check_hans.sh
: 1615399958:0;echo "p3 evaluate_heur_output.py ~/experiments/aug/hans_predictions.txt" >>check_hans.sh
: 1615399960:0;vim check_hans.sh
: 1615399986:0;sh check_hans.sh
: 1615399992:0;vim check_hans.sh
: 1615400012:0;sh check_hans.sh
: 1615401259:0;tad cs
: 1615403688:0;vim get_heuristic_stats.py
: 1615403925:0;sh check_hans.sh
: 1615404561:0;vim get_heuristic_stats.py
: 1615404573:0;sh check_hans.sh
: 1615404588:0;vim get_heuristic_stats.py
: 1615404612:0;sh check_hans.sh
: 1615408840:0;vim get_heuristic_stats.py
: 1615408932:0;sh check_hans.sh
: 1615413567:0;vim get_heuristic_stats.py
: 1615442429:0;nvidia-smi 
: 1615442433:0;cd ~
: 1615442438:0;cd apex/commonsense-discourse/training
: 1615442440:0;vim nohup.out
: 1615442451:0;cd ..
: 1615442458:0;ls
: 1615442469:0;cd experiment/ctrl_discovery_1
: 1615442471:0;ls
: 1615442482:0;rm -r checkpoint-*
: 1615442852:0;nvidia-smi 
: 1615442857:0;cd ~
: 1615565757:0;nvidia-smi 
: 1615565780:0;cd apex/commonsense-discourse/training
: 1615565783:0;vim nohup.out
: 1615565799:0;cd ..
: 1615565804:0;cd experiment/ctrl_discovery_1
: 1615565805:0;ls
: 1615565808:0;rm -r checkpoint-*
: 1615595165:0;nvidia-smi 
: 1615595182:0;cd ..
: 1615598256:0;ls
: 1615598263:0;cd ctrl_discovery_1
: 1615598264:0;ls
: 1615598270:0;rm -r checkpoint-*
: 1615598337:0;cd ~
: 1615598339:0;cd transformers-importance-sampling/
: 1615598480:0;vim get_heuristic_stats.py
: 1615600695:0;nvidia-smi 
: 1615673795:0;ls
: 1615673831:0;ts jupyter
: 1615673835:0;jupyter notebook --no-browser --port=8888
: 1615829296:0;nvidia-smi 
: 1615830060:0;cd apex/commonsense-discourse/training
: 1615830062:0;ls
: 1615830072:0;vim train_model.sh
: 1615830128:0;vim run_clm_discovery.py
: 1615830153:0;tl
: 1615830157:0;tad cs
: 1615830164:0;cd //
: 1615830167:0;cd ~
: 1615830170:0;cd apex/commonsense-discourse/training
: 1615830176:0;vim train_model.sh
: 1615830426:0;vim run_clm_discovery.py
: 1615830445:0;sh train_model.sh
: 1615830458:0;vim train_model.sh
: 1615830489:0;sh train_model.sh
: 1615945730:0;tl
: 1615945732:0;tad cs
: 1615945758:0;ls apex/experiment/ctrl_discovery_4
: 1616090372:0;tl
: 1616090374:0;tad cs
: 1616185421:0;nvidia-smi 
: 1616185428:0;cd apex/experiment
: 1616185429:0;ls
: 1616185436:0;cd ctrl_discovery_4
: 1616185441:0;git lfs install
: 1616185445:0;export PATH=/home/nlp/tools/bin:$PATH
: 1616185448:0;git lfs install
: 1616185451:0;transformers-cli lfs-enable-largefiles .
: 1616185461:0;ls
: 1616185506:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_4
: 1616185521:0;ls
: 1616185526:0;rm eval_results_clm.txt
: 1616185534:0;rm trainer_state.json
: 1616185542:0;rm training_args.bin
: 1616185543:0;ls
: 1616185548:0;rm train_results.txt
: 1616185551:0;ls
: 1616185555:0;rm -r checkpoint-140000
: 1616185559:0;ls
: 1616185568:0;mv * ctrl_discovery_4
: 1616185570:0;ls
: 1616185572:0;cd ..
: 1616185587:0;mv ctrl_discovery_4 ctrl_discovery_4_k
: 1616185594:0;mv ctrl_discovery_4_k/ctrl_discovery_4 .
: 1616185596:0;ls
: 1616185603:0;rm -r ctrl_discovery_4_k
: 1616185607:0;cd ctrl_discovery_4
: 1616185610:0;ls
: 1616185612:0;transformers-cli lfs-enable-largefiles .
: 1616185619:0;git lfs install
: 1616185622:0;git add .
: 1616185730:0;git commit -m "v1.0"
: 1616185734:0;git push
: 1616186074:0;cd apex/commonsense-discourse/training
: 1616186077:0;vim train_model.sh
: 1616186105:0;tl
: 1616186107:0;tad cs
: 1616186122:0;vim train_model.sh
: 1616186175:0;sh train_model.sh
: 1616186342:0;nvidia-smi 
: 1616186918:0;tad cs
: 1616248663:0;tl
: 1616248666:0;tad cs
: 1616277044:0;cd apex/commonsense-discourse/training
: 1616277051:0;vim run_clm_discovery.py
: 1616277102:0;tad cs
: 1616347924:0;cd apex/experiment
: 1616347930:0;cd ctrl_discovery_2
: 1616347931:0;ls
: 1616347939:0;vim vocab.json
: 1616365118:0;tl
: 1616365120:0;tad cs
: 1616467642:0;ls
: 1616467645:0;cd ..
: 1616467655:0;ls ../experiment
: 1616467668:0;cd training
: 1616467674:0;vim generate_ds.sh
: 1616467684:0;vim train_model.sh
: 1616467784:0;sh train_model.sh
: 1616467813:0;cd apex/experiment
: 1616467813:0;ls
: 1616467820:0;cd ctrl_discovery_5
: 1616467821:0;ls
: 1616467828:0;rm -r checkpoint-80000
: 1616467862:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_5
: 1616467870:0;ls
: 1616467874:0;mv * ctrl_discovery_5
: 1616467877:0;ls
: 1616467881:0;cd ctrl_discovery_5
: 1616467881:0;ls
: 1616467887:0;rm eval_results_clm.txt
: 1616467894:0;rm train_results.txt
: 1616467903:0;rm trainer_state.json
: 1616467909:0;rm training_args.bin
: 1616467914:0;expport PATH=/home/nlp/tools/bin:$PATH
: 1616467920:0;export PATH=/home/nlp/tools/bin:$PATH
: 1616467926:0;git lfs install
: 1616467933:0;transformers-cli lfs-enable-largefiles .
: 1616467940:0;tad cs
: 1616467946:0;git add .
: 1616468041:0;git commit -m "v1.0"
: 1616468045:0;git push
: 1616468824:0;tad cs
: 1616727315:0;vim train_model.sh
: 1616727362:0;sh train_model.sh
: 1616988167:0;tad cs
: 1616988177:0;cd ..
: 1616988195:0;ls ../experiment
: 1616988232:0;cd training
: 1616988246:0;vim train_model.sh
: 1616988281:0;ls ../../experiment
: 1616988297:0;vim train_model.sh
: 1616988352:0;sh train_model.sh
: 1617129335:0;tad cs
: 1617129357:0;cd apex/experiment
: 1617129357:0;ls
: 1617129378:0;cd ctrl_discovery_flipped_3
: 1617129438:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_flipped_3
: 1617129446:0;ls
: 1617129456:0;rm *.txt
: 1617129459:0;ls
: 1617129466:0;cd ..
: 1617129527:0;cp ctrl_discovery_flipped_2/merges.txt ctrl_discovery_flipped_3/
: 1617129530:0;cd ctrl_discovery_flipped_3
: 1617129531:0;ls
: 1617129536:0;rm -r checkpoint-80000
: 1617129548:0;rm trainer_state.json
: 1617129549:0;ls
: 1617129556:0;mv * ctrl_discovery_flipped_3
: 1617129558:0;ls
: 1617129566:0;cd ctrl_discovery_flipped_3
: 1617129569:0;transformers-cli lfs-enable-largefiles .
: 1617129576:0;git lfs install
: 1617129577:0;export PATH=/home/nlp/tools/bin:$PATH
: 1617129579:0;git lfs install
: 1617129582:0;git add .
: 1617129862:0;git commit -m "v1.0"
: 1617129867:0;git push
: 1617131422:0;cd ..
: 1617131431:0;cd ctrl_discovery_flipped_4
: 1617131519:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_flipped_4
: 1617131526:0;ls
: 1617131534:0;rm -r checkpoint-80000
: 1617131542:0;rm eval_results_clm.txt
: 1617131556:0;rm train_results.txt
: 1617131558:0;ls
: 1617131563:0;rm trainer_state.json
: 1617131565:0;ls
: 1617131569:0;mv * ctrl_discovery_flipped_4
: 1617131572:0;cd ctrl_discovery_flipped_4
: 1617131577:0;git lfs install
: 1617131580:0;transformers-cli lfs-enable-largefiles .
: 1617131585:0;git add .
: 1617131689:0;git commit -m "v1.0"
: 1617131693:0;git push
: 1617205761:0;cd apex
: 1617205762:0;ls
: 1617205767:0;wget https://github.com/prajjwal1/commonsense-discourse/blob/main/data/gen_train_0_10.json\?raw\=true
: 1617205770:0;ls
: 1617205783:0;wget https://raw.githubusercontent.com/prajjwal1/commonsense-discourse/main/data/gen_train_0_10.json\?token\=AF4L3A7TLK5OZG5PKM3BL3LANXKI6
: 1617205786:0;ls
: 1617205795:0;mv 'gen_train_0_10.json?token=AF4L3A7TLK5OZG5PKM3BL3LANXKI6' gen_train.json
: 1617205816:0;wget https://raw.githubusercontent.com/prajjwal1/commonsense-discourse/main/data/gen_valid.json\?token\=AF4L3A62UCQYYWNX5MTTUK3ANXKLA
: 1617205820:0;ls
: 1617205823:0;mv 
: 1617205835:0;mv 'gen_valid.json?token=AF4L3A62UCQYYWNX5MTTUK3ANXKLA' gen_valid.json
: 1617205886:0;wget https://raw.githubusercontent.com/prajjwal1/commonsense-discourse/main/data/raw_train.json\?token\=AF4L3A3MXJNYIT5DUZQZPP3ANXKPG
: 1617205893:0;ls
: 1617205894:0;mv 
: 1617205904:0;mv 'raw_train.json?token=AF4L3A3MXJNYIT5DUZQZPP3ANXKPG' raw_train.json
: 1617205942:0;wget https://raw.githubusercontent.com/prajjwal1/commonsense-discourse/main/data/raw_valid.json\?token\=AF4L3AZZMHWAXH2FU26O4JDANXKRU
: 1617205954:0;mv 'raw_valid.json?token=AF4L3AZZMHWAXH2FU26O4JDANXKRU' raw_valid.json
: 1617304274:0;tad cs
: 1617304289:0;ls
: 1617304307:0;cp run_clm_discovery.py run_gpt.py
: 1617304312:0;vim run_gpt.py
: 1617304455:0;vim train_model.sh
: 1617304554:0;sh train_model.sh
: 1617305421:0;nvidia-smi 
: 1617305426:0;vim train_model.sh
: 1617305458:0;sh train_model.sh
: 1617326345:0;cd apex/commonsense-discourse/training
: 1617326347:0;vim train_model.sh
: 1617556334:0;tad cs
: 1617556790:0;ls apex/experiment/ctrl_discovery_4
: 1617556795:0;ls apex/experiment/ctrl_discovery_5
: 1617556799:0;ls apex/experiment/ctrl_discovery_5/ctrl_discovery_5
: 1617556865:0;ls apex/experiment/ctrl_discovery_5/ctrl_discovery_6
: 1617556879:0;tad cs
: 1617557712:0;nvidia-smi 
: 1617557720:0;tad cs
: 1617560048:0;vim train_model.sh
: 1617560096:0;sh train_model.sh
: 1617560135:0;vim train_model.sh
: 1617560152:0;sh train_model.sh
: 1617562471:0;vim train_model.sh
: 1617562501:0;ls
: 1617562505:0;vim train_model.sh
: 1617562523:0;sh train_model.sh
: 1617562999:0;vim train_model.sh
: 1617563014:0;sh train_model.sh
: 1617565055:0;vim run_clm_discovery.py
: 1617565214:0;vim train_model.sh
: 1617565249:0;sh train_model.sh
: 1617570436:0;vim train_model.sh
: 1617570452:0;ls ../../experiment
: 1617570654:0;ls ../../experiment/ctrl_discovery_6
: 1617570666:0;vim ../../experiment/ctrl_discovery_6
: 1617570683:0;vim train_model.sh
: 1617570805:0;sh train_model.sh
: 1617570813:0;vim train_model.sh
: 1617570824:0;sh train_model.sh
: 1617572571:0;vim train_model.sh
: 1617572585:0;sh train_model.sh
: 1617639401:0;cd transformers-importance-sampling/
: 1617639404:0;vim get_heuristic_stats.py
: 1617639411:0;ls
: 1617639416:0;vim heuristics_get_examples.py
: 1617639683:0;p3 heuristics_get_examples.py
: 1617639877:0;cd transformers-importance-sampling/
: 1617639879:0;vim heuristics_get_examples.py
: 1617642231:0;p3 heuristics_get_examples.py
: 1617642273:0;vim heuristics_get_examples.py
: 1617642330:0;nvidia-smi 
: 1617642350:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617642658:0;vim heuristics_get_examples.py
: 1617643122:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617643126:0;vim heuristics_get_examples.py
: 1617643142:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617643280:0;vim heuristics_get_examples.py
: 1617643297:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617643324:0;vim heuristics_get_examples.py
: 1617643394:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617646191:0;vim heuristics_get_examples.py
: 1617647097:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617654720:0;vim heuristics_get_examples.py
: 1617654775:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617725199:0;cd transformers-importance-sampling/
: 1617725201:0;ls
: 1617725211:0;rm word_emb_1.txt
: 1617725221:0;vim heuristics_get_examples.py
: 1617725229:0;p3 heuristics_get_examples.py
: 1617725369:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617727252:0;vim heuristics_get_examples.py
: 1617727273:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617729454:0;vim heuristics_get_examples.py
: 1617729520:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617729921:0;vim heuristics_get_examples.py
: 1617730010:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617730464:0;vim heuristics_get_examples.py
: 1617730491:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617732141:0;vim heuristics_get_examples.py
: 1617732170:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617741829:0;vim heuristics_get_examples.py
: 1617741872:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617742161:0;vim get_heuristic_stats.py
: 1617742315:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617742345:0;nvidia-smi 
: 1617742353:0;vim get_heuristic_stats.py
: 1617742376:0;nvidia-smi 
: 1617742378:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617742403:0;nvidia-smi 
: 1617742408:0;vim get_heuristic_stats.py
: 1617742432:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617742455:0;vim get_heuristic_stats.py
: 1617742473:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617742513:0;vim heuristics_get_examples.py
: 1617742539:0;vim get_heuristic_stats.py
: 1617742579:0;vim heuristics_get_examples.py
: 1617742586:0;vim get_heuristic_stats.py
: 1617742708:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617742768:0;vim get_heuristic_stats.py
: 1617742780:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617742901:0;vim get_heuristic_stats.py
: 1617742983:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617743016:0;vim get_heuristic_stats.py
: 1617743028:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617743042:0;vim get_heuristic_stats.py
: 1617743100:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617743344:0;vim get_heuristic_stats.py
: 1617743366:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617743541:0;vim get_heuristic_stats.py
: 1617743563:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617743804:0;vim get_heuristic_stats.py
: 1617743826:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617744067:0;vim get_heuristic_stats.py
: 1617744088:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617744339:0;vim get_heuristic_stats.py
: 1617744388:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617746573:0;vim get_heuristic_stats.py
: 1617746593:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617746866:0;vim get_heuristic_stats.py
: 1617746917:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1617748073:0;vim heuristics_get_examples.py
: 1617748115:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617748590:0;vim heuristics_get_examples.py
: 1617748627:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617749844:0;vim heuristics_get_examples.py
: 1617749857:0;CUDA_VISIBLE_DEVICES=1 p3 heuristics_get_examples.py
: 1617821743:0;tad cs
: 1617821767:0;cd apex/commonsense-discourse/
: 1617821770:0;python3
: 1617821957:0;ls ../../experiments
: 1617821963:0;ls ../experiment/
: 1617821967:0;python3
: 1618023210:0;nvidia-smi 
: 1618023291:0;cd transformers-importance-sampling/
: 1618023291:0;ls
: 1618023352:0;vim get_heuristic_stats.py
: 1618024912:0;p3 get_heuristic_stats.py
: 1618025049:0;cd transformers-importance-sampling/
: 1618025051:0;vim get_heuristic_stats.py
: 1618025094:0;p3 get_heuristic_stats.py
: 1618025280:0;vim get_heuristic_stats.py
: 1618025295:0;p3 get_heuristic_stats.py
: 1618025478:0;vim get_heuristic_stats.py
: 1618025516:0;p3 get_heuristic_stats.py
: 1618025767:0;vim get_heuristic_stats.py
: 1618025901:0;p3 get_heuristic_stats.py
: 1618026185:0;vim get_heuristic_stats.py
: 1618026598:0;p3 get_heuristic_stats.py
: 1618026826:0;vim get_heuristic_stats.py
: 1618026863:0;ls
: 1618026880:0;cp get_heuristic_stats.py get_heuristic_stat_2.py
: 1618026887:0;vim get_heuristic_stat_2.py
: 1618026952:0;p3 get_heuristic_stats.py
: 1618027147:0;p3 get_heuristic_stat_2.py
: 1618027856:0;nvidia-smi 
: 1618027863:0;p3 get_heuristic_stat_2.py
: 1618027877:0;vim get_heuristic_stat_2.py
: 1618027908:0;p3 get_heuristic_stat_2.py
: 1618027929:0;vim get_heuristic_stats.py
: 1618027958:0;p3 get_heuristic_stat_2.py
: 1618027964:0;vim get_heuristic_stats.py
: 1618027970:0;vim get_heuristic_stat_2.py
: 1618027978:0;vim get_heuristic_stats.py
: 1618027982:0;p3 get_heuristic_stat_2.py
: 1618028153:0;vim get_heuristic_stat_2.py
: 1618028587:0;p3 get_heuristic_stat_2.py
: 1618028705:0;vim get_heuristic_stat_2.py
: 1618028729:0;ls ../cartography/filtered/roberta_large_hard/cartography_confidence_0.01
: 1618028740:0;ls ../cartography/filtered/roberta_large_hard_mnli
: 1618028756:0;ls ../cartography/filtered/bert_base_hard_mnli
: 1618028766:0;ls ../cartography/filtered/bert_base_easy_mnli
: 1618028777:0;vim get_heuristic_stat_2.py
: 1618028825:0;p3 get_heuristic_stat_2.py
: 1618028930:0;vim get_heuristic_stat_2.py
: 1618028957:0;ls ../cartography/filtered/bert_base_easy_mnli
: 1618028965:0;p3 get_heuristic_stat_2.py
: 1618029054:0;vim get_heuristic_stat_2.py
: 1618029072:0;p3 get_heuristic_stat_2.py
: 1618029150:0;vim get_heuristic_stat_2.py
: 1618029182:0;p3 get_heuristic_stat_2.py
: 1618029266:0;vim get_heuristic_stat_2.py
: 1618029313:0;p3 get_heuristic_stat_2.py
: 1618029422:0;vim get_heuristic_stat_2.py
: 1618029437:0;p3 get_heuristic_stat_2.py
: 1618029601:0;vim get_heuristic_stat_2.py
: 1618029618:0;p3 get_heuristic_stat_2.py
: 1618029803:0;vim get_heuristic_stat_2.py
: 1618029825:0;p3 get_heuristic_stat_2.py
: 1618030000:0;vim get_heuristic_stat_2.py
: 1618030027:0;p3 get_heuristic_stat_2.py
: 1618030227:0;vim get_heuristic_stat_2.py
: 1618030245:0;p3 get_heuristic_stat_2.py
: 1618030499:0;vim get_heuristic_stat_2.py
: 1618030517:0;p3 get_heuristic_stat_2.py
: 1618030689:0;vim get_heuristic_stat_2.py
: 1618030704:0;p3 get_heuristic_stat_2.py
: 1618030878:0;vim get_heuristic_stat_2.py
: 1618030907:0;p3 get_heuristic_stat_2.py
: 1618031088:0;vim get_heuristic_stat_2.py
: 1618031112:0;p3 get_heuristic_stat_2.py
: 1618031295:0;vim get_heuristic_stat_2.py
: 1618031323:0;mv get_heuristics_stat_2.py get_heuristic_stats.py
: 1618031331:0;mv get_heuristic_stat_2.py get_heuristic_stats.py
: 1618031339:0;p3 get_heuristic_stats.py
: 1618031520:0;vim get_heuristic_stat_2.py
: 1618031528:0;vim get_heuristic_stats.py
: 1618031547:0;p3 get_heuristic_stats.py
: 1618031712:0;vim get_heuristic_stats.py
: 1618031746:0;p3 get_heuristic_stats.py
: 1618031933:0;vim get_heuristic_stats.py
: 1618031951:0;p3 get_heuristic_stats.py
: 1618032248:0;vim get_heuristic_stats.py
: 1618032315:0;p3 get_heuristic_stats.py
: 1618032499:0;vim get_heuristic_stats.py
: 1618032532:0;p3 get_heuristic_stats.py
: 1618032538:0;vim get_heuristic_stats.py
: 1618032558:0;p3 get_heuristic_stats.py
: 1618032622:0;vim get_heuristic_stats.py
: 1618032660:0;p3 get_heuristic_stats.py
: 1618032991:0;vim get_heuristic_stats.py
: 1618033008:0;p3 get_heuristic_stats.py
: 1618033194:0;vim get_heuristic_stats.py
: 1618033223:0;p3 get_heuristic_stats.py
: 1618033598:0;vim get_heuristic_stats.py
: 1618033629:0;p3 get_heuristic_stats.py
: 1618033834:0;vim get_heuristic_stats.py
: 1618033850:0;p3 get_heuristic_stats.py
: 1618034026:0;vim get_heuristic_stats.py
: 1618034070:0;p3 get_heuristic_stats.py
: 1618034242:0;vim get_heuristic_stats.py
: 1618034270:0;p3 get_heuristic_stats.py
: 1618034521:0;vim get_heuristic_stats.py
: 1618034537:0;p3 get_heuristic_stats.py
: 1618034719:0;vim get_heuristic_stats.py
: 1618034751:0;p3 get_heuristic_stats.py
: 1618034920:0;vim get_heuristic_stats.py
: 1618034946:0;p3 get_heuristic_stats.py
: 1618035116:0;vim get_heuristic_stats.py
: 1618035132:0;p3 get_heuristic_stats.py
: 1618035334:0;vim get_heuristic_stats.py
: 1618035402:0;p3 get_heuristic_stats.py
: 1618035517:0;vim get_heuristic_stats.py
: 1618035567:0;p3 get_heuristic_stats.py
: 1618035862:0;vim get_heuristic_stats.py
: 1618061088:0;cd transformers-importance-sampling/
: 1618061091:0;vim get_heuristic_stats.py
: 1618061460:0;p3 get_heuristic_stats.py
: 1618061740:0;vim get_heuristic_stats.py
: 1618061766:0;p3 get_heuristic_stats.py
: 1618063227:0;vim get_heuristic_stats.py
: 1618063249:0;vim run_glue.sh
: 1618063254:0;vim run_glue.py
: 1618063306:0;vim run_glue.sh
: 1618063380:0;vim get_heuristic_stats.py
: 1618063954:0;p3 get_heuristic_stats.py
: 1618063972:0;vim get_heuristic_stats.py
: 1618063996:0;p3 get_heuristic_stats.py
: 1618064134:0;vim get_heuristic_stats.py
: 1618064216:0;p3 get_heuristic_stats.py
: 1618064234:0;ls data
: 1618064401:0;vim get_heuristic_stats.py
: 1618064451:0;ls data
: 1618064454:0;p3 get_heuristic_stats.py
: 1618064471:0;ls data
: 1618064475:0;vim get_heuristic_stats.py
: 1618064558:0;ls data
: 1618064561:0;p3 get_heuristic_stats.py
: 1618064635:0;vim get_heuristic_stats.py
: 1618064672:0;p3 get_heuristic_stats.py
: 1618064718:0;vim get_heuristic_stats.py
: 1618064921:0;p3 get_heuristic_stats.py
: 1618064959:0;vim get_heuristic_stats.py
: 1618065015:0;p3 get_heuristic_stats.py
: 1618069487:0;vim get_heuristic_stats.py
: 1618069542:0;p3 get_heuristic_stats.py
: 1618069595:0;vim get_heuristic_stats.py
: 1618069606:0;p3 get_heuristic_stats.py
: 1618069627:0;vim get_heuristic_stats.py
: 1618069653:0;p3 get_heuristic_stats.py
: 1618069823:0;vim get_heuristic_stats.py
: 1618069839:0;vim heuristics_get_examples.py
: 1618069881:0;p3 get_heuristic_stats.py
: 1618069896:0;p3 heuristics_get_examples.py
: 1618070175:0;vim heuristics_get_examples.py
: 1618070199:0;p3 heuristics_get_examples.py
: 1618070524:0;vim heuristics_get_examples.py
: 1618070536:0;p3 heuristics_get_examples.py
: 1618071076:0;vim get_heuristic_stats.py
: 1618071306:0;p3 get_heuristic_stats.py
: 1618071656:0;vim get_heuristic_stats.py
: 1618071674:0;p3 get_heuristic_stats.py
: 1618071898:0;vim get_heuristic_stats.py
: 1618071920:0;p3 get_heuristic_stats.py
: 1618072481:0;vim get_heuristic_stats.py
: 1618072501:0;p3 get_heuristic_stats.py
: 1618072681:0;vim get_heuristic_stats.py
: 1618072717:0;p3 get_heuristic_stats.py
: 1618072897:0;vim get_heuristic_stats.py
: 1618072923:0;p3 get_heuristic_stats.py
: 1618073237:0;vim get_heuristic_stats.py
: 1618073262:0;p3 get_heuristic_stats.py
: 1618073438:0;vim get_heuristic_stats.py
: 1618073471:0;p3 get_heuristic_stats.py
: 1618073488:0;vim get_heuristic_stats.py
: 1618073513:0;p3 get_heuristic_stats.py
: 1618073701:0;vim get_heuristic_stats.py
: 1618073726:0;p3 get_heuristic_stats.py
: 1618073728:0;vim get_heuristic_stats.py
: 1618073765:0;p3 get_heuristic_stats.py
: 1618074006:0;vim get_heuristic_stats.py
: 1618074037:0;p3 get_heuristic_stats.py
: 1618074218:0;vim get_heuristic_stats.py
: 1618074247:0;p3 get_heuristic_stats.py
: 1618074447:0;vim get_heuristic_stats.py
: 1618074468:0;p3 get_heuristic_stats.py
: 1618074714:0;vim get_heuristic_stats.py
: 1618074736:0;p3 get_heuristic_stats.py
: 1618075075:0;vim get_heuristic_stats.py
: 1618075106:0;p3 get_heuristic_stats.py
: 1618075310:0;vim get_heuristic_stats.py
: 1618075329:0;p3 get_heuristic_stats.py
: 1618075584:0;vim get_heuristic_stats.py
: 1618075628:0;p3 get_heuristic_stats.py
: 1618075876:0;vim get_heuristic_stats.py
: 1618075893:0;p3 get_heuristic_stats.py
: 1618076098:0;vim get_heuristic_stats.py
: 1618076154:0;p3 get_heuristic_stats.py
: 1618076357:0;vim get_heuristic_stats.py
: 1618076387:0;p3 get_heuristic_stats.py
: 1618076585:0;vim get_heuristic_stats.py
: 1618076605:0;p3 get_heuristic_stats.py
: 1618076832:0;vim get_heuristic_stats.py
: 1618076849:0;p3 get_heuristic_stats.py
: 1618077108:0;vim get_heuristic_stats.py
: 1618077124:0;p3 get_heuristic_stats.py
: 1618077319:0;vim get_heuristic_stats.py
: 1618077397:0;p3 get_heuristic_stats.py
: 1618077633:0;vim get_heuristic_stats.py
: 1618077657:0;p3 get_heuristic_stats.py
: 1618077989:0;vim get_heuristic_stats.py
: 1618078008:0;p3 get_heuristic_stats.py
: 1618078233:0;vim get_heuristic_stats.py
: 1618078327:0;p3 get_heuristic_stats.py
: 1618078541:0;vim get_heuristic_stats.py
: 1618078585:0;p3 get_heuristic_stats.py
: 1618078823:0;vim get_heuristic_stats.py
: 1618078845:0;p3 get_heuristic_stats.py
: 1618079630:0;vim get_heuristic_stats.py
: 1618079948:0;vim heuristics_get_examples.py
: 1618080205:0;p3 get_heuristic_stats.py
: 1618080956:0;vim heuristics_get_examples.py
: 1618080995:0;p3 heuristics_get_examples.py
: 1618081852:0;vim heuristics_get_examples.py
: 1618081878:0;p3 heuristics_get_examples.py
: 1618083026:0;vim get_heuristic_stats.py
: 1618083068:0;p3 get_heuristic_stats.py
: 1618091532:0;vim heuristics_get_examples.py
: 1618091571:0;p3 heuristics_get_examples.py
: 1618098846:0;cd ..
: 1618098852:0;cd apex/experiment
: 1618098854:0;ls
: 1618098943:0;cd ctrl_discovery_6
: 1618098944:0;ls
: 1618098950:0;rm -r checkpoint-80000
: 1618098975:0;ls
: 1618098983:0;vimm eval
: 1618098986:0;vim eval_results_clm.txt
: 1618098994:0;git clone git clone https://huggingface.co/prajjwal1/ctrl_discovery_6
: 1618099003:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_6
: 1618099025:0;ls
: 1618099029:0;rm eval_results_clm.txt
: 1618099035:0;rm trainer_state.json
: 1618099044:0;rm train*
: 1618099046:0;ls
: 1618099050:0;mv * ctrl_discovery_6
: 1618099052:0;ls
: 1618099056:0;cd ctrl_discovery_6
: 1618099060:0;export PATH=/home/nlp/tools/bin:$PATH
: 1618099064:0;git lfs install
: 1618099068:0;transformers-cli lfs-enable-largefiles .
: 1618099074:0;git add .
: 1618116083:0;git commit -m "v1.0"
: 1618116086:0;git push
: 1618118350:0;cd ..
: 1618160927:0;cd transformers-importance-sampling/
: 1618160929:0;vim get_heuristic_stats.py
: 1618161028:0;p3 get_heuristic_stats.py
: 1618161238:0;vim get_heuristic_stats.py
: 1618161263:0;p3 get_heuristic_stats.py
: 1618161450:0;vim get_heuristic_stats.py
: 1618161470:0;p3 get_heuristic_stats.py
: 1618161650:0;vim get_heuristic_stats.py
: 1618161702:0;p3 get_heuristic_stats.py
: 1618161896:0;vim get_heuristic_stats.py
: 1618161934:0;p3 get_heuristic_stats.py
: 1618162098:0;vim get_heuristic_stats.py
: 1618162125:0;p3 get_heuristic_stats.py
: 1618162315:0;vim get_heuristic_stats.py
: 1618162356:0;p3 get_heuristic_stats.py
: 1618162412:0;vim get_heuristic_stats.py
: 1618162462:0;p3 get_heuristic_stats.py
: 1618162781:0;vim get_heuristic_stats.py
: 1618162814:0;p3 get_heuristic_stats.py
: 1618163068:0;vim get_heuristic_stats.py
: 1618163084:0;p3 get_heuristic_stats.py
: 1618163626:0;vim get_heuristic_stats.py
: 1618163640:0;p3 get_heuristic_stats.py
: 1618164332:0;vim get_heuristic_stats.py
: 1618164346:0;p3 get_heuristic_stats.py
: 1618164597:0;vim get_heuristic_stats.py
: 1618164613:0;p3 get_heuristic_stats.py
: 1618165452:0;cd ../apex/experiment
: 1618165453:0;ls
: 1618165464:0;cd ctrl_discovery_flipped_5
: 1618165465:0;ls
: 1618165472:0;rm -r checkpoint-80000
: 1618165477:0;ls
: 1618165482:0;rm training_args.bin
: 1618165487:0;rm train*
: 1618165489:0;ls
: 1618165554:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_flipped_5
: 1618165576:0;mv * ctrl_discovery_flipped_5
: 1618165578:0;ls
: 1618165581:0;cd ctrl_discovery_flipped_5
: 1618165583:0;export PATH=/home/nlp/tools/bin:$PATH
: 1618165585:0;git lfs install
: 1618165587:0;transformers-cli lfs-enable-largefiles .
: 1618165594:0;git add .
: 1618165710:0;git commit -m "v1.0"
: 1618165720:0;rm eval_results_clm.txt
: 1618165724:0;git add .
: 1618165727:0;git commit -m "v1.0"
: 1618165732:0;git psuh
: 1618165736:0;git push
: 1618177277:0;cd ..
: 1618177285:0;cd ~
: 1618177287:0;cd transformers-importance-sampling/
: 1618177288:0;ls
: 1618177297:0;vim maml_few_shot.py
: 1618177313:0;vim core/meta.py
: 1618177372:0;vim heuristics_get_examples.py
: 1618179020:0;p3 heuristics_get_examples.py
: 1618179024:0;vim heuristics_get_examples.py
: 1618179038:0;p3 heuristics_get_examples.py
: 1618179236:0;cd transformers-importance-sampling/
: 1618179240:0;mkdir insert
: 1618179303:0;vim heuristics_get_examples.py
: 1618179362:0;mkdir insert
: 1618179369:0;p3 heuristics_get_examples.py
: 1618179605:0;mkdir insert
: 1618179610:0;vim heuristics_get_examples.py
: 1618179636:0;mkdir insert
: 1618179639:0;p3 heuristics_get_examples.py
: 1618179899:0;vim heuristics_get_examples.py
: 1618180020:0;p3 heuristics_get_examples.py
: 1618180258:0;vim heuristics_get_examples.py
: 1618180319:0;p3 heuristics_get_examples.py
: 1618180561:0;vim heuristics_get_examples.py
: 1618180763:0;p3 heuristics_get_examples.py
: 1618181000:0;vim heuristics_get_examples.py
: 1618181082:0;p3 heuristics_get_examples.py
: 1618184527:0;vim heuristics_get_examples.py
: 1618184543:0;p3 heuristics_get_examples.py
: 1618185403:0;ls
: 1618185407:0;cd insert
: 1618185409:0;ls
: 1618185412:0;vim c_e.json
: 1618185425:0;cd ..
: 1618185430:0;vim heuristics_get_examples.py
: 1618185475:0;cd ..
: 1618185477:0;cd transformers-importance-sampling/
: 1618185483:0;p3 heuristics_get_examples.py
: 1618186054:0;cd insert
: 1618186054:0;ls
: 1618186057:0;vim c_e.json
: 1618186188:0;tl
: 1618186195:0;ts jupyter
: 1618186201:0;jupyter notebook --no-browser --port=8888
: 1618186206:0;cd ~
: 1618186208:0;jupyter notebook --no-browser --port=8888
: 1618186375:0;vim c_e.json
: 1618192279:0;cd ~
: 1618192284:0;cd transformers-importance-sampling/
: 1618192287:0;git add .
: 1618192304:0;git status
: 1618192311:0;git add .
: 1618192359:0;git add get_heuristic_stats.py
: 1618192362:0;git add get_heuristic_stat_2.py
: 1618192369:0;git add heuristics.sh
: 1618192374:0;git add nbs/graph_plots_paper.ipynb
: 1618192381:0;git add nbs/heuristics.ipynb
: 1618192386:0;git add nohup.out
: 1618192389:0;git add roberta_ambi.txt
: 1618192394:0;git add run_seed_fig_1.sh
: 1618192396:0;git status
: 1618192405:0;ls augmented_dataset
: 1618192409:0;ls augmented_dataset/au
: 1618192417:0;rm augmented_dataset
: 1618192425:0;git add heuristics_get_examples.py
: 1618192429:0;git status
: 1618192438:0;git commit -m "new exp"
: 1618192444:0;git push
: 1618192450:0;git push origin new
: 1618192510:0;ls ../apex/experiment
: 1618326210:0;cd transformers-importance-sampling/
: 1618326213:0;vim heuristics_get_examples.py
: 1618326439:0;ls
: 1618326451:0;vim insert/e_c.json
: 1618326551:0;vim insert/c_e.json
: 1618327859:0;vim heuristics_get_examples.py
: 1618425055:0;nvidia-smi 
: 1618425067:0;cd apex/experiment
: 1618425070:0;ls
: 1618425154:0;cd ..
: 1618425155:0;ls
: 1618425159:0;cd commonsense-discourse/training
: 1618425160:0;ls
: 1618425166:0;vim train_model.sh
: 1618425235:0;sh train_model.sh
: 1618626609:0;ls
: 1618626620:0;tl
: 1618626632:0;tad jupyter
: 1618626642:0;nvidia-smi 
: 1618626659:0;cd apex/
: 1618626661:0;ls experiment
: 1618626678:0;ls experiment/ctrl_discovery_7
: 1618626683:0;ts cs
: 1618626688:0;ls
: 1618626697:0;cd commonsense-discourse
: 1618626698:0;ls
: 1618626701:0;cd training
: 1618626702:0;ls
: 1618626707:0;vim train_model.sh
: 1618626716:0;sh train_model.sh
: 1618626729:0;tl
: 1618806294:0;tad cs
: 1619015078:0;nvidia-smi 
: 1619015086:0;cd transformers-importance-sampling/
: 1619015088:0;vim get_heuristic_stats.py
: 1619015107:0;ls cartography/filtered/bert_ambiguous_mnli
: 1619015117:0;ls ../cartography/filtered/bert_base_easy_mnli
: 1619015126:0;ls ../cartography/filtered/bert_base_ambiguous_mnli
: 1619015131:0;vim get_heuristic_stats.py
: 1619015202:0;p3 get_heuristic_stats.py
: 1619015255:0;vim get_heuristic_stats.py
: 1619015273:0;p3 get_heuristic_stats.py
: 1619015462:0;vim get_heuristic_stats.py
: 1619015494:0;p3 get_heuristic_stats.py
: 1619015670:0;vim get_heuristic_stats.py
: 1619015692:0;p3 get_heuristic_stats.py
: 1619015862:0;vim get_heuristic_stats.py
: 1619015894:0;p3 get_heuristic_stats.py
: 1619016092:0;vim get_heuristic_stats.py
: 1619016301:0;p3 get_heuristic_stats.py
: 1619016338:0;vim get_heuristic_stats.py
: 1619016360:0;p3 get_heuristic_stats.py
: 1619016535:0;vim get_heuristic_stats.py
: 1619016573:0;p3 get_heuristic_stats.py
: 1619016736:0;vim get_heuristic_stats.py
: 1619016805:0;p3 get_heuristic_stats.py
: 1619016968:0;vim get_heuristic_stats.py
: 1619017070:0;p3 get_heuristic_stats.py
: 1619017289:0;vim get_heuristic_stats.py
: 1619017322:0;p3 get_heuristic_stats.py
: 1619017507:0;vim get_heuristic_stats.py
: 1619017524:0;p3 get_heuristic_stats.py
: 1619017698:0;vim get_heuristic_stats.py
: 1619017849:0;p3 get_heuristic_stats.py
: 1619028434:0;vim get_heuristic_stats.py
: 1619033560:0;p3 get_heuristic_stats.py
: 1619034016:0;vim get_heuristic_stats.py
: 1619034041:0;p3 get_heuristic_stats.py
: 1619036124:0;vim get_heuristic_stats.py
: 1619036149:0;p3 get_heuristic_stats.py
: 1619046488:0;cd ..
: 1619046492:0;tad cs
: 1619046500:0;vim train_model.sh
: 1619046534:0;sh train_model.sh
: 1619046550:0;cd tools
: 1619046550:0;ls
: 1619046553:0;cd bin
: 1619046554:0;ls
: 1619125948:0;cd transformers-importance-sampling/
: 1619125966:0;vim get_heuristic_stats.py
: 1619126031:0;p3 get_heuristic_stats.py
: 1619126171:0;CUDA_VISIBLDE_DEVICES=1 p3 get_heuristic_stats.py
: 1619126174:0;vim get_heuristic_stats.py
: 1619126188:0;CUDA_VISIBLDE_DEVICES=1 p3 get_heuristic_stats.py
: 1619126313:0;nvidia-smi 
: 1619126319:0;vim get_heuristic_stats.py
: 1619126332:0;CUDA_VISIBLDE_DEVICES=1 p3 get_heuristic_stats.py
: 1619126548:0;vim get_heuristic_stats.py
: 1619126561:0;CUDA_VISIBLDE_DEVICES=1 p3 get_heuristic_stats.py
: 1619126801:0;nvidia-smi 
: 1619126811:0;vim get_heuristic_stats.py
: 1619126855:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1619126860:0;vim get_heuristic_stats.py
: 1619126872:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1619127487:0;vim get_heuristic_stats.py
: 1619127640:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1619127873:0;vim get_heuristic_stats.py
: 1619127901:0;CUDA_VISIBLE_DEVICES=1 p3 get_heuristic_stats.py
: 1619376069:0;tad cs
: 1619376072:0;ls
: 1619376079:0;vim train_model.sh
: 1619376097:0;sh train_model.sh
: 1619376114:0;nvidia-smi 
: 1619376131:0;cd ..
: 1619376133:0;ls
: 1619376172:0;cd ..
: 1619376174:0;ls
: 1619376188:0;cd experiment
: 1619376189:0;ls
: 1619376205:0;cd ctrl_discovery_7
: 1619376270:0;git lfs install\
git clone https://huggingface.co/prajjwal1/ctrl_discovery_7
: 1619376282:0;mv * ctrl_discovery_7
: 1619376285:0;cd ctrl_discovery_7
: 1619376286:0;ls
: 1619376288:0;export PATH=/home/nlp/tools/bin:$PATH
: 1619376290:0;git lfs install\
git clone https://huggingface.co/prajjwal1/ctrl_discovery_7
: 1619376299:0;git lfs install
: 1619376302:0;ls
: 1619376307:0;rm eval_results_clm.txt
: 1619376314:0;rm train*
: 1619376317:0;rm -r checkpoint-80000
: 1619376324:0;ls
: 1619376342:0;ls ctrl_discovery_7
: 1619376345:0;cd ..
: 1619376348:0;ls
: 1619376350:0;cd ctrl_discovery_7
: 1619376354:0;rm -r ctrl_discovery_7
: 1619376356:0;ls
: 1619376362:0;transformers-cli lfs-enable-largefiles .
: 1619376371:0;git add .
: 1619376466:0;git commit -m "v1"
: 1619376470:0;git push
: 1619384253:0;cd ..
: 1619384307:0;ls
: 1619384316:0;cd ctrl_discovery_8
: 1619384317:0;ls
: 1619384319:0;rm train*
: 1619384324:0;rm -r checkpoint-80000
: 1619384331:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_8
: 1619384344:0;mv * ctrl_discovery_8
: 1619384345:0;ls
: 1619384348:0;cd ctrl_discovery_8
: 1619384349:0;ls
: 1619384351:0;rm eval_results_clm.txt
: 1619384352:0;ls
: 1619384357:0;git add .
: 1619384371:0;git lfs install
: 1619384374:0;transformers-cli lfs-enable-largefiles .
: 1619384380:0;git add .
: 1619384489:0;git commit -m "v1"
: 1619384494:0;git push
: 1619384517:0;nvidia-smi 
: 1619553137:0;cd transformers-importance-sampling/
: 1619553139:0;ls
: 1619553145:0;vim models/orthogonal_transformer.py
: 1619629653:0;nvidia-smi 
: 1619629671:0;tl
: 1619629680:0;ts jupyter
: 1619629685:0;jupyter notebook --no-browser --port=8888
: 1619632081:0;ls
: 1619633455:0;nvidia-smi 
: 1619634438:0;ls experiments/train_test_overlap
: 1619634524:0;ls
: 1619634528:0;ls experiments/train_test_overlap
: 1619634803:0;pip3 install sentence_transformers
: 1619742327:0;tl
: 1619742330:0;ts cs
: 1619742334:0;ls
: 1619742338:0;cd transformers-importance-sampling/
: 1619742346:0;python3 train_test_overlap.py
: 1619755061:0;tad cs
: 1619808289:0;nvidia-smi 
: 1619808366:0;htop
: 1619808378:0;nvidia-smi 
: 1619808390:0;cd apex/commonsense-discourse/training
: 1619808391:0;ls
: 1619808395:0;vim train_model.sh
: 1619808422:0;ls ../../experiment
: 1619808427:0;sh train_model.sh
: 1619808436:0;ts cs2
: 1619808439:0;ls
: 1619808441:0;sh train_model.sh
: 1619808455:0;nvidia-smi 
: 1619891952:0;tl
: 1619891957:0;tad cs
: 1619891987:0;python3
: 1619892006:0;vim train_test_overlap.py
: 1619892031:0;python3 train_test_overlap.py
: 1619892062:0;pip3 install pylint
: 1619892133:0;pylint train_test_overlap.py
: 1619892154:0;python3 train_test_overlap.py
: 1619934198:0;tad cs
: 1619970921:0;tl
: 1619970936:0;tad cs
: 1619971577:0;nvidia-smi 
: 1619971585:0;tad cs
: 1619971592:0;tad cs2
: 1619978821:0;tad cs
: 1619988626:0;tad cs2
: 1619988629:0;tad cs
: 1619988773:0;ts cs3
: 1619988777:0;ls
: 1619988798:0;rm -r nltk_data
: 1619988804:0;ls
: 1619988812:0;cd prajjwal1
: 1619988814:0;ls
: 1619988949:0;git clone https://github.com/prajjwal1/commonsense-discourse.git
: 1619988971:0;ls
: 1619988975:0;cd commonsense-discourse
: 1619988975:0;ls
: 1619988978:0;cd discosense
: 1619988980:0;ls
: 1619989001:0;tad utd
: 1619989004:0;tl
: 1619989056:0;ls
: 1619989060:0;cd prajjwal1/commonsense-discourse
: 1619989061:0;ls
: 1619989063:0;git pull
: 1619989071:0;ls
: 1619989074:0;cd discosense
: 1619989074:0;ls
: 1619989077:0;vim generate_ds.sh
: 1619989117:0;sh generate_ds.sh
: 1619989216:0;tl
: 1619989219:0;ts gen
: 1619989224:0;ls
: 1619989228:0;sh generate_ds.sh
: 1619991886:0;tad gen
: 1619991916:0;nvidia-smi 
: 1619991922:0;tad cs
: 1619998437:0;nvidia-smi 
: 1619998443:0;ls
: 1619998450:0;htop
: 1619998462:0;vim generate_valid.sh
: 1619998494:0;sh generate_ds.sh
: 1619998503:0;sh generate_valid.sh
: 1619998509:0;ts gen_2
: 1619998513:0;sh generate_valid.sh
: 1619998519:0;tad gen_1
: 1619998521:0;tad gen
: 1619998543:0;tad cs2
: 1619998555:0;tad gen_2
: 1619998571:0;tad gen_1
: 1619998573:0;tad gen
: 1619998605:0;tad cs
: 1620047622:0;ls
: 1620047637:0;vim train_test_overlap.py
: 1620075336:0;ls
: 1620075338:0;cd ..
: 1620075345:0;cd cartography
: 1620075345:0;ls
: 1620075349:0;cd filtered
: 1620075350:0;ls
: 1620075366:0;cd ..
: 1620075366:0;ls
: 1620075372:0;cd bert_base
: 1620075373:0;ls
: 1620075380:0;cd training_dynamics
: 1620075381:0;ls
: 1620075397:0;vim dynamics_epoch_1.jsonl
: 1620083819:0;ls
: 1620083828:0;tl
: 1620083829:0;nvidia-smi 
: 1620083837:0;mkdir gh
: 1620083839:0;cd gh
: 1620083844:0;git clone https://github.com/prajjwal1/travelsearch
: 1620083865:0;cd travelsearch
: 1620083865:0;ls
: 1620083870:0;cd clustering
: 1620083871:0;ls
: 1620083918:0;p3 reranking
: 1620083923:0;p3 rerankingkmeans.py
: 1620083929:0;python3
: 1620083970:0;p3 rerankingkmeans.py
: 1620084010:0;tl
: 1620084013:0;tad cs2
: 1620084025:0;ls
: 1620084089:0;cd kmeans
: 1620084091:0;wget https://personal.utdallas.edu/\~abp170003/S.pickle
: 1620084244:0;cd gh/travelsearch
: 1620084245:0;ls
: 1620084255:0;cd clustering
: 1620084256:0;ls
: 1620084259:0;cd complete
: 1620084272:0;wget https://personal.utdallas.edu/\~abp170003/AggVectors.pickle
: 1620084407:0;ls
: 1620084415:0;cd ..
: 1620084416:0;ls
: 1620084451:0;tad cs2
: 1620084562:0;wget https://personal.utdallas.edu/\~abp170003/S.pickle
: 1620084724:0;vim rerankingkmeans.py
: 1620085218:0;curl https://personal.utdallas.edu/\~abp170003/S.pickle
: 1620085495:0;cd ..
: 1620085496:0;ls
: 1620085499:0;wget https://personal.utdallas.edu/\~abp170003/S.pickle
: 1620085547:0;ls
: 1620085551:0;cd ..
: 1620085552:0;ls
: 1620085556:0;cd ..
: 1620085557:0;ls
: 1620085567:0;cd travelsearch
: 1620085567:0;ls
: 1620085570:0;cd ..
: 1620085586:0;ls
: 1620085632:0;pip3 install flask
: 1620085650:0;ls
: 1620085653:0;cd travelsearch
: 1620085655:0;p3 app.py
: 1620085870:0;cd gh/travelsearch
: 1620085871:0;ls
: 1620085873:0;cd clustering
: 1620085874:0;ls
: 1620085962:0;ts flask
: 1620085967:0;p3 app.py
: 1620085971:0;ls
: 1620085974:0;cd ..
: 1620085975:0;ls
: 1620085978:0;git pull
: 1620086010:0;tad flask
: 1620086199:0;cd clustering/complete
: 1620086200:0;ls
: 1620086210:0;curl https://personal.utdallas.edu/\~abp170003/S.pickle --output S.pickle
: 1620086618:0;tad cs2
: 1620086730:0;curl https://personal.utdallas.edu/\~abp170003/S.pickle --output S.pickle
: 1620086829:0;ls
: 1620086832:0;git pull
: 1620086840:0;ls
: 1620086845:0;cd ..
: 1620086846:0;ls
: 1620086856:0;vim association2.py
: 1620086885:0;mkdir query_expansion
: 1620086889:0;mv association2.py query_expansion
: 1620086894:0;mv scalar2.py query_expansion
: 1620086899:0;mv stopwords query_expansion
: 1620086900:0;ls
: 1620086904:0;mv metric2.py query_expansion
: 1620086905:0;ls
: 1620086970:0;cd query_expansion
: 1620086971:0;ls
: 1620086977:0;v association2.py
: 1620087069:0;vim metric2.py
: 1620087114:0;vim scalar2.py
: 1620087165:0;cd ..
: 1620087167:0;git add .
: 1620087173:0;git status
: 1620087182:0;git add query_expansion/
: 1620087194:0;git commit -m "query_expansion"
: 1620087201:0;git push
: 1620087231:0;mkdir data
: 1620087373:0;tad cs2
: 1620087625:0;axel
: 1620087721:0;tad cs2
: 1620088007:0;cd ..
: 1620088009:0;ls
: 1620088011:0;cd ..
: 1620088014:0;cd gh
: 1620088014:0;ls
: 1620088016:0;cd ..
: 1620088018:0;cd tools
: 1620088019:0;ls
: 1620088024:0;git clone https://github.com/axel-download-accelerator/axel.git
: 1620088041:0;cd axel/
: 1620088049:0;ls
: 1620088058:0;./configure && make && make install
: 1620088085:0;make configue
: 1620088087:0;make configure
: 1620088111:0;./configure
: 1620088114:0;ls
: 1620088143:0;cd src
: 1620088143:0;ls
: 1620088222:0;tad cs2
: 1620089213:0;p3 app.py
: 1620089269:0;cd ..
: 1620089272:0;ls
: 1620089276:0;cd ..
: 1620089282:0;ls
: 1620089285:0;cd gh
: 1620089287:0;cd travelsearch
: 1620089288:0;ls
: 1620089290:0;cd clustering
: 1620089299:0;ls
: 1620089303:0;vim rerankingkmeans.py
: 1620089382:0;ls
: 1620089385:0;cd ..
: 1620089387:0;ls
: 1620089391:0;cd travelsearch
: 1620089392:0;ls
: 1620089394:0;vim app.py
: 1620089426:0;git pull
: 1620089431:0;vim app.py
: 1620089445:0;ls
: 1620089451:0;vim app.py
: 1620089477:0;cd ..
: 1620089506:0;cd clustering
: 1620089509:0;vim rerankingkmeans.py
: 1620090934:0;p3 app.py
: 1620090964:0;cd clustering
: 1620090972:0;ls
: 1620090975:0;cd ..
: 1620090981:0;cd cluster
: 1620090984:0;cd clustering/u
: 1620090986:0;cd clustering/
: 1620090986:0;ls
: 1620091005:0;mv S.pickle kmean
: 1620091010:0;ls
: 1620091020:0;mv kmeans/S.pickle kmeans
: 1620091029:0;mv kmean/S.pickle kmeans
: 1620091035:0;mv kmean kmeans
: 1620091040:0;ls kmeans
: 1620091065:0;cd kmeans
: 1620091069:0;ls kmean
: 1620091086:0;mv kmean S.pickle
: 1620091092:0;cd ..
: 1620091094:0;ls
: 1620091095:0;cd ..
: 1620091098:0;cd travelsearch
: 1620091100:0;p3 app.py
: 1620091465:0;grep -c ^processor /proc/cpuinfo
: 1620091488:0;grep MemTotal /proc/meminfo.
: 1620091490:0;grep MemTotal /proc/meminfo
: 1620094723:0;cd ~
: 1620094749:0;cd experiments/train_test_overlap
: 1620094749:0;ls
: 1620094753:0;vim data_all.json
: 1620099469:0;cd ~
: 1620137186:0;tl
: 1620137192:0;tad gen
: 1620137218:0;tad flask
: 1620140008:0;ts cs
: 1620140010:0;tad cs
: 1620140013:0;cd ~
: 1620140018:0;cd gh/travelsearch
: 1620140018:0;ls
: 1620140023:0;cd travelsearch
: 1620140023:0;ls
: 1620140027:0;vim app.py
: 1620140115:0;cd ..
: 1620140120:0;vim clustering
: 1620140234:0;ls
: 1620140237:0;cd clustering
: 1620140238:0;ls
: 1620140241:0;vim rerankingkmeans.py
: 1620140326:0;vim ../travelsearch/app.py
: 1620141155:0;cd gh/travelsearch
: 1620141407:0;ls
: 1620141413:0;vim README.md
: 1620141418:0;git pull
: 1620141434:0;vim README.md
: 1620141841:0;tad flask
: 1620141845:0;p3 app.py
: 1620143080:0;ls
: 1620143084:0;git pull
: 1620143101:0;p3 app.py
: 1620143106:0;vim app.py
: 1620143127:0;p3 app.py
: 1620143131:0;vim app.py
: 1620143142:0;p3 app.py
: 1620143240:0;vim ../clustering/rerankingkmeans.py
: 1620143282:0;vim rerankingkmeans.py
: 1620143291:0;tad cs
: 1620143303:0;e
: 1620143306:0;tad cs
: 1620143309:0;ts cs
: 1620143316:0;ls
: 1620143319:0;cd gh/travelsearch
: 1620143325:0;vim clustering/rerankingkmeans.py
: 1620143453:0;p3 app.py
: 1620143732:0;vim clustering/rerankingkmeans.py
: 1620144491:0;pip install multiprocessing
: 1620144512:0;vim clustering/rerankingkmeans.py
: 1620144525:0;pip install joblib
: 1620144532:0;vim clustering/rerankingkmeans.py
: 1620144594:0;p3 app.py
: 1620146308:0;vim app.py
: 1620146320:0;p3 app.py
: 1620147963:0;ls
: 1620147970:0;git add travelsearch/app.py
: 1620147976:0;git add clustering/rerankingkmeans.py
: 1620147984:0;git commit -m "Multiprocessing"
: 1620147989:0;git push
: 1620148752:0;vim clustering/rerankingkmeans.py
: 1620148777:0;p3 app.py
: 1620152946:0;ls
: 1620152953:0;cd ..
: 1620152955:0;git status
: 1620152959:0;git add README.md
: 1620152963:0;git add requirements.txt
: 1620152970:0;git add clustering/rerankingkmeans.py
: 1620152978:0;git commit -m "Multiprocessing working"
: 1620152991:0;git push
: 1620153089:0;vim clustering/rerankingkmeans.py
: 1620153596:0;cd travelsearch
: 1620153598:0;p3 app.py
: 1620158110:0;cd ..
: 1620158135:0;cd travelsearch
: 1620158138:0;git pull
: 1620158430:0;vim travelsearch/app.py
: 1620158457:0;pip3 install -r requirements.txt
: 1620158464:0;vim requirements.txt
: 1620158532:0;pip3 install -r requirements.txt
: 1620158767:0;ls
: 1620158769:0;git pull
: 1620158851:0;vim travelsearch/app.py
: 1620159289:0;git pull
: 1620159300:0;p3 app.py
: 1620162674:0;git pull
: 1620162858:0;p3 app.py
: 1620165461:0;git pull
: 1620165473:0;p3 travelsearch/app.py
: 1620165478:0;ls
: 1620165493:0;cd travelsearch
: 1620165495:0;p3 app.py
: 1620165504:0;cd ..
: 1620165511:0;pip3 install bs4
: 1620165535:0;p3 app.py
: 1620165539:0;ls
: 1620165542:0;cd travelsearch
: 1620165543:0;p3 app.py
: 1620166530:0;ls
: 1620166533:0;cd ..
: 1620166534:0;ls
: 1620166538:0;cd clustering
: 1620166542:0;git pull
: 1620166549:0;vim rerankingkmeans.py
: 1620166564:0;c ..
: 1620166565:0;cd ..
: 1620166569:0;vim clustering/rerankingkmeans.py
: 1620166574:0;vim rerankingkmeans.py
: 1620167202:0;cd ..
: 1620167204:0;cd travelsearch
: 1620167206:0;p3 app.py
: 1620167506:0;cd ..
: 1620167510:0;cd travelsearch
: 1620167525:0;ls
: 1620167533:0;vim index/PageRank.py
: 1620167543:0;cd index
: 1620167543:0;ls
: 1620167559:0;vim ElasticSearchIndex.py
: 1620167714:0;tl
: 1620167717:0;tad gen
: 1620167816:0;git pull
: 1620167872:0;cd ..
: 1620167875:0;git stash
: 1620167880:0;git pull
: 1620167891:0;tad flas
: 1620168207:0;cd ..
: 1620168211:0;ls experiments
: 1620169681:0;cd gh/travelsearch
: 1620169683:0;git pull
: 1620169694:0;vim clustering/rerankingComplete.py
: 1620169732:0;vim clustering/rerankingkmeans.py
: 1620170112:0;vim clustering/rerankingComplete.py
: 1620170446:0;git add clustering/rerankingkmeans.py
: 1620170453:0;git add clustering/rerankingComplete.py
: 1620170458:0;git add clustering/rerankingSingle.py
: 1620170470:0;git commit -m "Fixed bugs"
: 1620170475:0;git push
: 1620170823:0;git pull
: 1620170848:0;tad flask
: 1620170851:0;p3 app.py
: 1620170906:0;git pull
: 1620170929:0;vim index/ElasticSearchIndex.py
: 1620171427:0;git pull
: 1620173494:0;vim clustering/rerankingkmeans.py
: 1620173619:0;tad flask
: 1620173622:0;p3 app.py
: 1620173646:0;vim clustering/rerankingSingle.py
: 1620173660:0;vim clustering/rerankingComplete.py
: 1620174848:0;git pull
: 1620174872:0;git diff 
: 1620174880:0;git diff  clustering/rerankingComplete.py
: 1620174918:0;git add .
: 1620174930:0;git add clustering/re*
: 1620174949:0;git commit -m "ixed imports"
: 1620174953:0;git pull
: 1620174971:0;git push
: 1620175623:0;git pull
: 1620175759:0;tad flask
: 1620175763:0;p3 app.py
: 1620175785:0;tad flask
: 1620175788:0;p3 app.py
: 1620175803:0;tad flask
: 1620175842:0;htop
: 1620175915:0;p3 app.py
: 1620175935:0;ps -fA | grep python
: 1620175951:0;kill -94011944
: 1620175964:0;kill -9 4011944
: 1620175978:0;kill -9 4011904
: 1620175983:0;p3 app.py
: 1620176292:0;nvidia-smi 
: 1620176297:0;tad gen
: 1620177949:0;vim clustering/rerankingComplete.py
: 1620178043:0;vim clustering/rerankingSingle.py
: 1620178087:0;vim clustering/rerankingkmeans.py
: 1620178133:0;git add clustering/re*
: 1620178140:0;git commit -m "fixed imports"
: 1620178146:0;git push
: 1620178156:0;git status
: 1620178173:0;git add .
: 1620178182:0;git add clustering/re*
: 1620178190:0;git commit -m "fixed num_docs"
: 1620178195:0;git push
: 1620178198:0;git pull
: 1620178211:0;git push
: 1620178238:0;p3 app.py
: 1620178247:0;ps -fA | grep python
: 1620178255:0;kill -9 4016651
: 1620178260:0;p3 app.py
: 1620178511:0;git pull
: 1620178530:0;cd index
: 1620178534:0;p3 util.py
: 1620178641:0;vim util.py
: 1620178751:0;git pull
: 1620178788:0;cd ..
: 1620178795:0;vim clustering/rerankingkmeans.py
: 1620178937:0;p3 app.py
: 1620179022:0;vim clustering/rerankingSingle.py
: 1620179145:0;p3 app.py
: 1620179225:0;vim clustering/rerankingComplete.py
: 1620179333:0;git add clustering/re*
: 1620179345:0;git commit -m "fixed reranking"
: 1620179351:0;git pull
: 1620179360:0;git push
: 1620179532:0;cd index
: 1620179535:0;p3 util.py
: 1620179542:0;ls
: 1620179691:0;vim util.py
: 1620179755:0;cd ..
: 1620179756:0;ls
: 1620179761:0;cd crawl
: 1620179762:0;ls
: 1620179764:0;cd ..
: 1620179801:0;cd index
: 1620179862:0;vim util.py
: 1620179887:0;vim ../crawl/travel.json
: 1620179908:0;p3 util.py
: 1620180012:0;vim ../index/util.py 
: 1620185031:0;cd ..
: 1620185038:0;git pull
: 1620185209:0;p3 app.py
: 1620185310:0;cd index
: 1620185310:0;ls
: 1620185318:0;cd ../index
: 1620185352:0;curl --header 'Host: doc-0s-78-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:88.0) Gecko/20100101 Firefox/88.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/' --cookie 'AUTH_7e227ghd5c0ufhiukl9lav14b03l2k30_nonce=qoi7lmqki4hmm' --header 'Upgrade-Insecure-Requests: 1' --header 'DNT: 1' --header 'Sec-GPC: 1' 'https://doc-0s-78-docs.googleusercontent.com/docs/securesc/5fhmrhpcmfja880ilsiekjucqrerho05/vqnhhgh6d955inv0pq0sufh7132l56ej/1620185250000/18330255840714409363/12118617426975648804Z/1nu2voTKTE2lBHSpzLs2womp4FTrJB51m?e=download&nonce=qoi7lmqki4hmm&user=12118617426975648804Z&hash=f59q0r6ujpdtc9j1b7udtenu1ba1po5r' --output 'pages_text.json'
: 1620185406:0;p3 app.py
: 1620185410:0;cd ../travelsearch
: 1620185412:0;p3 app.py
: 1620185426:0;vim app.py
: 1620185439:0;cd travelsearch
: 1620185440:0;vim app.py
: 1620185470:0;p3 app.py
: 1620185479:0;vim app.py
: 1620185515:0;p3 app.py
: 1620185638:0;vim ../index/pages_text.json 
: 1620185649:0;cd ../index
: 1620185684:0;rm pages_text.json
: 1620185692:0;wget --header 'Host: doc-0s-78-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:88.0) Gecko/20100101 Firefox/88.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/' --header 'Cookie: AUTH_7e227ghd5c0ufhiukl9lav14b03l2k30_nonce=qoi7lmqki4hmm' --header 'Upgrade-Insecure-Requests: 1' --header 'DNT: 1' --header 'Sec-GPC: 1' 'https://doc-0s-78-docs.googleusercontent.com/docs/securesc/5fhmrhpcmfja880ilsiekjucqrerho05/vqnhhgh6d955inv0pq0sufh7132l56ej/1620185250000/18330255840714409363/12118617426975648804Z/1nu2voTKTE2lBHSpzLs2womp4FTrJB51m?e=download&nonce=qoi7lmqki4hmm&user=12118617426975648804Z&hash=f59q0r6ujpdtc9j1b7udtenu1ba1po5r' --output-document 'pages_text.json'
: 1620185838:0;wget --header 'Host: doc-0s-78-docs.googleusercontent.com' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:88.0) Gecko/20100101 Firefox/88.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://drive.google.com/' --header 'Cookie: AUTH_7e227ghd5c0ufhiukl9lav14b03l2k30_nonce=ms3hfrtnhsmls' --header 'Upgrade-Insecure-Requests: 1' --header 'DNT: 1' --header 'Sec-GPC: 1' 'https://doc-0s-78-docs.googleusercontent.com/docs/securesc/5fhmrhpcmfja880ilsiekjucqrerho05/7eoo2lj0kkdts3tsqvatmaequ1r5clmr/1620185775000/18330255840714409363/12118617426975648804Z/1nu2voTKTE2lBHSpzLs2womp4FTrJB51m?e=download&nonce=ms3hfrtnhsmls&user=12118617426975648804Z&hash=modcgei5ca7joha6pbe3dodc7tjokshl' --output-document 'pages_text.json'
: 1620185877:0;ls
: 1620185878:0;cd ..
: 1620185883:0;cd index
: 1620185886:0;cd ../travelsearch
: 1620185887:0;p3 app.py
: 1620186122:0;vim ../clustering/rerankingkmeans.py
: 1620186627:0;git status
: 1620186638:0;git diff app.py
: 1620186653:0;git add app.py
: 1620186663:0;git commit -m "file permissions"
: 1620186666:0;git push
: 1620186677:0;git pull
: 1620186686:0;git push
: 1620187027:0;git pull
: 1620187049:0;p3 app.py
: 1620187066:0;vim ../query_expansion/association2.py
: 1620187078:0;p3 app.py
: 1620187083:0;vim ../query_expansion/association2.py
: 1620187116:0;p3 app.py
: 1620187130:0;vim ../query_expansion/metric2.py
: 1620187143:0;p3 app.py
: 1620187486:0;git pull
: 1620188780:0;p3 app.py
: 1620188785:0;vim app.py
: 1620188811:0;p3 app.py
: 1620188817:0;vim app.py
: 1620188838:0;p3 app.py
: 1620188866:0;vim app.py
: 1620188921:0;p3 app.py
: 1620188943:0;git pull
: 1620188950:0;p3 app.py
: 1620189260:0;git pull
: 1620189293:0;git stash
: 1620189300:0;git pull
: 1620189306:0;p3 app.py
: 1620189419:0;git pull
: 1620189426:0;p3 app.py
: 1620189991:0;vim app.py
: 1620190049:0;ls
: 1620190052:0;cd ..
: 1620190053:0;ls
: 1620190062:0;cd travelsearch
: 1620190064:0;git pull
: 1620190198:0;vim app.py
: 1620190247:0;p3 app.py
: 1620190255:0;vim app.py
: 1620190269:0;p3 app.py
: 1620190852:0;git pull
: 1620190870:0;pylint ../query_expansion/association2.py
: 1620190974:0;cd ..
: 1620190978:0;ls
: 1620191264:0;git pull
: 1620191723:0;vim clustering/rerankingkmeans.py
: 1620192027:0;vim app
: 1620192035:0;vim travelsearch/app.py
: 1620192143:0;vim clustering/rerankingkmeans.py
: 1620193360:0;nvidia-smi 
: 1620193499:0;vim clustering/rerankingkmeans.py
: 1620193592:0;git pull
: 1620193606:0;git stash
: 1620193610:0;git pull
: 1620193618:0;p3 app.py
: 1620193773:0;vim clustering/rerankingkmeans.py
: 1620193972:0;p3 app.py
: 1620194197:0;vim clustering/km.py
: 1620194218:0;vim clustering/rerankingkmeans.py
: 1620194478:0;p3 app.py
: 1620195404:0;cd .
: 1620195406:0;ls
: 1620195410:0;vim travelsearch/app.py
: 1620195422:0;git pul
: 1620195424:0;git pull
: 1620195460:0;pip3 install tldextract
: 1620195477:0;p3 app.py
: 1620195590:0;vim travelsearch/app.py
: 1620195836:0;p3 app.py
: 1620195948:0;vim travelsearch/app.py
: 1620196181:0;ls
: 1620196191:0;vim clustering/rerankingkmeans.py
: 1620196220:0;git pull
: 1620196234:0;p3 app.py
: 1620196403:0;vim clustering/rerankingkmeans.py
: 1620196552:0;vim travelsearch/templates/search.html
: 1620196713:0;vim clustering/rerankingkmeans.py
: 1620196733:0;git pull
: 1620196774:0;vim clustering/rerankingkmeans.py
: 1620196887:0;git pull
: 1620197043:0;vim clustering/rerankingkmeans.py
: 1620197148:0;p3 app.py
: 1620198489:0;git pull
: 1620225121:0;cd gh/travelsearch
: 1620225124:0;git pull
: 1620226311:0;git status
: 1620226316:0;git stash
: 1620226322:0;git pull
: 1620226551:0;vim travelsearch/app.py
: 1620226603:0;vim clustering/kmeansWrong.py
: 1620226655:0;cd gh/travelsearch
: 1620226657:0;c
: 1620226659:0;git pull
: 1620226755:0;vim index/pages_text.json
: 1620227278:0;git pull
: 1620227539:0;ls
: 1620227546:0;ls index
: 1620227557:0;vim index/ElasticSearchIndex.py
: 1620229338:0;tad flask
: 1620229344:0;git pull
: 1620229349:0;git status
: 1620229358:0;git add ../index/ElasticSearchIndex.py
: 1620229366:0;git commit -m "fie path fix"
: 1620229371:0;git push
: 1620229384:0;p3 app.py
: 1620229400:0;cd gh/travelsearch
: 1620229531:0;tad gen
: 1620229924:0;vim clustering/kmeansWrong.py
: 1620230563:0;git pull
: 1620231662:0;vim clustering/kmeansWrong.py
: 1620235833:0;git pull
: 1620235865:0;p3 app.py
: 1620237853:0;git pull
: 1620238953:0;p3 app.py
: 1620241342:0;git pull
: 1620241348:0;p3 app.py
: 1620243259:0;ls
: 1620243274:0;vim crawl/crawl/urls.py
: 1620243413:0;git pull
: 1620243467:0;p3 app.py
: 1620244867:0;git pull
: 1620247987:0;p3 app.py
: 1620252054:0;e
: 1620262641:0;cd prajjwal1/commonsense-discourse
: 1620262642:0;ls
: 1620262644:0;cd data
: 1620262645:0;ls
: 1620262649:0;vim gen_train_0_50.json
: 1620262659:0;cd ..
: 1620262662:0;cd discosense
: 1620262676:0;vim generate_dataset.py
: 1620262696:0;vim generate_ds.sh
: 1620262745:0;vim generate_dataset.py
: 1620262802:0;vim generate_ds.sh
: 1620262830:0;sh generate_ds.sh
: 1620266174:0;vim generate_dataset.py
: 1620266185:0;sh generate_ds.sh
: 1620266261:0;vim generate_dataset.py
: 1620266291:0;sh generate_ds.sh
: 1620266401:0;vim generate_dataset.py
: 1620266429:0;sh generate_ds.sh
: 1620266499:0;ls ../data
: 1620266509:0;vim generate_ds.sh
: 1620266527:0;ls ../data/gen_train_0_50.json
: 1620266536:0;vim generate_ds.sh
: 1620266563:0;python3
: 1620266624:0;vim ../data/gen_train_0_50.json
: 1620266648:0;cd ..
: 1620266652:0;cd data
: 1620266653:0;ls
: 1620266666:0;cd ..
: 1620266672:0;cd discosense
: 1620266674:0;vim generate_ds.sh
: 1620266757:0;mv generate_ds.sh generate_ds_0.sh
: 1620266764:0;ts gen
: 1620266770:0;tad gen
: 1620266774:0;cd ..
: 1620266781:0;cd data
: 1620266789:0;cd ../discosense
: 1620266798:0;sh generate_ds_0.sh
: 1620266814:0;vim generate_ds.sh
: 1620266821:0;vim generate_d_0
: 1620266827:0;vim generate_ds_0.sh
: 1620266841:0;sh generate_ds_0.sh
: 1620266849:0;vim generate_ds_0.sh
: 1620266899:0;sh generate_ds_0.sh
: 1620266906:0;vim generate_ds_0.sh
: 1620266913:0;vim generate_ds.sh
: 1620266917:0;vim generate_ds_0.sh
: 1620266938:0;tad gen
: 1620266951:0;sh generate_ds_0.sh
: 1620266956:0;vim generate_ds_0.sh
: 1620266967:0;sh generate_ds_0.sh
: 1620267006:0;vim generate_ds_0.sh
: 1620267032:0;git status
: 1620267050:0;git diff generate_ds.sh
: 1620267090:0;vim generate_ds_0.sh
: 1620267105:0;ls
: 1620267111:0;tad cs2
: 1620267118:0;ls 
: 1620267124:0;vim train_model.sh
: 1620267144:0;sh train_model.sh
: 1620267149:0;tad cs
: 1620267152:0;tl
: 1620267156:0;tad cs3
: 1620271771:0;sh generate_ds.sh
: 1620271803:0;ls
: 1620271814:0;sh generate_ds_0.sh
: 1620271822:0;vim generate_ds_0.sh
: 1620271934:0;sh generate_ds_0.sh
: 1620272150:0;nvidia-smi 
: 1620272173:0;tad cs3
: 1620272182:0;vim generate_ds_0.sh
: 1620272203:0;tad cs3
: 1620272206:0;vim generate_ds_0.sh
: 1620272225:0;sh generate_ds_0.sh
: 1620272371:0;tad cs2
: 1620272375:0;vim train_model.sh
: 1620272380:0;nvidia-smi 
: 1620272389:0;vim train_model.sh
: 1620272404:0;sh train_model.sh
: 1620272546:0;tad gen
: 1620272552:0;tl
: 1620272555:0;tad gen_2
: 1620272560:0;tl
: 1620272563:0;tad cs2
: 1620272566:0;tad cs3
: 1620272572:0;tad cs
: 1620272574:0;tad cs2
: 1620272577:0;sh train_model.sh
: 1620272702:0;tad gen_2
: 1620272705:0;tad gen
: 1620272924:0;nvidia-smi 
: 1620272938:0;tad cs2
: 1620272944:0;sh train_model.sh
: 1620272955:0;tad gen
: 1620272962:0;tad cs2
: 1620273142:0;nvidia-smi 
: 1620273146:0;htop
: 1620273175:0;tad jupyter
: 1620273197:0;jupyter notebook --no-browser --port=8888
: 1620273204:0;tad gen_2
: 1620273213:0;tad cs2
: 1620273221:0;sh train_model.sh
: 1620273400:0;tad gen_2
: 1620273404:0;tad gen
: 1620272710:247;sh generate_ds_0.sh
: 1620273409:0;vim generate_ds_0.sh
: 1620273414:0;nvidia-smi 
: 1620273418:0;sh generate_ds_0.sh
: 1620273426:0;tad gen
: 1620273504:0;nvidia-smi 
: 1620273561:0;tad gen_2
: 1620273579:0;cp generate_ds_0.sh generate_ds_1.sh
: 1620273585:0;vim generate_ds_1.sh
: 1620273675:0;sh generate_ds_1.sh
: 1620273760:0;tad gen
: 1620273800:0;tad gen_2
: 1620273822:0;nvidia-smi 
: 1620275300:0;tad gen_2
: 1620315732:0;nvidia-smi 
: 1620447140:0;tl
: 1620447145:0;tad cs2
: 1620447168:0;tad gen2
: 1620447170:0;tad gen_2
: 1620447212:0;tad gen
: 1620447229:0;nvidia-smi 
: 1620506340:0;tad cs2
: 1620506350:0;tad gen
: 1620506367:0;tad gen_2
: 1620598773:0;nvidia-smi 
: 1620598785:0;cd transformers-importance-sampling/
: 1620598789:0;vim run_glue.sh
: 1620599010:0;vim run_glue.py
: 1620599276:0;vim new_run_glue.py
: 1620599462:0;export TASK_NAME=mnli
: 1620599561:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 8 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620599581:0;pip3 install transformers --upgrade
: 1620599690:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 8 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620599703:0;cd ..
: 1620599709:0;cd transformers
: 1620599713:0;git pull
: 1620599957:0;pip3 install setup.pip install git+https://github.com/huggingface/transformers
: 1620599960:0;pip install git+https://github.com/huggingface/transformers
: 1620600084:0;cd ..
: 1620600088:0;cd transformers-importance-sampling/
: 1620600092:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 8 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620600305:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 4 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620600329:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 8 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620600776:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620601973:0;nvidia-smi 
: 1620601986:0;tad gen_2
: 1620602041:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620602178:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620602264:0;nvidia-smi 
: 1620610822:0;vim new_run_glue.py
: 1620610862:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620611490:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 2e-5 \\
  -- overwrite_output_dir \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620611513:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 2e-5 \\
  --overwrite_output_dir \\
  --num_train_epochs 1 \\
  --output_dir /home/nlp/experiments/token_check
: 1620657733:0;cd experiments
: 1620657734:0;ls
: 1620657736:0;cd train_test_overlap
: 1620657737:0;ls
: 1620657747:0;mv similarity.bin ngram_similarity.bin
: 1620657750:0;cd ..
: 1620657756:0;cd transformers-importance-sampling/
: 1620657760:0;vim train_test_overlap.py
: 1620658104:0;p3 train_test_overlap.py
: 1620658506:0;nvidia-smi 
: 1620658521:0;CUDA_VISIBLE_DEVICES=1 p3 train_test_overlap.py
: 1620658867:0;ts cs
: 1620658930:0;tad cs
: 1620658934:0;p3 train_test_overlap.py
: 1620658938:0;CUDA_VISIBLE_DEVICES=1 p3 train_test_overlap.py
: 1620678601:0;ls
: 1620678606:0;tad gen_2
: 1620678608:0;ddsdsdsasddasdsdads
: 1620678620:0;cd ..
: 1620678622:0;cd data
: 1620678622:0;ls
: 1620678632:0;vim gen_train_0_50.json
: 1620678643:0;rm gen_train_0_50.json
: 1620678649:0;vim gen_train_0_50_op_0.json
: 1620678663:0;cp gen_train_0_50_op_0.json backup
: 1620678673:0;cp gen_train_50_100_op_0.json  backup
: 1620678674:0;cd ..
: 1620678677:0;cd discosense
: 1620678685:0;vim generate_ds_0.sh
: 1620678704:0;vim generate_dataset.py
: 1620678714:0;vim generate_ds_0.sh
: 1620678815:0;sh generate_ds_0.sh
: 1620678825:0;vim generate_ds_0.sh
: 1620678835:0;sh generate_ds_0.sh
: 1620678895:0;tad gen
: 1620678904:0;vim generate_ds_`.sh
: 1620678916:94;vim generate_ds_1.sh
: 1620679015:0;sh generate_ds_1.sh
: 1620679067:0;cd ..
: 1620679082:0;vim prajjwal1/commonsense-discourse/discosense/generate_ds_1.sh
: 1620679088:0;nvidia-smi 
: 1620679104:0;cd apex/commonsense-discourse/training
: 1620679105:0;ls
: 1620679113:0;vim train_model.sh
: 1620679159:0;sh train_model.sh
: 1620679195:0;tad cs2
: 1620679203:0;sh train_model.sh
: 1620679210:0;nvidia-smi 
: 1620679214:0;htop
: 1620679270:0;tad cs2
: 1620682666:0;nvidia-smi 
: 1620682673:0;tad gen
: 1620682678:0;tad gen_2
: 1620684002:0;nvidia-smi 
: 1620692914:0;tad gen_2
: 1620692923:0;tad gen
: 1620768864:0;cd transformers-importance-sampling/
: 1620768867:0;cd hasn
: 1620768869:0;cd hans
: 1620768870:0;ls
: 1620769048:0;p3 run_hans.py --task_name hans --model_type bert-base-uncased --do_eval --data_dir $HANS_DIR --model_name_or_path bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir .
: 1620769072:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --model_type bert-base-uncased --do_eval --data_dir $HANS_DIR --model_name_or_path bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir .
: 1620769081:0;vim run_hans_all.sh
: 1620769135:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir .
: 1620769172:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path blackbird/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir .
: 1620769467:0;pip3 install transformers==4.3
: 1620769632:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path blackbird/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir .
: 1620769645:0;mkdir bb
: 1620769653:0;cd bb
: 1620769658:0;git lfs install
: 1620769665:0;export PATH=/home/nlp/tools/bin:$PATH
: 1620769666:0;git lfs install
: 1620769668:0;git lfs install\
git clone https://huggingface.co/blackbird/bert-base-uncased-MNLI-v1
: 1620769712:0;ls
: 1620769714:0;cd ..
: 1620769718:0;ls
: 1620769745:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path bb/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir bb/bert-base-uncased-MNLI-v1
: 1620769773:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path bb/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir bb/bert-base-uncased-MNLI-v1 --overwrite_output_dir 
: 1620769787:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path bb/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir bb/bert-base-uncased-MNLI-v1 --overwrite_cache
: 1620769816:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir $HANS_DIR --model_name_or_path bb/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir bb/bert-base-uncased-MNLI-v1 --tokenizer bert-base-uncased
: 1620769838:0;vim run_hans_all.sh
: 1620769849:0;echo $HANS_PATH
: 1620769853:0;echo $HANS_DIR
: 1620769873:0;CUDA_VISIBLE_DEVICES=1 p3 run_hans.py --task_name hans --do_eval --data_dir /home/nlp/data/glue_data/hans --model_name_or_path bb/bert-base-uncased-MNLI-v1 --max_seq_length 128 --output_dir bb/bert-base-uncased-MNLI-v1 --tokenizer bert-base-uncased
: 1620770164:0;cd ..
: 1620770168:0;cd data/glue_data/hans
: 1620770169:0;ls
: 1620770187:0;p3 evaluate_heur_output.py ~/transformers-importance-sampling/hans/bb/bert-base-uncased-MNLI-v1/hans_predictions.txt
: 1620770225:0;p3 evaluate_heur_output.py ~/experiments/big_small/albert_large/epoch_4/hans_predictions.txt
: 1620775510:0;python3
: 1620777511:0;cd
: 1620777514:0;cd transformers-importance-sampling/
: 1620777527:0;vim run_glue.sh
: 1620777572:0;sh run_glue.sh
: 1620777591:0;vim run_glue.sh
: 1620777603:0;sh run_glue.sh
: 1620777618:0;nvidia-smi 
: 1620777622:0;vim run_glue.sh
: 1620777636:0;nvidia-smi 
: 1620777639:0;sh run_glue.sh
: 1620777655:0;htop
: 1620777667:0;nvidia-smi 
: 1620777834:0;vim run_glue.sh
: 1620777855:0;nvidia-smi 
: 1620777860:0;vim run_glue.sh
: 1620777877:0;sh run_glue.sh
: 1620780898:0;nvidia-smi 
: 1620780906:0;tad gen
: 1620827593:0;cd transformers-importance-sampling/
: 1620827599:0;vim train_test_overlap.py
: 1620827625:0;ls ../data/glue_data/MNLI
: 1620827630:0;vim train_test_overlap.py
: 1620827797:0;cd transformers-importance-sampling/
: 1620827799:0;vim train_test_overlap.py
: 1620827901:0;nvidia-smi 
: 1620827918:0;CUDA_VISIBLE_DEVICES=1 p3 train_test_overlap.py
: 1620828115:0;nvidia-smi 
: 1620841605:0;vim train_test_overlap.py
: 1620841707:0;p3 train_test_overlap.py
: 1620842806:0;vim train_test_overlap.py
: 1620842858:0;p3 train_test_overlap.py
: 1620842862:0;vim train_test_overlap.py
: 1620842943:0;p3 train_test_overlap.py
: 1620842947:0;vim train_test_overlap.py
: 1620842993:0;p3 train_test_overlap.py
: 1620843086:0;nvidia-smi 
: 1620843091:0;vim train_test_overlap.py
: 1620843123:0;p3 train_test_overlap.py
: 1620843972:0;vim train_test_overlap.py
: 1620843987:0;p3 train_test_overlap.py
: 1620844249:0;vim train_test_overlap.py
: 1620844269:0;p3 train_test_overlap.py
: 1620844368:0;vim train_test_overlap.py
: 1620844378:0;vim nbs/train_test_overlap
: 1620844382:0;vim nbs/train_test_overlap.ipynb
: 1620844398:0;vim nbs/train_test_overlap_utils.py
: 1620844486:0;vim train_test_overlap.py
: 1620844503:0;p3 train_test_overlap.py
: 1620844580:0;vim nbs/train_test_overlap_utils.py
: 1620844617:0;p3 train_test_overlap.py
: 1620844778:0;vim nbs/train_test_overlap_utils.py
: 1620844790:0;vim train_test_overlap.py
: 1620844850:0;p3 train_test_overlap.py
: 1620844991:0;vim train_test_overlap.py
: 1620845004:0;vim nbs/train_test_overlap_utils.py
: 1620845025:0;vim train_test_overlap.py
: 1620845057:0;p3 train_test_overlap.py
: 1620845062:0;vim train_test_overlap.py
: 1620845074:0;p3 train_test_overlap.py
: 1620845332:0;vim train_test_overlap.py
: 1620845447:0;p3 train_test_overlap.py
: 1620845600:0;vim train_test_overlap.py
: 1620845699:0;vim nbs/train_test_overlap_utils.py
: 1620845788:0;p3 train_test_overlap.py
: 1620845909:0;vim train_test_overlap.py
: 1620846161:0;vim nbs/train_test_overlap_utils.py
: 1620846208:0;vim train_test_overlap.py
: 1620846391:0;p3 train_test_overlap.py
: 1620846418:0;vim train_test_overlap.py
: 1620846438:0;p3 train_test_overlap.py
: 1620846634:0;tl
: 1620846637:0;tad cs3
: 1620846639:0;cd ~
: 1620846641:0;cd transformers-importance-sampling/
: 1620846644:0;p3 train_test_overlap.py
: 1620846994:0;tad cs3
: 1621006385:0;tad css3
: 1621006387:0;tad cs3
: 1621006395:0;tad gen
: 1621006404:0;tad gen_2
: 1621006420:0;tad cs1
: 1621006425:0;tad cs2
: 1621006521:0;ls experiments/train_test_overlap
: 1621008760:0;cd apex/commonsense-discourse/data
: 1621008761:0;ls
: 1621008842:0;cd ../training
: 1621008844:0;ls
: 1621008857:0;tad gen_2
: 1621008860:0;ls
: 1621008865:0;cd ..
: 1621008868:0;cd data
: 1621008868:0;ls
: 1621008877:0;vim gen_train_0_50_op_1.json
: 1621008920:0;vim gen_train_50_100_op_1.json
: 1621008937:0;vim gen_train_50_100_op_0.json
: 1621008970:0;cd ../discosense
: 1621008973:0;vim generate_ds_1.sh
: 1621008993:0;vim generate_dataset.py
: 1621009070:0;vim generate.py
: 1621009204:0;vim generate_dataset.py
: 1621009294:0;vim ../data/gen_train_50_100_op_0.json
: 1621009304:0;vim ../data/gen_train_50_100_op_1.json
: 1621009336:0;vim generate_dataset.py
: 1621009361:0;vim generate_ds_1.sh
: 1621009381:0;vim config.py
: 1621009429:0;vim ../data/gen_train_50_100_op_1.json
: 1621009524:0;cd ..
: 1621009527:0;cd data
: 1621009528:0;ls
: 1621009534:0;vim gen_train_0_50_op_1.json
: 1621009554:0;vim gen_train_0_50_op_0.json
: 1621009571:0;vim gen_train_0_50_op_1.json
: 1621009589:0;vim gen_train_0_50_op_0.json
: 1621009707:0;cd ../discosense
: 1621009710:0;vim config.py
: 1621009731:0;sh generate_ds_1.sh
: 1621009919:0;vim generate_dataset.py
: 1621009979:0;sh generate_ds_1.sh
: 1621010198:0;vim generate_dataset.py
: 1621010393:0;sh generate_ds_1.sh
: 1621010486:0;vim generate_dataset.py
: 1621010561:0;sh generate_ds_1.sh
: 1621010651:0;vim generate_dataset.py
: 1621010675:0;sh generate_ds_1.sh
: 1621010759:0;vim generate_dataset.py
: 1621011272:0;sh generate_ds_1.sh
: 1621011402:0;vim generate_dataset.py
: 1621011416:0;sh generate_ds_1.sh
: 1621011510:0;vim generate_dataset.py
: 1621011654:0;sh generate_ds_1.sh
: 1621011875:0;vim generate_dataset.py
: 1621011967:0;sh generate_ds_1.sh
: 1621011990:0;vim config.py
: 1621012005:0;sh generate_ds_1.sh
: 1621012106:0;vim config.py
: 1621012117:0;vim generate_dataset.py
: 1621012280:0;vim config.py
: 1621012285:0;sh generate_ds_1.sh
: 1621012422:0;tad gen_2
: 1621012432:0;tad gen
: 1621012439:0;sh generate_ds_0.sh
: 1621012545:0;vim ../data/gen_train_50_100_op_1.json
: 1621012557:0;cd ..
: 1621012560:0;cd data
: 1621012561:0;ls
: 1621012563:0;cd ~
: 1621012569:0;cd prajjwal1/commonsense-discourse
: 1621012571:0;cd data
: 1621012576:0;vim gen_train_0_50_op_0.json
: 1621020805:0;tad gen
: 1621182538:0;nvidia-smi 
: 1621182544:0;tad gen
: 1621182615:0;tad gen_2
: 1621182663:0;cd apex/experiment
: 1621182665:0;ls
: 1621182722:0;cd ctrl_discovery_9
: 1621182723:0;ls
: 1621182727:0;rm -r checkpoint-80000
: 1621182757:0;ls
: 1621182762:0;rm eval_results_clm.txt
: 1621182770:0;rm train*
: 1621182771:0;ls
: 1621182775:0;export PATH=/home/nlp/tools/bin:$PATH
: 1621182778:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_9
: 1621182798:0;mv * ctrl_discovery_9
: 1621182800:0;ls
: 1621182802:0;cd ctrl_discovery_9
: 1621182806:0;git add .
: 1621182871:0;ls
: 1621182878:0;git commit -m "v1"
: 1621182913:0;git push
: 1621183272:0;transformers-cli lfs-enable-largefiles .
: 1621183278:0;git push
: 1621183957:0;cd ..
: 1621183962:0;ls
: 1621183966:0;cd ctrl_discovery_10
: 1621184019:0;ls
: 1621184028:0;rm -r checkpoint-80000
: 1621184040:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_10
: 1621184064:0;ls
: 1621184072:0;rm eval_results_clm.txt
: 1621184079:0;rm train*
: 1621184082:0;ls
: 1621184086:0;mv * ctrl_discovery_10
: 1621184089:0;cd ctrl_discovery_10
: 1621184090:0;ls
: 1621184094:0;git add .
: 1621184174:0;git commit -m "v1"
: 1621184178:0;transformers-cli lfs-enable-largefiles .
: 1621184185:0;git psh
: 1621184188:0;git push
: 1621184815:0;cd ..
: 1621184823:0;cd ctrl_discovery_11
: 1621184825:0;ls
: 1621184833:0;rm checkpoint-80000
: 1621184838:0;rm -rf checkpoint-80000
: 1621184845:0;rm train*
: 1621184860:0;rm eval_results_clm.txt
: 1621184862:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_11
: 1621184876:0;mv * ctrl_discovery_11
: 1621184878:0;ls
: 1621184880:0;cd ctrl_discovery_11
: 1621184882:0;transformers-cli lfs-enable-largefiles .
: 1621184888:0;git add .
: 1621184961:0;git commit -m "v1"
: 1621184965:0;git push
: 1621207190:0;cd ~
: 1621207197:0;cd prajjwal1/commonsense-discourse
: 1621207199:0;ls
: 1621207202:0;cd discosense
: 1621207202:0;ls
: 1621207220:0;cp generate_ds_0.sh generate_valid_0.sh
: 1621207238:0;rm generate_valid.sh
: 1621207243:0;vim generate_valid_0.sh
: 1621207451:0;vim generate_dataset.py
: 1621207490:0;vim ../data/raw_valid.json
: 1621207501:0;vim generate_dataset.py
: 1621207570:0;vim generate_valid_0.sh
: 1621207579:0;sh generate_valid_0.sh
: 1621207588:0;tad cs
: 1621207592:0;cd ~
: 1621207597:0;cd prajjwal1/commonsense-discourse/discosense
: 1621207603:0;sh generate_valid_0.sh
: 1621208252:0;vim generate_valid_0.sh
: 1621208286:0;sh generate_valid_0.sh
: 1621208292:0;vim generate_valid_0.sh
: 1621208308:0;sh generate_valid_0.sh
: 1621208411:0;vim generate_dataset.py
: 1621208523:0;sh generate_valid_0.sh
: 1621208528:0;vim generate_valid_0.sh
: 1621208547:0;sh generate_valid_0.sh
: 1621208654:0;vim generate_dataset.py
: 1621208696:0;sh generate_valid_0.sh
: 1621208785:0;vim generate_dataset.py
: 1621208856:0;sh generate_valid_0.sh
: 1621208961:0;vim generate_dataset.py
: 1621208973:0;ls
: 1621208979:0;git status
: 1621208982:0;git add config.py
: 1621208987:0;git add generate_dataset.py
: 1621208993:0;git add generate_ds.sh
: 1621208996:0;git add generate_valid.sh
: 1621209009:0;git commit -m "more flexibility"
: 1621209017:0;git push
: 1621209035:0;sh generate_valid_0.sh
: 1621209593:0;ls
: 1621209604:0;cp generate_valid_0.sh generate_valid_1.sh
: 1621209610:0;vim generate_valid_1.sh
: 1621209670:0;sh generate_valid_1.sh
: 1621209676:0;tad cs2
: 1621209679:0;cd ~
: 1621209682:0;cd prajjwal1/commonsense-discourse/discosense
: 1621209684:0;sh generate_valid_1.sh
: 1621213729:0;tad cs2
: 1621216672:0;vim generate_valid_1.sh
: 1621216694:0;vim generate_valid_0.sh
: 1621216699:0;tad cs2
: 1621269643:0;cd prajjwal1/commonsense-discourse/discosense
: 1621269647:0;tad cs2
: 1621269657:0;vim generate_valid_1.sh
: 1621269713:0;sh generate_valid_1.sh
: 1621269726:0;tad cs
: 1621269734:0;vim generate_valid_0.sh
: 1621269810:0;sh generate_valid_0.sh
: 1621269813:0;tad cs2
: 1621269860:0;tad gen
: 1621269873:0;vim generate_ds_0.sh
: 1621269912:0;sh generate_ds_0.sh
: 1621269932:0;tad gen_2
: 1621269939:0;vim generate_ds_1.sh
: 1621270021:0;sh generate_ds_1.sh
: 1621270029:0;tad cs2
: 1621270103:0;tad cs
: 1621270109:0;sh generate_valid_0.sh
: 1621270112:0;tad cs2
: 1621270127:0;tad cs
: 1621270146:0;tad gen_2
: 1621270150:0;tad gen
: 1621270162:0;vim ../data/gen_train_50_100_op_1.json
: 1621272794:0;tad gen
: 1621272811:0;tad gen_2
: 1621272832:0;tad cs
: 1621272842:0;tad cs2
: 1621273790:0;nvidia-smi 
: 1621276989:0;ls
: 1621276995:0;cd ~
: 1621276998:0;cd transformers-importance-sampling/
: 1621276999:0;ls
: 1621277002:0;git status
: 1621277008:0;git add get_heuristic_stats.py
: 1621277013:0;git add run_glue.sh
: 1621277035:0;git add train_test_overlap.py
: 1621277049:0;git add nbs/train_test_overlap.ipynb
: 1621277057:0;git add nbs/train_test_overlap_utils.py
: 1621277061:0;git status
: 1621277081:0;git commit -m "overlap"
: 1621277085:0;git push
: 1621277098:0;git push origin new
: 1621277111:0;export PATH=/home/nlp/tools/bin:$PATH
: 1621277113:0;git push origin new
: 1621277602:0;cd ../prajjwal1
: 1621277603:0;ls
: 1621277605:0;cd commonsense-discourse
: 1621277608:0;git status
: 1621277616:0;git add data/
: 1621277623:0;git status
: 1621277651:0;git commit -m "backup data"
: 1621277655:0;git push
: 1621294323:0;tl
: 1621294327:0;tad gen
: 1621294336:0;tad cs2
: 1621294340:0;tad cs
: 1621302992:35;vim generate_valid_0.sh
: 1621303028:0;sh generate_valid_0.sh
: 1621303041:0;tad cs2
: 1621303058:0;tad cs3
: 1621303071:0;tad cs2
: 1621303080:0;ls
: 1621303085:0;tad cs
: 1621303899:0;tad cs2
: 1621303914:0;htop
: 1621304033:0;vim generate_valid_1.sh
: 1621304100:0;vim ../data/gen_train_50_100_op_1.json
: 1621304116:0;vim generate_valid_1.sh
: 1621304165:0;sh generate_valid_1.sh
: 1621357249:0;nvidia-smi 
: 1621357257:0;tad gen
: 1621357284:0;tad cs
: 1621357297:0;tad cs3
: 1621357303:0;tad cs2
: 1621357305:0;ls
: 1621357335:0;git status
: 1621357349:0;git add ../data/gen_valid_0_50_op_1.json
: 1621357356:0;git add ../data/gen_valid_0_50_op_2.json
: 1621357361:0;git add ../data/gen_valid_0_50_op_1.json
: 1621357371:0;git add ../data/gen_valid_50_100_op_2.json
: 1621357375:0;git add ../data/gen_valid_50_100_op_1.json
: 1621357379:0;git status
: 1621357405:0;git add .
: 1621357409:0;git commit -m "backup data"
: 1621357413:0;git push
: 1621357598:0;tad cs2
: 1621357605:0;tad gen
: 1621441362:0;nvidia-smi 
: 1621442089:0;tad gen
: 1621525381:0;tad gen2
: 1621525385:0;tad gen_2
: 1621525393:0;cd ..
: 1621525395:0;git status
: 1621525403:0;git add data/gen_train_0_50_op_2.json
: 1621525410:0;git add data/gen_train_50_100_op_2.json
: 1621525427:0;cd discosense
: 1621525427:0;ls
: 1621525437:0;git add generate_ds_0.sh
: 1621525444:0;git add -f generate_ds_0.sh
: 1621525456:0;git commit -m "data gen complete"
: 1621525464:0;git push
: 1621528028:0;nvidia-smi 
: 1621528034:0;cd apex/experiment
: 1621528038:0;cd ..
: 1621528041:0;cd commonsense-discourse/training
: 1621528042:0;ls
: 1621528046:0;vim generate_ds.sh
: 1621528053:0;vim train_model.sh
: 1621528077:0;tad cs
: 1621528079:0;ls
: 1621528082:0;cd ..
: 1621528083:0;cd ~
: 1621528088:0;cd apex/commonsense-discourse/training
: 1621528091:0;sh train_model.sh
: 1622036382:0;cd apex/commonsense-discourse/training
: 1622036384:0;vim train_model.sh
: 1622036404:0;cd ..
: 1622036408:0;ls
: 1622036413:0;cd experiment
: 1622036414:0;ls
: 1622036427:0;nvidia-smi 
: 1622036434:0;cd ../
: 1622036435:0;ls
: 1622036440:0;cd ..
: 1622036570:0;ls
: 1622036573:0;cd anna
: 1622036574:0;ls
: 1622036578:0;cd ../nlp
: 1622036581:0;cd transformers-importance-sampling/
: 1622036582:0;cd hans
: 1622036604:0;ls
: 1622036612:0;mkdir backup
: 1622036619:0;mv run_hans.py backup
: 1622036624:0;mv utils_hans.py backup
: 1622039575:0;wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/research_projects/adversarial/run_hans.py run_hans.py
: 1622039587:0;vim run_hans.py
: 1622039622:0;wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/research_projects/adversarial/utils_hans.py utils_hans.py
: 1622039638:0;vim utils_hans.py
: 1622039645:0;cd ..
: 1622039648:0;cd hans
: 1622039690:0;ls ../../experiments/big_small/bert_base/epoch_4
: 1622039754:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622039775:0;cd ~
: 1622039783:0;cd transformers
: 1622039785:0;git pull
: 1622039986:0;pip3 install --user git+https://github.com/huggingface/transformers
: 1622040153:0;cd ~
: 1622040160:0;cd transformers-importance-sampling/hans
: 1622040164:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040190:0;python3
: 1622040221:0;ls
: 1622040231:0;mv transformers backup
: 1622040235:0;python3
: 1622040245:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040364:0;pip3 install --user git+https://github.com/huggingface/tokenizers
: 1622040382:0;pip3 install --user tokenizers --upgrade
: 1622040394:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040412:0;vim run_hans.py
: 1622040443:0;vim utils_hans.py
: 1622040476:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040524:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040640:0;mv backup/transformers .
: 1622040642:0;ls
: 1622040646:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040670:0;vim run_hans.py
: 1622040709:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040783:0;cd data/glue_data/hans
: 1622040808:0;vim run_hans.py
: 1622040821:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small/bert_base/epoch_4 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small/bert_base/epoch_4 --tokenizer_name bert-base-uncased
: 1622040825:0;python3 evaluate_heur_output.py ~/experiments/big_small/bert_base/epoch_4/hans_predictions.txt
: 1622040997:0;cd ..
: 1622041017:0;cd glue_data/hans
: 1622041022:0;cd ..
: 1622041023:0;ls
: 1622041138:0;wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/text-classification/run_glue.py new_run_glue.py
: 1622041166:0;ls
: 1622041168:0;cd ~
: 1622041171:0;cd apex/commonsense-discourse/training
: 1622041175:0;vim train_model.sh
: 1622041245:0;sh train_model.sh
: 1622041660:0;python3 evaluate_heur_output.py ~/experiments/big_small/roberta_large/epoch_4/hans_predictions.txt
: 1622041735:0;cd ~
: 1622041739:0;cd transformers-importance-sampling/hans
: 1622041741:0;cd ..
: 1622041833:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 4 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 4 \\
  --output_dir /home/nlp/experiments/big_small_again \\
--load_best_model_at_end
: 1622041845:0;export TASK_NAME=mnli
: 1622041847:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 4 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 4 \\
  --output_dir /home/nlp/experiments/big_small_again \\
--load_best_model_at_end
: 1622041874:0;nvidia-smi 
: 1622041911:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 4 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 4 \\
  --output_dir /home/nlp/experiments/big_small_again \\
--load_best_model_at_end \\
--fp16
: 1622042044:0;python3 new_run_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 4 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 4 \\
  --output_dir /home/nlp/experiments/big_small_again/bert_base/ \\
--load_best_model_at_end \\
--fp16
: 1622042114:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 4 \\
  --output_dir /home/nlp/experiments/big_small_again/bert_base/ \\
--load_best_model_at_end \\
--fp16
: 1622042189:0;CUDA_VISIBLE_DEVICES=1 python3 new_run_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 90 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 4 \\
  --output_dir /home/nlp/experiments/big_small_again/bert_base/ \\
--load_best_model_at_end \\
--fp16
: 1622054995:0;tad gen
: 1622054997:0;tl
: 1622055003:0;ts gen
: 1622055007:0;sh train_model.sh
: 1622055021:0;cd ..
: 1622055025:0;cd experiment
: 1622055026:0;ls
: 1622055034:0;cd ctrl_discovery_12
: 1622055035:0;ls
: 1622055038:0;rm -rf checkpoint-80000
: 1622055045:0;rm eval_results_clm.txt
: 1622055050:0;rm train*
: 1622055051:0;ls
: 1622055076:0;git lfs install\
git clone https://huggingface.co/prajjwal1/ctrl_discovery_12
: 1622055086:0;export PATH=/home/nlp/tools/bin:$PATH
: 1622055091:0;git lfs install\
git clone https://huggingface.co/prajjwal1/ctrl_discovery_12
: 1622055097:0;mv * ctrl_discovery_12
: 1622055100:0;cd ctrl_discovery_12
: 1622055100:0;ls
: 1622055103:0;git add .
: 1622055200:0;git commit -m v1"
: 1622055203:0;git commit -m "v1"
: 1622055206:0;git push
: 1622055225:0;transformers-cli lfs-enable-largefiles .
: 1622055244:0;git push
: 1622055619:0;nvidia-smi 
: 1622055629:0;cd hans
: 1622055674:0;python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small_again/bert_base/ --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small_again/bert_base --tokenizer_name bert-base-uncased
: 1622055699:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path /home/nlp/experiments/big_small_again/bert_base/ --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 1024 --output_dir=/home/nlp/experiments/big_small_again/bert_base --tokenizer_name bert-base-uncased
: 1622055897:0;cd data/glue_data/hans
: 1622055926:0;python3 evaluate_heur_output.py ~/experiments/big_small_again/bert_base/hans_predictions.txt
: 1622137997:0;nvidia-smi 
: 1622137999:0;tl
: 1622138001:0;tad gen
: 1622138008:0;cd prajjwal1/commonsense-discourse/discosense
: 1622138010:0;cd ~
: 1622138033:0;cp apex/commonsense-discourse/training/train_model.sh prajjwal1/commonsense-discourse/discosense
: 1622138038:0;cd prajjwal1/commonsense-discourse/discosense
: 1622138117:0;git pull
: 1622138145:0;git stash
: 1622138149:0;git pull
: 1622138182:0;cp apex/commonsense-discourse/training/train_model.sh .
: 1622138190:0;cp ~/apex/commonsense-discourse/training/train_model.sh .
: 1622138194:0;git add .
: 1622138197:0;git status
: 1622138204:0;git commit -m "added training script"
: 1622138208:0;git push
: 1622216371:0;nvidia-smi 
: 1622216378:0;tad cs
: 1622216382:0;tl
: 1622216384:0;tad gen
: 1622343884:0;vim train_model.sh
: 1622343945:0;sh train_model.sh
: 1622479289:0;tad gen
: 1622479298:0;vim train_model.sh
: 1622479315:0;sh train_model.sh
: 1622479644:0;tad gen
: 1622758552:0;vim train_model.sh
: 1622758618:0;sh train_model.sh
: 1622758627:0;cd apex/experiment
: 1622758629:0;ls
: 1622758640:0;rm -rf ctrl_discovery_1
: 1622758716:0;cd ctrl_discovery_13
: 1622758717:0;ls
: 1622758720:0;rm -rf checkpoint-80000
: 1622758727:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_13
: 1622758734:0;ls
: 1622758743:0;rm eval_results_clm.txt
: 1622758747:0;rm train*
: 1622758750:0;ls
: 1622758756:0;mv * ctrl_discovery_13
: 1622758758:0;cd ctrl_discovery_13
: 1622758761:0;export PATH=/home/nlp/tools/bin:$PATH
: 1622758762:0;transformers-cli lfs-enable-largefiles .
: 1622758768:0;git add .
: 1622758852:0;git commit -m "v1"
: 1622758856:0;tad gen
: 1622758871:0;git push
: 1622778780:0;cd transformers-importance-sampling/hans
: 1622779016:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path blackbird/alberta-base-mnli-v1 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 16 --output_dir=/home/nlp/experiments/sasha/alberta-base-mnli-v1 --tokenizer_name roberta-base
: 1622779157:0;ls
: 1622779162:0;cd bb
: 1622779165:0;ls
: 1622779179:0;mkdir alberta-base-mnli-v1
: 1622779182:0;cd alberta-base-mnli-v1
: 1622779238:0;git lfs install\
git clone https://huggingface.co/blackbird/alberta-base-mnli-v1
: 1622779246:0;export PATH=/home/nlp/tools/bin:$PATH
: 1622779247:0;git lfs install\
git clone https://huggingface.co/blackbird/alberta-base-mnli-v1
: 1622779269:0;ls
: 1622779278:0;mv alberta-base-mnli-v1 .
: 1622779284:0;mv alberta-base-mnli-v1 l
: 1622779287:0;mv l ..
: 1622779289:0;cd ..
: 1622779289:0;ls
: 1622779292:0;rm alberta-base-mnli-v1
: 1622779297:0;rm -r alberta-base-mnli-v1
: 1622779308:0;mv l alberta-base-mnli-v1
: 1622779309:0;ls
: 1622779311:0;cd ..
: 1622779375:0;CUDA_VISIBLE_DEVICES=1 python3 run_hans.py --model_name_or_path bb/alberta-base-mnli-v1 --task_name hans --do_eval --data_dir=/home/nlp/data/glue_data/hans --max_seq_length 128 --per_device_eval_batch_size 16 --output_dir=/home/nlp/transformers-importance-sampling/hans/bb/alberta-base-mnli-v1
: 1622779563:0;cd ~
: 1622779565:0;cd data/glue_data/hans
: 1622779566:0;ls
: 1622779595:0;python3 evaluate_heur_output.py ~/transformers-importance-sampling/hans/bb/alberta-base-mnli-v1/hans_predictions.txt
: 1622780101:0;cd ~/transformers-importance-sampling/hans
: 1622780106:0;stat run_hans.py
: 1622780162:0;cd ~/data/glue_data/hans
: 1622780181:0;python3 evaluate_heur_output.py ~/experiments/big_small/albert_large/ha
: 1622780189:0;python3 evaluate_heur_output.py ~/experiments/big_small/albert_large/epoch_4/hans_predictions.txt
: 1622780214:0;python3 evaluate_heur_output.py ~/experiments/big_small/bert_large/epoch_4/hans_predictions.txt
: 1622912658:0;nvidia-smi 
: 1622912665:0;tad gen
: 1623003321:0;cd ~/apex/experiment
: 1623003322:0;ls
: 1623003392:0;rm -r ctrl_discovery_10 ctrl_discovery_11 ctrl_discovery_6 ctrl_discovery_7 ctrl_discovery_8 ctrl_discovery_9 ctrl_discovery_flipped_4 ctrl_discovery_flipped_3 ctrl_discovery_2 ctrl_discovery_1 ctrl_discovery_1
: 1623003419:0;rm -rf ctrl_discovery_10 ctrl_discovery_11 ctrl_discovery_6 ctrl_discovery_7 ctrl_discovery_8 ctrl_discovery_9 ctrl_discovery_flipped_4 ctrl_discovery_flipped_3 ctrl_discovery_2 ctrl_discovery_1 ctrl_discovery_1
: 1623004393:0;ls
: 1623004402:0;cd ..
: 1623004412:0;cd experiment/ctrl_discovery_flipped_6
: 1623004414:0;ls
: 1623004423:0;rm -rf checkpoint-80000
: 1623007264:0;export PATH=/home/nlp/tools/bin:$PATH
: 1623007268:0;git lfs install\
git clone https://huggingface.co/blackbird/alberta-base-mnli-v1
: 1623007275:0;git lfs install
: 1623007279:0;git clone https://huggingface.co/prajjwal1/ctrl_flipped_6
: 1623007362:0;ls
: 1623007373:0;cd ..
: 1623007380:0;ts cs
: 1623007398:0;ls
: 1623007443:0;rm -rf ctrl_discovery_12 ctrl_discovery_13 ctrl_discovery_4 ctrl_discovery_5 ctrl_discovery_flipped_5 roberta ctrl_discovery_3
: 1623007452:0;rm eval_results_clm.txt
: 1623007463:0;cd ctrl_discovery_6
: 1623007473:0;cd ctrl_discovery_flipped_6
: 1623007480:0;rm eval_results_clm.txt
: 1623007484:0;rm train*
: 1623007490:0;ls
: 1623007544:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_flipped_6
: 1623007699:0;rm -r ctrl_flipped_6
: 1623007809:0;rm -rf ctrl_flipped_6
: 1623007830:0;ls
: 1623007838:0;mv * ctrl_discovery_flipped_6
: 1623007843:0;cd ctrl_discovery_flipped_6
: 1623007847:0;git add .
: 1623007961:0;git commit -m "v1"
: 1623008916:0;git push
: 1623008957:0;transformers-cli lfs-enable-largefiles .
: 1623008976:0;git push
: 1623009799:0;tad gen
: 1623015663:0;cd ~
: 1623015669:0;cd apex/experiment
: 1623015670:0;ls
: 1623015698:0;cd ctrl_discovery_flipped_1
: 1623015700:0;cd ..
: 1623015711:0;cd ctrl_discovery_flipped_14
: 1623015759:0;tad cs
: 1623015762:0;ls
: 1623015771:0;rm -rf ctrl_discovery_flipped_*
: 1623015775:0;tad gen
: 1623015788:0;cd ../commonsense-discourse/training
: 1623015790:0;vim train_model.sh
: 1623015809:0;sh train_model.sh
: 1623015814:0;cd ..
: 1623015817:0;cd ~
: 1623015821:0;cd apex/experiment
: 1623015822:0;ls
: 1623015824:0;cd ctrl_discovery_14
: 1623015828:0;rm -rf checkpoint-80000
: 1623015845:0;git clone https://huggingface.co/prajjwal1/ctrl_discovery_14
: 1623015861:0;ls
: 1623015868:0;rm train*
: 1623015872:0;rm eval_results_clm.txt
: 1623015874:0;ls
: 1623015881:0;mv * ctrl_discovery_14
: 1623015883:0;ls
: 1623015885:0;cd ctrl_discovery_14
: 1623015887:0;git add .
: 1623016018:0;git commit -m "v1"
: 1623016041:0;git push
: 1623016083:0;transformers-cli lfs-enable-largefiles .
: 1623016092:0;git push
: 1623020109:0;tad gen
: 1623020118:0;nvidia-smi 
: 1625089867:0;cd transformers-importance-sampling/hans
: 1625089869:0;cd ..
: 1625089871:0;git status
: 1625089892:0;git add hans/run_hans.py
: 1625089898:0;git add hans/utils_hans.py
: 1625089910:0;git commit -m "update hans for double confirmation"
: 1625089914:0;git push
: 1625089937:0;rm .git/hooks/post-commit
: 1625089944:0;git push
: 1625089950:0;git push origin new
: 1625089979:0;rm .git/hooks/pre-push
: 1625089981:0;git push origin new
: 1625090009:0;tl
: 1625090015:0;jupyter notebook --no-browser --port=8888
: 1625165743:0;cd transformers-importance-sampling/hans
: 1625165748:0;cd ..
: 1625165761:0;jupyter notebook --no-browser --port=8888
: 1625171933:0;ts jupyter
: 1625171937:0;jupyter notebook --no-browser --port=8888
: 1625176411:0;cd transformers-importance-sampling/hans
: 1625176413:0;cd ..
: 1625176438:0;git add .
: 1625176445:0;git status
: 1625176460:0;rm -rf hans/bb
: 1625176472:0;git add nbs/graph_plots_paper.ipynb
: 1625176480:0;git commit -m "update graph"
: 1625176493:0;git push
: 1625176497:0;git push origin new
: 1627148051:0;nvidia-smi 
: 1627148063:0;reboot
: 1627148075:0;tl
: 1627148080:0;tad jupyter
: 1627148210:0;cd cartography
: 1627148244:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627148679:0;vim cartography/selection/train_dy_filtering.py
: 1627148773:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627148994:0;vim cartography/selection/train_dy_filtering.py
: 1627149041:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627149273:0;vim cartography/selection/train_dy_filtering.py
: 1627149319:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627149403:0;vim cartography/selection/train_dy_filtering.py
: 1627149422:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627149549:0;ls
: 1627149558:0;mkdir figures
: 1627149561:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627331535:0;cd cartography
: 1627331540:0;vim cartography/selection/train_dy_filtering.py
: 1627331594:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1627331966:0;vim cartography/selection/train_dy_filtering.py
: 1627331998:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628000154:0;cd cartography
: 1628000158:0;vim cartography/selection/train_dy_filtering.py
: 1628000335:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628000539:0;vim cartography/selection/train_dy_filtering.py
: 1628000919:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628001132:0;vim cartography/selection/train_dy_filtering.py
: 1628001220:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628001386:0;vim cartography/selection/train_dy_filtering.py
: 1628001412:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628001596:0;vim cartography/selection/train_dy_filtering.py
: 1628001678:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628001823:0;vim cartography/selection/train_dy_filtering.py
: 1628001883:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628002034:0;vim cartography/selection/train_dy_filtering.py
: 1628002408:0;cd cartography
: 1628002409:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628002561:0;cd cartography
: 1628002565:0;cd ..
: 1628002601:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628003192:0;vim cartography/selection/train_dy_filtering.py
: 1628003241:0;python3 -m cartography.selection.train_dy_filtering --plot --task_name MNLI --model_dir roberta_large --model roberta-large
: 1628085316:0;cd transformers-importance-sampling/hans
: 1628085318:0;cd ..
: 1628085322:0;git status
: 1628085332:0;git add check_hans.sh
: 1628085340:0;git add insert
: 1628085344:0;git add nbs
: 1628085375:0;git commit -m "updating changes"
: 1628085384:0;git push
: 1628085386:0;git push origin new
: 1628116163:0;p3
: 1628432606:0;cd transformers-importance-sampling/
: 1628432609:0;vim README.md
: 1628432638:0;git add .
: 1628432644:0;git status
: 1628432648:0;git add README.md
: 1628432662:0;rm hans/transformers
: 1628432666:0;rm -rf hans/transformers
: 1628432681:0;rm -rf hans/v3.3.0.zip
: 1628432686:0;rm -rf new_run_glue.py
: 1628432695:0;rm -rf run_glue.py.1
: 1628432699:0;git sttaus
: 1628432703:0;git status
: 1628432716:0;git commit -m "rm old venue"
: 1628432719:0;git push
: 1628432721:0;git push origin new
: 1628556569:0;cd apex/experiment
: 1628556570:0;ls
: 1628556574:0;cd gpt2_xl
: 1628556574:0;ls
: 1628556579:0;rm -rf checkpoint-100000
: 1628556618:0;export PATH=/home/nlp/tools/bin:$PATH
: 1628556622:0;git lfs install
: 1628556625:0;git clone https://huggingface.co/prajjwal1/gpt_xl_discovery
: 1628556634:0;mv * gpt_xl_discovery
: 1628556637:0;cd gpt_xl_discovery
: 1628556645:0;transformers-cli lfs-enable-largefiles .
: 1628556655:0;git add .
: 1628556811:0;git commit -m "v1"
: 1628556825:0;git push
: 1628557057:0;ls
: 1628557252:0;git push
: 1628557263:0;ls
: 1628557269:0;cd ..
: 1628557282:0;ls
: 1628557285:0;\
git clone https://huggingface.co/prajjwal1/gpt2_xl_discovery
: 1628557291:0;ls
: 1628557300:0;mv gpt_xl_discovery/* gpt2_xl_discovery
: 1628557302:0;ls
: 1628557307:0;cd gpt2_xl_discovery
: 1628557307:0;ls
: 1628557315:0;transformers-cli lfs-enable-largefiles .
: 1628557321:0;git lfs install
: 1628557326:0;git add .
: 1628557406:0;git commit -m "v1"
: 1628557409:0;git push
: 1628627553:0;cd cartography
: 1628627553:0;ls
: 1628730667:0;nvidia-smi 
: 1628730702:0;tl
: 1628730706:0;ts jupyter
: 1628730710:0;jupyter notebook --no-browser --port=8888
: 1628730744:0;pip3 install -U adapter-transformers
: 1628732144:0;pip3 install wandb
: 1628732794:0;nvidia-smi 
: 1628798584:0;cd transformers-importance-sampling/
: 1628798591:0;vim adapter_glue.py
: 1628798636:0;export TASK_NAME=mnli
: 1628798675:0;python3 run_glue_alt.py \\
  --model_name_or_path roberta_large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628798688:0;python3 adapter_glue.py \\
  --model_name_or_path roberta_large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628798706:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628798804:0;vim adapter_glue.py
: 1628798863:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628798973:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628798992:0;python3 adapter_glue.py \\
  --num_train_epochs 12 \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 128 \\
  --per_device_train_batch_size 32 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628799951:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 1024 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628800054:0;nvidia-smi 
: 1628800067:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 1024 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628800238:0;nvidia-smi 
: 1628800249:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 1024 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628800642:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628802511:0;nvidia-smi 
: 1628802516:0;cd transformers-importance-sampling/
: 1628802520:0;ts code
: 1628802527:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628802533:0;export TASK_NAME=mnli
: 1628802534:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628804245:0;tad code
: 1628804306:0;ls ../experiments/adapter_less_data
: 1628804313:0;ls ../experiments/adapter_less_data/mnli
: 1628805986:0;vim adapter_glue.py
: 1628806055:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 30.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628807881:0;ls ../experiments/adapter_less_data/mnli
: 1628807934:0;ls -l ../experiments/adapter_less_data/mnli
: 1628808231:0;ls ../experiments/adapter_less_data/mnli
: 1628808267:0;ls ../experiments/adapter_less_data/
: 1628808780:0;vim adapter_glue.py
: 1628808817:0;rm ../experiments/adapter_less_data/pytorch_model.bin
: 1628808825:0;rm ../experiments/adapter_less_data/mnli/pytorch_model_head.bin
: 1628808840:0;rm ../experiments/adapter_less_data/mnli/pytorch_adapter.bin
: 1628808857:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --train_adapter \\
  --adapter_config pfeiffer
: 1628810685:0;tad code
: 1628810693:0;ls ../experiments/adapter_less_data/
: 1628810700:0;ls ../experiments/adapter_less_data/mnli
: 1628880157:0;tad code
: 1628880218:0;ls ../experiments/adapter_less_data/mnli
: 1628880225:0;ls ../experiments/adapter_less_data/
: 1628883795:0;cd transformers-importance-sampling/
: 1628883874:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628883884:0;export TASK_NAME=mnli
: 1628883886:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --overwrite_output_dir \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628884172:0;tad code
: 1628884188:0;ls ../experiments/adapter_less_data/
: 1628884319:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --overwrite_output_dir \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628887001:0;vim adapter_glue.py
: 1628887084:0;cp adapter_glue.py adapter_hans.py
: 1628887097:0;mv adapter_hans.py hans
: 1628887100:0;cd hans
: 1628887100:0;ls
: 1628887133:0;vim adapter_hans.py
: 1628887158:0;vim adapter_utils_hans.py
: 1628887184:0;vim adapter_hans.py
: 1628887563:0;cd transformers-importance-sampling/hans
: 1628887771:0;tad code
: 1628887852:0;cd hans
: 1628887854:0;vim adapter_hans.py
: 1628887910:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628887912:0;ls
: 1628887926:0;mv adapter_hans.py adapter_run_hans.py
: 1628887929:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628887956:0;ls
: 1628887961:0;rm adapter_hans.py
: 1628887964:0;vim adapter_run_hans.py
: 1628887976:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888034:0;export TASK_NAME=hans
: 1628888036:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888077:0;export TASK_NAME=hans
: 1628888079:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888166:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --data_dir /home/nlp/data/glue_data/hans/ \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888205:0;vim adapter_run_hans.py
: 1628888255:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --data_dir /home/nlp/data/glue_data/hans/ \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888272:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888306:0;vim adapter_utils_hans.py
: 1628888354:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888377:0;vim adapter_utils_hans.py
: 1628888394:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628888447:0;vim adapter_run_hans.py
: 1628888472:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1628889159:0;ls ../experiments/adapter_less_data/
: 1628889166:0;ls ../../experiments/adapter_less_data/
: 1628889174:0;cd ~/data/glue_data/hans
: 1628889176:0;ls
: 1628889201:0;p3 evaluate_heur_output.py ~/experiments/adapter_less_data/hans_predictions.txt
: 1628889653:0;cd ..
: 1628889656:0;git status
: 1628889660:0;git add adapter_glue.py
: 1628889675:0;git add hans/adapter_run_hans.py
: 1628889684:0;git add hans/adapter_utils_hans.py
: 1628889697:0;git add nbs/adapter_less_data.ipynb
: 1628889703:0;git commit -m "new adapter code"
: 1628889707:0;git push
: 1628889710:0;git push origin new
: 1628889740:0;git status
: 1628889749:0;ls hans/backup
: 1629055489:0;cd transformers-importance-sampling/
: 1629055494:0;ls
: 1629055510:0;vim train_clustering.py
: 1629055586:0;cd transformers-importance-sampling/
: 1629055596:0;cp adapter_glue.py adapter_diverse_glue.py
: 1629055656:0;vim adapter_diverse_glue.py
: 1629055984:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629055993:0;export TASK_NAME=MNLI
: 1629055994:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629056005:0;vim adapter_diverse_glue.py
: 1629056016:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629056219:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629057415:0;nvidia-smi 
: 1629057419:0;cd transformers-importance-sampling/
: 1629057423:0;tad code
: 1629057429:0;ts code
: 1629057434:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629057444:0;export TASK_NAME=MNLI
: 1629057446:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629076218:0;cd transformers-importance-sampling/
: 1629076219:0;cd hans
: 1629076227:0;ls
: 1629076256:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629076263:0;export TASK_NAME=hans
: 1629076264:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629076458:0;vim utils_hans.py
: 1629076604:0;tad code
: 1629076619:0;cd hans
: 1629076622:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629076693:0;export TASK_NAME=hans
: 1629076696:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629076871:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1629076886:0;cd data/glue_data/hans
: 1629076897:0;p3 evaluate_heur_output.py ~/experiments/adapter_diverse_less_data/hans_predictions.txt
: 1629077024:0;p3 evaluate_heur_output.py ~/experiments/adapter_less_data/hans_predictions.txt
: 1629077052:0;vim utils_hans.py
: 1629077097:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629077882:0;p3 evaluate_heur_output.py ~/experiments/adapter_diverse_less_data/hans_predictions.txt
: 1629077909:0;vim utils_hans.py
: 1629077997:0;p3 evaluate_heur_output.py ~/experiments/adapter_less_data/hans_predictions.txt
: 1629078190:0;vim ~/experiments/adapter_less_data/hans_predictions.txt
: 1629078286:0;cp ~/experiments/adapter_less_data/hans_predictions.txt k1.txt
: 1629078303:0;vim adapter_utils_hans.py
: 1629078359:0;vim utils_
: 1629078364:0;vim utils_hans.py
: 1629078405:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli
: 1629078562:0;p3 evaluate_heur_output.py ~/experiments/adapter_less_data/hans_predictions.txt
: 1629078623:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629078775:0;p3 evaluate_heur_output.py ~/experiments/adapter_diverse_less_data/hans_predictions.txt
: 1629078880:0;cd ..
: 1629078881:0;ls
: 1629078895:0;vim adapter_glue.py
: 1629078906:0;vim adapter_diverse_glue.py
: 1629078981:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629079007:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629079045:0;export TASK_NAME=mnli
: 1629079047:0;python3 adapter_diverse_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --overwrite_output_dir \\
  --train_adapter
: 1629084905:0;tad code
: 1629084910:0;cd hans
: 1629084923:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629084956:0;export TASK_NAME=mnli
: 1629084961:0;export TASK_NAME=hans
: 1629084964:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_diverse_less_data \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_diverse_less_data/mnli
: 1629085123:0;cd ~/data/glue_data/hans
: 1629085126:0;p3 evaluate_heur_output.py ~/experiments/adapter_diverse_less_data/hans_predictions.txt
: 1629121425:0;cd transformers-importance-sampling/
: 1629121602:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --overwrite_output_dir \\
  --load_adapter nli/multinli@ukp
: 1629121611:0;export TASK_NAME=MNLI
: 1629121613:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --overwrite_output_dir \\
  --load_adapter nli/multinli@ukp
: 1629121774:0;vim adapter_glue.py
: 1629122191:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 512 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --overwrite_output_dir
: 1629122229:0;nvvidia-smi 
: 1629122239:0;nvidia-smi 
: 1629122253:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 512 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --overwrite_output_dir
: 1629122334:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir \\
  --load_adapter nli/multinli@ukp
: 1629122351:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir \\
  --load_adapter nli/multinli@ukp
: 1629122356:0;tad code
: 1629122358:0;cd ..
: 1629122368:0;cd ~/transformers-importance-sampling/
: 1629122379:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir \\
  --load_adapter nli/multinli@ukp
: 1629122391:0;export TASK_NAME=MNLI
: 1629122393:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 16 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir \\
  --load_adapter nli/multinli@ukp
: 1629122468:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629122515:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 25.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629122594:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 10.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629122606:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629122991:0;tad code
: 1629123013:0;nvidia-smi 
: 1629123024:0;ts code2
: 1629123029:0;cd transformers-importance-sampling/
: 1629123070:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 4.0 \\
  --output_dir ~/experiments/adapter_full_data_four_epochs \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629123078:0;export TASK_NAME=MNLI
: 1629123079:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 4.0 \\
  --output_dir ~/experiments/adapter_full_data_four_epochs \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629123143:0;tad code
: 1629123175:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --save_strategy epoch \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629127829:0;tad code
: 1629135335:0;cd transformers-importance-sampling/hans
: 1629135352:0;tad code
: 1629135409:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data/checkpoint-6136 \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data/checkpoint-6136/mnli/
: 1629135416:0;export TASK_NAME=hans
: 1629135418:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data/checkpoint-6136 \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data/checkpoint-6136/mnli/
: 1629135877:0;cd ~/data/glue_data/hans
: 1629135891:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data/checkpoint-6136/hans_predictions.txt
: 1629136649:0;tad code
: 1629136839:0;cd transformers-importance-sampling/hans
: 1629136842:0;cd ..
: 1629136852:0;tad code2
: 1629136895:0;python3 adapter_glue.py \\
  --model_name_or_path bert-base \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_bert \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629136928:0;python3 adapter_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_bert \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629136975:0;tad code
: 1629136980:0;tad code2
: 1629137007:0;e
: 1629152706:0;tad code
: 1629152714:0;tad code2
: 1629159265:0;tad code
: 1629159276:0;cd hans
: 1629159321:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data/mnli/ \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data/mnli
: 1629159339:0;export TASK_NAME=hans
: 1629159340:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data/mnli/ \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data/mnli
: 1629159489:0;tad code2
: 1629159506:0;tad code
: 1629159524:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-large \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_bert/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_bert/mnli
: 1629159533:0;cd data/glue_data/hans
: 1629159544:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data/mnli/hans_predictions.txt
: 1629159746:0;tad code2
: 1629159752:0;tad code
: 1629159769:0;python3 adapter_run_hans.py \\
  --model_name_or_path bert-base-uncased \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_bert/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_bert/mnli
: 1629159851:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data_bert/mnli/hans_predictions.txt
: 1629159903:0;tad code2
: 1629160024:0;python3 adapter_glue.py \\
  --model_name_or_path bert-large-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 64 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_bert_large \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629160108:0;tad code2
: 1629160131:34;python3 adapter_glue.py \\
  --model_name_or_path bert-large-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 256 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_bert_large \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629160429:0;python3 adapter_glue.py \\
  --model_name_or_path bert-large-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_bert_large \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629162627:0;tad code
: 1629162638:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data/mnli/hans_predictions.txt
: 1629162643:0;tad code2
: 1629162647:0;tad code
: 1629162652:0;cd ~/data/glue_data/hans
: 1629162654:0;tad code
: 1629162657:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data/mnli/hans_predictions.txt
: 1629162704:0;p3
: 1629163132:0;e
: 1629223775:0;tad code
: 1629224050:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224102:0;tad code2
: 1629224109:0;tad code
: 1629224115:0;tad code2
: 1629224121:0;tad code
: 1629224126:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224129:0;tad code2
: 1629224137:0;tkss code2
: 1629224140:0;tad code
: 1629224144:0;tl
: 1629224147:0;nvidia-smi 
: 1629224151:0;ts code
: 1629224154:0;cd transformers-importance-sampling/hans
: 1629224156:0;cd ..
: 1629224160:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224165:0;ts code2
: 1629224169:0;cd transformers-importance-sampling/hans
: 1629224171:0;cd ..
: 1629224258:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224267:0;export TASK_NAME=mnli
: 1629224268:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224374:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --load_adapter /home/nlp/experiments/adapter_less_data \\
  --overwrite_output_dir
: 1629224508:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --train_adapter\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --load_adapter /home/nlp/experiments/adapter_less_data \\
  --overwrite_output_dir
: 1629224517:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --train_adapter \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --load_adapter /home/nlp/experiments/adapter_less_data \\
  --overwrite_output_dir
: 1629224582:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --train_adapter \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --load_adapter /home/nlp/experiments/adapter_less_data \\
  --adapter_config pfeiffer\
  --overwrite_output_dir
: 1629224590:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --train_adapter \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --load_adapter /home/nlp/experiments/adapter_less_data \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224631:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --train_adapter \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_less_data \\
  --load_adapter /home/nlp/experiments/adapter_less_data/mnli \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224761:0;tad code
: 1629224767:0;export TASK_NAME=mnli
: 1629224777:0;python3 adapter_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 1e-4 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base \\
  --train_adapter \\
  --adapter_config pfeiffer \\
  --overwrite_output_dir
: 1629224808:0;tad code2
: 1629224873:0;cd ~/data/glue_data/hans
: 1629224891:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data_bert/mnli/hans_predictions.txt
: 1629224895:0;p3
: 1629224984:0;cd ~/transformers-importance-sampling/hans
: 1629225018:0;python3 adapter_run_hans.py \\
  --model_name_or_path bert-large-uncased \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_bert/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_bert_large/mnli
: 1629225036:0;export TASK_NAME=hans
: 1629225038:0;python3 adapter_run_hans.py \\
  --model_name_or_path bert-large-uncased \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_bert/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_bert_large/mnli
: 1629225340:0;cd ~/data/glue_data/hans
: 1629225395:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data_bert/mnli/hans_predictions.txt
: 1629225398:0;p3
: 1629225503:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data/mnli/hans_predictions.txt
: 1629225505:0;p3
: 1629225573:0;p3 evaluate_heur_output.py ~/experiments/adapter_less_data/hans_predictions.txt
: 1629225594:0;p3
: 1629225664:0;p3 evaluate_heur_output.py ~/experiments/adapter_diverse_less_data/hans_predictions.txt
: 1629225666:0;p3
: 1629225735:0;cat ~/experiments/adapter_diverse_less_data/eval_results_mnli.txt
: 1629225749:0;cat ~/experiments/adapter_less_data/eval_results_mnli.txt
: 1629225975:0;tad code
: 1629237195:0;cd transformers-importance-sampling/hans
: 1629237197:0;cd ..
: 1629237200:0;tad code
: 1629237234:0;cd hans
: 1629237260:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-base \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_bert/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_roberta_base
: 1629237276:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-base \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_roberta_base
: 1629237312:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-base \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_roberta_base/mnli
: 1629237328:0;export TASK_NAME=hans
: 1629237330:0;python3 adapter_run_hans.py \\
  --model_name_or_path roberta-base \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/adapter_full_data_roberta_base/mnli \\
  --train_adapter \\
  --load_adapter /home/nlp/experiments/adapter_full_data_roberta_base/mnli
: 1629237399:0;cd ~/data/glue_data/hans
: 1629237411:0;p3 evaluate_heur_output.py ~/experiments/adapter_full_data_roberta_base/mnli/hans_predictions.txt
: 1629237414:0;p3
: 1629332563:0;cd transformers-importance-sampling/hans
: 1629332564:0;cd ..
: 1629332579:0;cp adapter_glue.py new_run_glue.py
: 1629332582:0;vim new_run_glue.py
: 1629332710:0;pip3 uninstall adapter-transformers
: 1629332751:0;pip3 uninstall transformers
: 1629332764:0;cd ..
: 1629332766:0;cd transformers
: 1629332769:0;git pull
: 1629332873:0;pip3 install setup.pip install git+https://github.com/huggingface/transformers
: 1629333041:0;pip3 install .
: 1629333334:0;cd ~/transformers-importance-sampling/
: 1629333489:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333507:0;vim new_run_glue.py
: 1629333531:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333538:0;vim new_run_glue.py
: 1629333554:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333562:0;export TASK_NAME=MNLI
: 1629333564:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333573:0;vim new_run_glue.py
: 1629333594:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333606:0;tad code
: 1629333610:0;cd ..
: 1629333613:0;cd ~/transformers-importance-sampling/
: 1629333615:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333623:0;export TASK_NAME=MNLI
: 1629333624:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629333947:0;vim new_run_glue.py
: 1629333991:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-large \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_large_ft \\
  --overwrite_output_dir
: 1629334046:0;tad code2
: 1629334048:0;nvidia-smi 
: 1629334160:0;tad code
: 1629396715:0;cd hans
: 1629396726:0;cp adapter_run_hans.py new_run_hans.py
: 1629396728:0;vim new_run_hans.py
: 1629397008:0;python3 adapter_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397046:0;vim new_run_hans.py
: 1629397065:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397075:0;vim new_run_hans.py
: 1629397102:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397142:0;vim new_run_hans.py
: 1629397162:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397170:0;vim new_run_hans.py
: 1629397182:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397195:0;export TASK_NAME=hans
: 1629397197:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397272:0;vim new_run_hans.py
: 1629397307:0;vim adapter_run_hans.py
: 1629397380:0;ls
: 1629397392:0;vim utils_hans.py
: 1629397443:0;vim adapter_utils_hans.py
: 1629397628:0;vim run_hans.py
: 1629397657:0;vim utils_hans.py
: 1629397792:0;vim adapter_utils_hans.py
: 1629397827:0;vim utils_
: 1629397831:0;vim utils_hans.py
: 1629397878:0;vim new_run_hans.py
: 1629397903:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629397975:0;vim utils_hans.py
: 1629398090:0;vim new_run_hans.py
: 1629398158:0;vim utils_hans.py
: 1629398198:0;vim adapter_run_hans.py
: 1629398395:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629398417:0;vim new_run_hans.py
: 1629398442:0;vim adapter_run_hans.py
: 1629398457:0;python3 new_run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629398511:0;vim run_hans.py
: 1629398538:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629398606:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629398662:0;pip3 install transformers==4.3
: 1629398816:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629398892:0;pip3 install transformers
: 1629399054:0;cd transformers-importance-sampling
: 1629399057:0;cd hans
: 1629399059:0;vim run_hans.py
: 1629399073:0;vim utils_hans.py
: 1629399208:0;vim run_hans.py
: 1629399219:0;vim utils_hans.py
: 1629399296:0;vim run_hans.py
: 1629399289:33;vim run_hans.py
: 1629399324:0;vim utils_hans.py
: 1629399397:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629399411:0;vim utils_hans.py
: 1629399425:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --per_device_eval_batch_size 256 \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629399483:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629399525:0;vim run_hans.py
: 1629399907:0;cd ~/transformers
: 1629399911:0;pip3 install .
: 1629400209:0;cd ~/transformers-importance-sampling/ha
: 1629400211:0;cd ~/transformers-importance-sampling/hans
: 1629400215:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629400351:0;vim run_hans.py
: 1629400511:0;cd ..
: 1629400568:0;cd hans
: 1629400571:0;vim utils_hans.py
: 1629400608:0;vim run_hans.py
: 1629400627:0;vim utils_hans.py
: 1629400696:0;cd ..
: 1629400702:0;cd hans
: 1629400707:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629400712:0;export TASK_NAME=hans
: 1629400713:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629400773:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629400833:0;vim utils_hans.py
: 1629400868:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629400981:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --per_device_eval_batch_size 1 \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629401147:0;vim utils_hans.py
: 1629401364:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629401439:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 512 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629401588:0;vim run_hans.py
: 1629401661:0;vim utils_hans.py
: 1629401668:0;python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 512 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1629401806:0;vim utils_hans.py
: 1629401809:0;vim run_hans.py
: 1629401817:0;cd ~/data/glue_data/hans
: 1629401825:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_large_ft/hans_predictions.txt
: 1629401831:0;p3
: 1629401897:0;cd ..
: 1629401900:0;cd ~/transformers-importance-sampling/hans
: 1629401902:0;cd ..
: 1629401990:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_base_ft \\
  --overwrite_output_dir
: 1629402008:0;export TASK_NAME=mnli
: 1629402010:0;python3 new_run_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 128 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_base_ft \\
  --overwrite_output_dir
: 1629402107:0;tad code2
: 1629402109:0;cd ..
: 1629402113:0;cd ~/transformers-importance-sampling/
: 1629402117:0;nvidia-smi 
: 1629402127:0;tad code
: 1629402282:0;tad code2
: 1629402283:0;nvidia-smi 
: 1629402312:0;tad code
: 1629402147:8497;python3 new_run_glue.py \\
  --model_name_or_path roberta-base \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_roberta_base_ft \\
  --overwrite_output_dir
: 1629414428:0;cd hans
: 1629414473:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 512 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_base_ft
: 1629414563:0;tad code
: 1629414579:0;cat ~/experiments/again_roberta_large_ft/eval_results_mnli.txt
: 1629414602:0;tad code
: 1629414614:0;cd data/glue_data/hans
: 1629414623:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_base_ft/hans_predictions.txt
: 1629414626:0;p3
: 1629414677:0;tad code
: 1629414701:0;cd ..
: 1629414755:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path prajjwal1/bert-tiny \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 2048 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_tiny_ft \\
  --overwrite_output_dir
: 1629417962:0;vim new_run_glue.py
: 1629418211:0;cd hans
: 1629418236:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 512 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418261:0;nvidia-smi 
: 1629418276:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --overwrite_cache \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418291:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418392:0;vim run_hans.py
: 1629418417:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --config_name prajjwal1/bert-tiny \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418502:0;ls ~/experiments/again_bert_tiny_ft
: 1629418583:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_base_ft \\
  --config_name prajjwal1/bert-tiny \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_base_ft
: 1629418619:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418677:0;vim run_hans.py
: 1629418686:0;vim utils_hans.py
: 1629418710:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418734:0;vim utils_hans.py
: 1629418745:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_tiny_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_tiny_ft
: 1629418958:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629418961:0;cd ..
: 1629418963:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629419277:0;tad code
: 1629419309:0;echo "export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path bert-base-uncased \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_train \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir" >> script_glue.sh
: 1629419312:0;vim script_glue.sh
: 1629419335:0;vim new_run_glue.py
: 1629419351:0;vim script_glue.sh
: 1629419938:0;sh script_glue.sh
: 1629486593:0;tad code
: 1629486734:0;cd experiments
: 1629486735:0;ls
: 1629486795:0;cat again_bert_base_ft/eval_results_mnli.txt
: 1629486804:0;cat again_bert_base_ft_47/eval_results_mnli.txt
: 1629486811:0;cat again_bert_base_ft_59/eval_results_mnli.txt
: 1629486814:0;python3
: 1629486915:0;cd ~/transformers-importance-sampling/hans
: 1629486918:0;nvidia-smi 
: 1629486945:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 128 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629486984:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629487230:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --n_gpu=1 \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629487244:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --_n_gpu=1 \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629487307:0;ls
: 1629487352:0;vim run_hans.py
: 1629487449:0;cd transformers-importance-sampling/hans
: 1629487454:0;vim utils_hans.py
: 1629487543:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --_n_gpu=1 \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629487553:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629487842:0;wget https://github.com/huggingface/transformers/archive/refs/tags/v4.3.1.zip
: 1629487845:0;ls
: 1629487851:0;unzip v4.3.1.zip
: 1629487980:0;ls
: 1629488000:0;mv transformers-4.3.1/src transformers
: 1629488006:0;ls transformers
: 1629488017:0;mv transformers/transformers kl
: 1629488021:0;rm -rf transformers
: 1629488039:0;mv kl transformers
: 1629488068:0;ls transformers
: 1629488078:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629488207:0;export TASK_NAME=hans; CUDA_VISIBLE_DEVICES=0 python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 32 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629488290:0;export TASK_NAME=hans; CUDA_VISIBLE_DEVICES=0 python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 1 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629488353:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft_47 \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 4 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft_47
: 1629488395:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft_47 \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft_47
: 1629488738:0;vim run_hans.py
: 1629488763:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft_47 \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft_47
: 1629488797:0;vim run_hans.py
: 1629488811:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft_47 \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft_47
: 1629488844:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629489081:0;l
: 1629489083:0;ls
: 1629489088:0;rm -rf transformers
: 1629489121:0;rm -rf transformers-4.3.1
: 1629489146:0;rm -rf v4.3.1.zip
: 1629489151:0;wget https://github.com/Adapter-Hub/adapter-transformers/archive/refs/heads/master.zip
: 1629489157:0;unzip master.zip
: 1629489281:0;ls
: 1629489298:0;mv adapter-transformers-master transformers
: 1629489300:0;ls transformers
: 1629489314:0;mv transformers kl
: 1629489322:0;mv kl/src transformers
: 1629489326:0;ls transformers
: 1629489334:0;mv transformers/transformers kl
: 1629489339:0;rm -rf transformers
: 1629489346:0;mv kl transformers
: 1629489349:0;ls transformers
: 1629489360:0;mv transformers/transformers kl
: 1629489363:0;rm -rf transformers
: 1629489446:0;mv kl transformers
: 1629489449:0;ls transformers
: 1629489459:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629489526:0;vim run_hans.py
: 1629489545:0;rm -rf transformers
: 1629489608:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_type bert-base-uncased \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629489620:0;vim run_hans.py
: 1629489657:0;export TASK_NAME=hans; python3 run_hans.py \\
  --config_name bert-base-uncased \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629489889:0;vim ~/experiments/again_bert_base_ft/config.json
: 1629490016:0;nvidia-smi 
: 1629490786:0;export TASK_NAME=hans; python3 run_hans.py \\
  --config_name bert-base-uncased \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629490834:0;cd ..
: 1629490876:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629490929:0;vim new_run_glue.py
: 1629490981:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629491031:0;vim new_run_glue.py
: 1629491051:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629491074:0;vim new_run_glue.py
: 1629491085:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629491199:0;vim new_run_glue.py
: 1629491259:0;export TASK_NAME=MNLI; python3 new_run_glue.py \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --save_strategy epoch \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 256 \\
  --per_device_train_batch_size 512 \\
  --learning_rate 2e-5 \\
  --num_train_epochs 8.0 \\
  --output_dir ~/experiments/again_bert_base_ft \\
  --overwrite_output_dir
: 1629491352:0;cd hans
: 1629491354:0;vim run_hans.py
: 1629491421:0;export TASK_NAME=hans; python3 run_hans.py \\
  --config_name bert-base-uncased \\
  --model_name_or_path ~/experiments/again_bert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629491600:0;tad code
: 1629491631:0;export TASK_NAME=hans; python3 run_hans.py \\
  --config_name bert-base-uncased \\
  --model_name_or_path bert-base-uncased \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629491676:0;ls
: 1629491683:0;rm master.zip
: 1629491686:0;ls backup
: 1629491812:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path roberta-base \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629492235:0;ls
: 1629492262:0;diff run_hans.py backup/run_hans.py
: 1629492359:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path bert-base-uncased \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_bert_base_ft
: 1629492691:0;tad code
: 1629492732:0;python3
: 1629494779:0;vim run_hans.py
: 1629497320:0;tad code
: 1629498535:0;cd ..
: 1629498539:0;vim script_glue.sh
: 1629652814:0;tad code
: 1629652819:0;vim script_glue.sh
: 1629653791:0;sh script_glue.sh
: 1629653817:0;tad code
: 1629750656:0;tl
: 1629750673:0;cd transformers-importance-sampling/
: 1629750704:0;ls ../experiments/again_bert_large_ft_47
: 1629750707:0;vim script_glue.sh
: 1629750726:0;sh script_glue.sh
: 1629751682:0;ts code
: 1629751687:0;sh script_glue.sh
: 1629751799:0;nvidia-smi 
: 1629751808:0;tad code
: 1630087736:0;tadd code
: 1630087743:0;tad code
: 1630087746:0;ls
: 1630087750:0;cd hans
: 1630087766:0;ls ../../experiments
: 1630088424:0;tad code
: 1630088426:0;ls
: 1630089376:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_base_ft
: 1630089536:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_base_ft_47 \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_base_ft_47
: 1630089701:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_base_ft_59 \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_base_ft_59
: 1630090126:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft
: 1630096596:0;tadad code
: 1630096598:0;tad code
: 1630096627:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft_47 \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft_47
: 1630118686:0;tad code
: 1630118711:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_roberta_large_ft_59 \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_roberta_large_ft_59
: 1630118903:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_albert_base_ft \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_albert_base_ft
: 1630118914:0;ls ../../experiments
: 1630118931:0;export TASK_NAME=hans; python3 run_hans.py \\
  --model_name_or_path ~/experiments/again_albert_base \\
  --data_dir ~/data/glue_data/hans \\
  --max_seq_length 96 \\
  --per_device_eval_batch_size 64 \\
  --evaluation_strategy epoch\\
  --overwrite_cache \\
  --task_name $TASK_NAME \\
  --do_eval \\
  --output_dir ~/experiments/again_albert_base
: 1630118971:0;cd ~/transformers-importance-sampling/hans
: 1630118976:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_base_ft/hans_predictions.txt
: 1630118988:0;ls
: 1630118993:0;cd ../../data/glue_data/hans
: 1630118997:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_base_ft/hans_predictions.txt
: 1630184401:0;tad code
: 1630184406:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_base_ft_47/hans_predictions.txt
: 1630184411:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_base_ft_59/hans_predictions.txt
: 1630184414:0;p3
: 1630184693:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_large_ft/hans_predictions.txt
: 1630184699:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_large_ft_47/hans_predictions.txt
: 1630184706:0;p3 evaluate_heur_output.py ~/experiments/again_roberta_large_ft_59/hans_predictions.txt
: 1630184708:0;p3
: 1630184910:0;cat ~/experiments/again_roberta_large_ft/eval_results_mnli.txt
: 1630184921:0;cat ~/experiments/again_roberta_large_ft_59/eval_results_mnli.txt
: 1630184926:0;cat ~/experiments/again_roberta_large_ft_47/eval_results_mnli.txt
: 1630184928:0;p3
: 1630184984:0;cat ~/experiments/again_roberta_base_ft/eval_results_mnli.txt
: 1630184989:0;cat ~/experiments/again_roberta_base_ft_47/eval_results_mnli.txt
: 1630184994:0;cat ~/experiments/again_roberta_base_ft_59/eval_results_mnli.txt
: 1630184996:0;p3
: 1630185078:0;tl
: 1630185085:0;tad jupyter
: 1630185090:0;ts jupyter
: 1630185094:0;jupyter notebook --no-browser --port=8888
: 1630185168:0;ls experiments/again_
: 1630185173:0;ls experiments/again_*
: 1630185220:0;cat ~/experiments/again_albert_base/eval_results_mnli.txt
: 1630185225:0;cat ~/experiments/again_albert_base_47/eval_results_mnli.txt
: 1630185230:0;cat ~/experiments/again_albert_base_59/eval_results_mnli.txt
: 1630185232:0;p3
: 1630185322:0;cat ~/experiments/again_albert_large/eval_results_mnli.txt
: 1630185327:0;cat ~/experiments/again_albert_large_47/eval_results_mnli.txt
: 1630185332:0;cat ~/experiments/again_albert_large_59/eval_results_mnli.txt
: 1630185335:0;p3
: 1630185406:0;cat ~/experiments/again_bert_tiny/eval_results_mnli.txt
: 1630185411:0;cat ~/experiments/again_bert_tiny_47/eval_results_mnli.txt
: 1630185416:0;cat ~/experiments/again_bert_tiny_59/eval_results_mnli.txt
: 1630185417:0;p3
: 1630185493:0;cat ~/experiments/again_bert_medium/eval_results_mnli.txt
: 1630185498:0;cat ~/experiments/again_bert_medium_47/eval_results_mnli.txt
: 1630185502:0;cat ~/experiments/again_bert_medium_59/eval_results_mnli.txt
: 1630185507:0;p3
: 1630185556:0;cat ~/experiments/again_bert_mini/eval_results_mnli.txt
: 1630185561:0;cat ~/experiments/again_bert_mini_47/eval_results_mnli.txt
: 1630185566:0;cat ~/experiments/again_bert_mini_59/eval_results_mnli.txt
: 1630185569:0;p3
: 1630185905:0;cat ~/experiments/again_bert_small/eval_results_mnli.txt
: 1630185910:0;cat ~/experiments/again_bert_small_47/eval_results_mnli.txt
: 1630185918:0;cat ~/experiments/again_bert_small_59/eval_results_mnli.txt
: 1630185920:0;p3
: 1630185980:0;cat ~/experiments/again_bert_large_ft/eval_results_mnli.txt
: 1630185986:0;cat ~/experiments/again_bert_large_ft_47/eval_results_mnli.txt
: 1630185990:0;cat ~/experiments/again_bert_large_ft_59/eval_results_mnli.txt
: 1630185992:0;p3
: 1630198656:0;tad code
: 1630198664:0;tad jupyter
: 1630953183:0;ls
: 1630953196:0;tl
: 1630953198:0;nvidia-smi 
: 1630953202:0;htop
: 1630953212:0;tad jupyter
: 1630953231:0;nvidia-smi 
: 1631125340:0;ls
: 1631125350:0;cd prajjwal1
: 1631125351:0;ls
: 1631125359:0;rm -rf commonsense-discourse
: 1631125381:0;git clone https://github.com/prajjwal1/commonsense-discourse
: 1631125436:0;ls
: 1631125439:0;cd commonsense-discourse
: 1631125440:0;ls
: 1631125448:0;cd discosense
: 1631125647:0;ls
: 1631125662:0;tad 8_2
: 1631125664:0;tl
: 1631125869:0;git pull
: 1631125882:0;ls
: 1633120295:0;tad jupyter
: 1633120395:0;nvidia-smi 
: 1633120674:0;pwd
: 1633121547:0;ls
: 1633188513:0;tad jupyter
: 1633188518:0;jupyter notebook --no-browser --port=8888
: 1633188527:0;l
: 1633188528:0;ls
: 1633384870:0;cp ~/.bash_history transformers-importance-sampling
: 1633384873:0;cd transformers-importance-sampling/
: 1633384880:0;vim .bash_history
: 1633384896:0;rm .bash_history
: 1633384901:0;cp ~/.zsh_history .
