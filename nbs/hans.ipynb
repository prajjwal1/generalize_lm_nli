{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer, EvalPrediction)\n",
    "from transformers import GlueDataTrainingArguments as DataTrainingArguments\n",
    "from transformers import (HfArgumentParser, Trainer, TrainingArguments,\n",
    "                          glue_compute_metrics, glue_output_modes,\n",
    "                          glue_tasks_num_labels, set_seed)\n",
    "\n",
    "from datasets.hans_dataset import HansDataset\n",
    "from datasets.hans_processors import glue_output_modes, glue_tasks_num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 13:45:43 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
      "06/05/2020 13:45:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False, 16-bits training: False\n",
      "06/05/2020 13:45:43 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/home/nlp/experiments/trial', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False)\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArguments(model_name_or_path = 'albert-base-v2')\n",
    "data_args = DataTrainingArguments(task_name = 'hans', data_dir = '/home/nlp/data/hans/')\n",
    "training_args = TrainingArguments(output_dir = '/home/nlp/experiments/trial',\n",
    "                                 do_eval = True)\n",
    "\n",
    "\n",
    "if (\n",
    "    os.path.exists(training_args.output_dir)\n",
    "    and os.listdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(\n",
    "        f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
    "    )\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.local_rank != -1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "# Set seed\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "try:\n",
    "    num_labels = glue_tasks_num_labels[data_args.task_name]\n",
    "    output_mode = glue_output_modes[data_args.task_name]\n",
    "except KeyError:\n",
    "    raise ValueError(\"Task not found: %s\" % (data_args.task_name))\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "#\n",
    "# Distributed training:\n",
    "# The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 13:45:45 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /home/nlp/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
      "06/05/2020 13:45:45 - INFO - transformers.configuration_utils -   Model config AlbertConfig {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"finetuning_task\": \"hans\",\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "06/05/2020 13:45:46 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /home/nlp/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca\n",
      "06/05/2020 13:45:46 - INFO - transformers.configuration_utils -   Model config AlbertConfig {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu_new\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "06/05/2020 13:45:46 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at /home/nlp/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
      "06/05/2020 13:45:46 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/albert-base-v2-pytorch_model.bin from cache at /home/nlp/.cache/torch/transformers/c7c1b2b621933bfa9a5f6ed18b1d6dc2f445001779b13d37286a806117ebeb10.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
      "06/05/2020 13:45:47 - INFO - transformers.modeling_utils -   Weights of AlbertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "06/05/2020 13:45:47 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=data_args.task_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:10:33 - INFO - filelock -   Lock 140635937441536 acquired on /home/nlp/data/hans/cached_dev_AlbertTokenizer_128_hans.lock\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_dataset -   Creating features from dataset file at /home/nlp/data/hans/\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   Writing example 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The president advised the doctor .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The doctor advised the president .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 406 10017 14 1687 13 9 3 14 1687 10017 14 406 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The student saw the managers .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The managers saw the student .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 1209 441 14 12657 13 9 3 14 12657 441 14 1209 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The presidents encouraged the banker .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The banker encouraged the presidents .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 406 18 5623 14 12426 13 9 3 14 12426 5623 14 406 18 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The senators supported the actor .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The actor supported the senators .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 11101 1827 14 1574 13 9 3 14 1574 1827 14 11101 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The actors avoided the bankers .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The bankers avoided the actors .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 4977 9460 14 12426 18 13 9 3 14 12426 18 9460 14 4977 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The senators mentioned the artist .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The artist mentioned the senators .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 11101 2211 14 1169 13 9 3 14 1169 2211 14 11101 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The managers saw the secretaries .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The secretaries saw the managers .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 12657 441 14 25738 13 9 3 14 25738 441 14 12657 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The professor recognized the secretaries .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The secretaries recognized the professor .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 1032 2124 14 25738 13 9 3 14 25738 2124 14 1032 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The author contacted the scientist .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The scientist contacted the author .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 1314 12842 14 6415 13 9 3 14 6415 12842 14 1314 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   *** Example ***\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_a: The athletes recommended the senator .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   text_b: The senator recommended the athletes .\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   guid: dev-non-entailment\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   input_ids: 2 14 7198 5773 14 3600 13 9 3 14 3600 5773 14 7198 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/05/2020 12:10:33 - INFO - datasets.hans_processors -   label: temp1 (id = 0)\n",
      "06/05/2020 12:10:35 - INFO - datasets.hans_processors -   Writing example 10000\n",
      "06/05/2020 12:10:36 - INFO - datasets.hans_processors -   Writing example 20000\n",
      "06/05/2020 12:10:40 - INFO - datasets.hans_dataset -   Saving features into cached file /home/nlp/data/hans/cached_dev_AlbertTokenizer_128_hans [took 3.185 s]\n",
      "06/05/2020 12:10:40 - INFO - filelock -   Lock 140635937441536 released on /home/nlp/data/hans/cached_dev_AlbertTokenizer_128_hans.lock\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = HansDataset(data_args, tokenizer=tokenizer, evaluate=True) if training_args.do_eval else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compute_metrics_fn(task_name: str) -> Callable[[EvalPrediction], Dict]:\n",
    "    def compute_metrics_fn(p: EvalPrediction) -> Dict:\n",
    "        if output_mode == \"classification\":\n",
    "            preds = np.argmax(p.predictions, axis=1)\n",
    "        elif output_mode == \"regression\":\n",
    "            preds = np.squeeze(p.predictions)\n",
    "        return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n",
    "\n",
    "    return compute_metrics_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:11:39 - INFO - transformers.trainer -   Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/calvin/huggingface\" target=\"_blank\">https://app.wandb.ai/calvin/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/calvin/huggingface/runs/16as20fo\" target=\"_blank\">https://app.wandb.ai/calvin/huggingface/runs/16as20fo</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:11:40 - INFO - wandb.run_manager -   system metrics and metadata threads started\n",
      "06/05/2020 12:11:40 - INFO - wandb.run_manager -   checking resume status, waiting at most 10 seconds\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   resuming run from id: UnVuOnYxOjE2YXMyMGZvOmh1Z2dpbmdmYWNlOmNhbHZpbg==\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   file/dir created: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-metadata.json\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   upserting run before process can begin, waiting at most 10 seconds\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   saving pip packages\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   initializing streaming files api\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   unblocking file change observer, beginning sync with W&B servers\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   file/dir created: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-history.jsonl\n",
      "06/05/2020 12:11:41 - INFO - wandb.run_manager -   shutting down system stats and metadata service\n",
      "06/05/2020 12:11:42 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/config.yaml\n",
      "06/05/2020 12:11:42 - INFO - wandb.run_manager -   file/dir created: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/requirements.txt\n",
      "06/05/2020 12:11:42 - INFO - wandb.run_manager -   file/dir created: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-events.jsonl\n",
      "06/05/2020 12:11:42 - INFO - wandb.run_manager -   file/dir created: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-summary.json\n",
      "06/05/2020 12:11:42 - INFO - wandb.run_manager -   stopping streaming files and file change observer\n",
      "06/05/2020 12:11:43 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=None,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=build_compute_metrics_fn(data_args.task_name),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:14:04 - INFO - transformers.trainer -   ***** Running Evaluation *****\n",
      "06/05/2020 12:14:04 - INFO - transformers.trainer -     Num examples = 30000\n",
      "06/05/2020 12:14:04 - INFO - transformers.trainer -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6a68a9edb54dd49035937942ab95fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=1875.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:15:00 - INFO - wandb.run_manager -   system metrics and metadata threads started\n",
      "06/05/2020 12:15:00 - INFO - wandb.run_manager -   checking resume status, waiting at most 10 seconds\n",
      "06/05/2020 12:15:00 - INFO - wandb.run_manager -   resuming run from id: UnVuOnYxOjE2YXMyMGZvOmh1Z2dpbmdmYWNlOmNhbHZpbg==\n",
      "06/05/2020 12:15:01 - INFO - wandb.run_manager -   upserting run before process can begin, waiting at most 10 seconds\n",
      "06/05/2020 12:15:01 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/config.yaml\n",
      "06/05/2020 12:15:01 - INFO - wandb.run_manager -   saving pip packages\n",
      "06/05/2020 12:15:01 - INFO - wandb.run_manager -   initializing streaming files api\n",
      "06/05/2020 12:15:01 - INFO - wandb.run_manager -   unblocking file change observer, beginning sync with W&B servers\n",
      "06/05/2020 12:15:01 - INFO - wandb.run_manager -   shutting down system stats and metadata service\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-summary.json\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-metadata.json\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-events.jsonl\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-history.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"eval_loss\": 1.1784355945587157, \"eval_acc\": 0.04203333333333333, \"step\": null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/requirements.txt\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-events.jsonl\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-summary.json\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-history.jsonl\n",
      "06/05/2020 12:15:02 - INFO - wandb.run_manager -   stopping streaming files and file change observer\n",
      "06/05/2020 12:15:03 - INFO - wandb.run_manager -   file/dir modified: /home/nlp/transformers-importance-sampling/nbs/wandb/run-20200605_031139-16as20fo/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "result = trainer.evaluate(eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1784355945587157, 'eval_acc': 0.04203333333333333}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.inner_group_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2020 15:15:46 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/albert-base-v2-pytorch_model.bin from cache at /home/nlp/.cache/torch/transformers/c7c1b2b621933bfa9a5f6ed18b1d6dc2f445001779b13d37286a806117ebeb10.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
      "06/05/2020 15:15:47 - INFO - transformers.modeling_utils -   Weights of AlbertForSequenceClassification not initialized from pretrained model: ['albert.encoder.albert_layer_groups.0.albert_layers.1.full_layer_layer_norm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.query.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.key.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.value.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.value.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.attention.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.ffn.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.1.ffn_output.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.1.ffn_output.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.full_layer_layer_norm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.query.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.key.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.value.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.value.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.attention.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.ffn.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.2.ffn_output.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.2.ffn_output.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.full_layer_layer_norm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.query.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.key.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.value.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.value.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.attention.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.ffn.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.3.ffn_output.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.3.ffn_output.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.full_layer_layer_norm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.query.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.key.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.value.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.value.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.attention.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.ffn.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.4.ffn_output.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.4.ffn_output.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.full_layer_layer_norm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.query.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.key.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.value.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.value.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.attention.LayerNorm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.ffn.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.5.ffn_output.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.5.ffn_output.bias', 'classifier.weight', 'classifier.bias']\n",
      "06/05/2020 15:15:47 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): AlbertLayerGroup(\n",
       "    (albert_layers): ModuleList(\n",
       "      (0): AlbertLayer(\n",
       "        (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (attention): AlbertAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): AlbertLayer(\n",
       "        (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (attention): AlbertAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): AlbertLayer(\n",
       "        (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (attention): AlbertAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): AlbertLayer(\n",
       "        (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (attention): AlbertAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (4): AlbertLayer(\n",
       "        (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (attention): AlbertAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (5): AlbertLayer(\n",
       "        (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (attention): AlbertAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.albert.encoder.albert_layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.processors import glue_processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = glue_processors[data_args.task_name]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nlp/data/hans/dev_matched.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b5b2d2a9a8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/data/processors/glue.py\u001b[0m in \u001b[0;36mget_dev_examples\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dev_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;34m\"\"\"See base class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dev_matched.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dev_matched\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_test_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/data/processors/utils.py\u001b[0m in \u001b[0;36m_read_tsv\u001b[0;34m(cls, input_file, quotechar)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;34m\"\"\"Reads a tab separated value file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8-sig\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/nlp/data/hans/dev_matched.tsv'"
     ]
    }
   ],
   "source": [
    "processor.get_dev_examples(data_args.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/home/nlp/data/hans/heuristics_evaluation_set.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in f:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-entailment\\t( ( The senators ) ( ( contacted ( the scientists ) ) . ) )\\t( ( The scientists ) ( ( contacted ( the senators ) ) . ) )\\t(ROOT (S (NP (DT The) (NNS senators)) (VP (VBD contacted) (NP (DT the) (NNS scientists))) (. .)))\\t(ROOT (S (NP (DT The) (NNS scientists)) (VP (VBD contacted) (NP (DT the) (NNS senators))) (. .)))\\tThe senators contacted the scientists .\\tThe scientists contacted the senators .\\tex12\\tlexical_overlap\\tln_subject/object_swap\\ttemp1\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hans.hans_processors import HansProcessor, hans_convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hans_proc = HansProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = hans_proc.get_dev_examples(\"/home/nlp/data/hans/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = hans_proc.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contradiction', 'entailment', 'neutral']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans_proc.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = glue_output_modes[data_args.task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   Writing example 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The president advised the doctor .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The doctor advised the president .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 406 10017 14 1687 13 9 3 14 1687 10017 14 406 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The student saw the managers .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The managers saw the student .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 1209 441 14 12657 13 9 3 14 12657 441 14 1209 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The presidents encouraged the banker .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The banker encouraged the presidents .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 406 18 5623 14 12426 13 9 3 14 12426 5623 14 406 18 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The senators supported the actor .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The actor supported the senators .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 11101 1827 14 1574 13 9 3 14 1574 1827 14 11101 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The actors avoided the bankers .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The bankers avoided the actors .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 4977 9460 14 12426 18 13 9 3 14 12426 18 9460 14 4977 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The senators mentioned the artist .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The artist mentioned the senators .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 11101 2211 14 1169 13 9 3 14 1169 2211 14 11101 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The managers saw the secretaries .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The secretaries saw the managers .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 12657 441 14 25738 13 9 3 14 25738 441 14 12657 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The professor recognized the secretaries .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The secretaries recognized the professor .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 1032 2124 14 25738 13 9 3 14 25738 2124 14 1032 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The author contacted the scientist .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The scientist contacted the author .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 1314 12842 14 6415 13 9 3 14 6415 12842 14 1314 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   *** Example ***\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_a: The athletes recommended the senator .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   text_b: The senator recommended the athletes .\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   guid: dev-non-entailment\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   input_ids: 2 14 7198 5773 14 3600 13 9 3 14 3600 5773 14 7198 13 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/20/2020 22:34:59 - INFO - hans.hans_processors -   label: temp1 (id = 0)\n",
      "05/20/2020 22:35:00 - INFO - hans.hans_processors -   Writing example 10000\n",
      "05/20/2020 22:35:01 - INFO - hans.hans_processors -   Writing example 20000\n"
     ]
    }
   ],
   "source": [
    "features = hans_convert_examples_to_features(examples, tokenizer, max_length = data_args.max_seq_length,\n",
    "                                            label_list = label_list, output_mode = output_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_mask\": [\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0\n",
       "  ],\n",
       "  \"input_ids\": [\n",
       "    2,\n",
       "    14,\n",
       "    406,\n",
       "    10017,\n",
       "    14,\n",
       "    1687,\n",
       "    13,\n",
       "    9,\n",
       "    3,\n",
       "    14,\n",
       "    1687,\n",
       "    10017,\n",
       "    14,\n",
       "    406,\n",
       "    13,\n",
       "    9,\n",
       "    3,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0\n",
       "  ],\n",
       "  \"label\": 0,\n",
       "  \"pairID\": \"0\",\n",
       "  \"token_type_ids\": [\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HansDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This will be superseded by a framework-agnostic approach\n",
    "    soon.\n",
    "    \"\"\"\n",
    "\n",
    "    args: GlueDataTrainingArguments\n",
    "    output_mode: str\n",
    "    features: List[InputFeatures]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args: GlueDataTrainingArguments,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        limit_length: Optional[int] = None,\n",
    "        evaluate=False,\n",
    "    ):\n",
    "        self.args = args\n",
    "        processor = HansProcessor()\n",
    "        self.output_mode = glue_output_modes[args.task_name]\n",
    "        # Load data features from cache or dataset file\n",
    "        cached_features_file = os.path.join(\n",
    "            args.data_dir,\n",
    "            \"cached_{}_{}_{}_{}\".format(\n",
    "                \"dev\" if evaluate else \"train\", tokenizer.__class__.__name__, str(args.max_seq_length), args.task_name,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Make sure only the first process in distributed training processes the dataset,\n",
    "        # and the others will use the cache.\n",
    "        lock_path = cached_features_file + \".lock\"\n",
    "        with FileLock(lock_path):\n",
    "\n",
    "            if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "                start = time.time()\n",
    "                self.features = torch.load(cached_features_file)\n",
    "                logger.info(\n",
    "                    f\"Loading features from cached file {cached_features_file} [took %.3f s]\", time.time() - start\n",
    "                )\n",
    "            else:\n",
    "                logger.info(f\"Creating features from dataset file at {args.data_dir}\")\n",
    "                label_list = processor.get_labels()\n",
    "                if args.task_name in [\"mnli\", \"mnli-mm\"] and tokenizer.__class__ in (\n",
    "                    RobertaTokenizer,\n",
    "                    RobertaTokenizerFast,\n",
    "                    XLMRobertaTokenizer,\n",
    "                ):\n",
    "                    # HACK(label indices are swapped in RoBERTa pretrained model)\n",
    "                    label_list[1], label_list[2] = label_list[2], label_list[1]\n",
    "                examples = (\n",
    "                    processor.get_dev_examples(args.data_dir)\n",
    "                    if evaluate\n",
    "                    else processor.get_train_examples(args.data_dir)\n",
    "                )\n",
    "                if limit_length is not None:\n",
    "                    examples = examples[:limit_length]\n",
    "                self.features = hans_convert_examples_to_features(\n",
    "                    examples,\n",
    "                    tokenizer,\n",
    "                    max_length=args.max_seq_length,\n",
    "                    label_list=label_list,\n",
    "                    output_mode=self.output_mode,\n",
    "                )\n",
    "                start = time.time()\n",
    "                torch.save(self.features, cached_features_file)\n",
    "                # ^ This seems to take a lot of time so I want to investigate why and how we can improve.\n",
    "                logger.info(\n",
    "                    \"Saving features into cached file %s [took %.3f s]\", cached_features_file, time.time() - start\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, i) -> InputFeatures:\n",
    "        return self.features[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args.ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
