{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import GlueDataTrainingArguments as DataTrainingArguments\n",
    "from transformers import GlueDataset, default_data_collator, glue_tasks_num_labels\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from hans.utils_hans import HansDataset, hans_processors\n",
    "from models.lstm import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_data_args = DataTrainingArguments(task_name = 'mnli', data_dir = '/home/nlp/data/glue_data/MNLI')\n",
    "hans_data_args = DataTrainingArguments(task_name = 'hans', data_dir = '/home/nlp/data/glue_data/hans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = glue_tasks_num_labels[mnli_data_args.task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(variant, num_labels=num_labels)\n",
    "model = AutoModel.from_pretrained(variant, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train_dataset = GlueDataset(mnli_data_args, tokenizer)\n",
    "mnli_eval_dataset = GlueDataset(mnli_data_args, tokenizer, mode=\"dev\")\n",
    "hans_eval_dataset = HansDataset(\n",
    "            data_dir=hans_data_args.data_dir,\n",
    "            tokenizer=tokenizer,\n",
    "            task=hans_data_args.task_name,\n",
    "            max_seq_length=hans_data_args.max_seq_length,\n",
    "            overwrite_cache=hans_data_args.overwrite_cache,\n",
    "            evaluate=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hans_data_collator(features):\n",
    "    \"\"\"\n",
    "    Data collator that removes the \"pairID\" key if present.\n",
    "    \"\"\"\n",
    "    batch = default_data_collator(features)\n",
    "    _ = batch.pop(\"pairID\", None)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_on_cuda(model, batch):\n",
    "    for k,v in batch.items():\n",
    "        batch[k] = v.cuda()\n",
    "    return model.cuda(), batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train_dl = DataLoader(mnli_train_dataset,collate_fn = default_data_collator,\n",
    "                            batch_size=1024, shuffle=False, drop_last=True)\n",
    "mnli_eval_dl = DataLoader(mnli_eval_dataset,collate_fn = default_data_collator,\n",
    "                            batch_size=128, shuffle=False, drop_last=True)\n",
    "hans_eval_dl = DataLoader(hans_eval_dataset,collate_fn = hans_data_collator,\n",
    "                            batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Config():\n",
    "    def __init__(self, num_labels, n_cells, n_layers, n_embed, d_embed,\n",
    "                d_proj, d_hidden, d_out=None, projection=False):\n",
    "        self.d_out = num_labels\n",
    "        self.n_cells = n_cells\n",
    "        self.n_layers = n_layers\n",
    "        self.n_layers = 1\n",
    "        self.n_embed = n_embed\n",
    "        self.d_embed = d_embed\n",
    "        self.d_proj = d_proj\n",
    "        self.d_hidden = d_hidden\n",
    "        self.projection = False\n",
    "        self.dp_ratio = 0.2\n",
    "        self.birnn = True\n",
    "        self.fix_emb = False\n",
    "        self.projection = projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HEXProjection(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(HEXProjection, self).__init__()\n",
    "        self.summarization_params = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        prelim_loss = torch.cat([x, y])\n",
    "        prelim_pred = torch.cat([torch.zeros_like(x), y])\n",
    "        prelim_H = torch.cat([x, torch.zeros_like(x)])\n",
    "        y_loss = self.summarization_params(prelim_loss)\n",
    "        y_pred = self.summarization_params(prelim_pred)\n",
    "        y_H = self.summarization_params(prelim_H)\n",
    "        \n",
    "        inverse_inside = torch.pinverse(torch.matmul(torch.transpose(y_H, 0, 1), y_H))\n",
    "        \n",
    "        y_loss = y_loss - torch.matmul(\n",
    "                                torch.matmul(\n",
    "                                    torch.matmul(y_H, inverse_inside), \n",
    "                                    torch.transpose(y_H, 0, 1))\n",
    "                                , y_loss)\n",
    "        return y_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_config = LSTM_Config(num_labels = 3, \n",
    "                          n_cells = 2,\n",
    "                          n_layers = 2,\n",
    "                          n_embed = len(tokenizer.vocab), \n",
    "                          d_embed = 768, \n",
    "                          d_proj = 768//2, \n",
    "                          d_hidden = 768//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(lstm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalTransformer(nn.Module):\n",
    "    def __init__(self, network_a, network_b, num_labels, batch_size):\n",
    "        super(OrthogonalTransformer, self).__init__()\n",
    "        self.network_a = network_a\n",
    "        self.network_b = network_b\n",
    "        self.hex = HEXProjection(768)\n",
    "        self.out_1 = nn.Linear(768, 3)\n",
    "        self.out_2 = nn.Linear(batch_size*2, batch_size)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch.pop('labels');\n",
    "        output_a = self.network_a(**batch)[1]\n",
    "        output_b = self.network_b(batch['input_ids'])\n",
    "        projected_logits = self.hex(output_a, output_b)\n",
    "        output = self.out_1(projected_logits)\n",
    "        return self.out_2(output.t()).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(mnli_eval_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthogonal_tfmr = OrthogonalTransformer(model, lstm, 3, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthogonal_tfmr, batch = put_on_cuda(orthogonal_tfmr, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = orthogonal_tfmr(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LSTM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import Bottle, Linear, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = torch.nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None):\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "\n",
    "        if position_ids is None:\n",
    "            position_ids = self.position_ids[:, :seq_length]\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, bert_config, config):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.config = config\n",
    "        self.embed = BertEmbeddings(bert_config)\n",
    "        self.projection = Linear(config.d_embed, config.d_proj)\n",
    "        self.encoder = Encoder(config)\n",
    "        self.dropout = nn.Dropout(p=config.dp_ratio)\n",
    "        self.relu = nn.ReLU()\n",
    "        seq_in_size = config.d_hidden\n",
    "        if self.config.birnn:\n",
    "            seq_in_size *= 2\n",
    "        lin_config = [seq_in_size]*2\n",
    "        self.out = nn.Sequential(\n",
    "            Linear(*lin_config),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            Linear(*lin_config),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            Linear(*lin_config),\n",
    "            self.relu,\n",
    "            self.dropout,\n",
    "            Linear(seq_in_size, config.d_out))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        embed = self.embed(batch['input_ids'], batch['token_type_ids'])\n",
    "        if self.config.projection:\n",
    "            embed = self.relu(self.projection(embed))\n",
    "        print(embed.shape)\n",
    "        embed = self.encoder(embed)\n",
    "        print(embed.shape)\n",
    "        return self.out(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_config = LSTM_Config(num_labels = 3, \n",
    "                          n_cells = 2,\n",
    "                          n_layers = 4,\n",
    "                          n_embed = len(tokenizer.vocab), \n",
    "                          d_embed = 768, \n",
    "                          d_proj = 768, \n",
    "                          d_hidden = 768,\n",
    "                          d_out = 3,\n",
    "                          projection = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(config, lstm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(lstm.parameters(), 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lstm.train().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads)\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "\n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "        if encoder_hidden_states is not None:\n",
    "            mixed_key_layer = self.key(encoder_hidden_states)\n",
    "            mixed_value_layer = self.value(encoder_hidden_states)\n",
    "            attention_mask = encoder_attention_mask\n",
    "        else:\n",
    "            mixed_key_layer = self.key(hidden_states)\n",
    "            mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        #out: 1 x emdedding_dim\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.attention = BertSelfAttention(config)\n",
    "        self.linear1 = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.act_fn = nn.ReLU()\n",
    "        \n",
    "        #out: 1 x vocab_size\n",
    "        self.linear2 = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs['input_ids'], inputs['token_type_ids'])\n",
    "        out = self.attention(embeds)[0].sum(1)\n",
    "        out = self.act_fn(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(cbow.parameters(), 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "cbow.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:17<05:08, 77.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.149527668952942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [02:34<03:51, 77.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0053470134735107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [03:53<02:35, 77.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910863637924194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [05:11<01:17, 77.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965848445892334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:29<00:00, 77.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0136642456054688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(5):\n",
    "    for idx, batch in enumerate(mnli_train_dl):\n",
    "        optim.zero_grad()\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.cuda()\n",
    "\n",
    "        loss = criterion(cbow(batch), batch['labels'])\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-85bebb417cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.nn.init.xavier_normal(nn.Linear(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(128, 768)\n",
    "y = torch.rand(128, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Linear(768, 128)(x)\n",
    "y = nn.Linear(768, 128)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.cat([x, y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.matmul(k, k.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3045,  0.0074,  0.0055,  ...,  0.0111,  0.0035,  0.0050],\n",
       "        [ 0.0074,  0.3605, -0.0142,  ..., -0.0242, -0.0330, -0.0365],\n",
       "        [ 0.0055, -0.0142,  0.2974,  ..., -0.0293, -0.0055,  0.0318],\n",
       "        ...,\n",
       "        [ 0.0111, -0.0242, -0.0293,  ...,  0.2929,  0.0047, -0.0404],\n",
       "        [ 0.0035, -0.0330, -0.0055,  ...,  0.0047,  0.3649, -0.0539],\n",
       "        [ 0.0050, -0.0365,  0.0318,  ..., -0.0404, -0.0539,  0.3125]],\n",
       "       grad_fn=<InverseBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(*k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class m(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(m, self).__init__()\n",
    "        self.k = torch.eye(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = m().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.k.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
