{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import math\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer, EvalPrediction, GlueDataset, default_data_collator) \n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import GlueDataTrainingArguments as DataTrainingArguments\n",
    "from transformers import (HfArgumentParser, Trainer, TrainingArguments,\n",
    "                          glue_compute_metrics, glue_output_modes,\n",
    "                          glue_tasks_num_labels, set_seed)\n",
    "\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers.data.processors.glue import MrpcProcessor, ColaProcessor, MnliProcessor, Sst2Processor, RteProcessor, WnliProcessor, QqpProcessor, QnliProcessor, StsbProcessor\n",
    "\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(model_name_or_path = 'albert-base-v2')\n",
    "data_args = DataTrainingArguments(task_name = 'MNLI', data_dir = '/home/nlp/data/glue_data/MNLI')\n",
    "training_args = TrainingArguments(output_dir = '/home/nlp/experiments/meta/',\n",
    "                                 do_eval = True,\n",
    "                                 per_device_train_batch_size=64)\n",
    "\n",
    "\n",
    "if (\n",
    "    os.path.exists(training_args.output_dir)\n",
    "    and os.listdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(\n",
    "        f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
    "    )\n",
    "\n",
    "# Set seed\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "try:\n",
    "    num_labels = glue_tasks_num_labels[data_args.task_name]\n",
    "    output_mode = glue_output_modes[data_args.task_name]\n",
    "except KeyError:\n",
    "    raise ValueError(\"Task not found: %s\" % (data_args.task_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=data_args.task_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compute_metrics_fn(task_name: str) -> Callable[[EvalPrediction], Dict]:\n",
    "    def compute_metrics_fn(p: EvalPrediction) -> Dict:\n",
    "        if output_mode == \"classification\":\n",
    "            preds = np.argmax(p.predictions, axis=1)\n",
    "        elif output_mode == \"regression\":\n",
    "            preds = np.squeeze(p.predictions)\n",
    "        return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n",
    "\n",
    "    return compute_metrics_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.training_args.TrainingArguments"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments(TrainingArguments):\n",
    "    tasks = ['mrpc', 'cola', 'mnli', 'sst-2', 'rte', 'qqp', 'qnli', 'sts-b']\n",
    "    target_task: str = field(default = 'mrpc')\n",
    "    task_shared: bool = field(default = True)\n",
    "\n",
    "    reload_model = None\n",
    "    num_update_steps: int = field(default = 5)\n",
    "    num_sample_tasks: int = field(default = 5)\n",
    "    inner_learning_rate: float = field(default = 1e-3)\n",
    "    glue_dir : str = field(default = None)\n",
    "    max_len: int = field(default = 80)\n",
    "    output_dir: str\n",
    "    eval_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(glue_dir='/home/nlp/data/glue_data', output_dir='/home/nlp/experiments/meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.tasks = ['mnli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_dict = {\n",
    "          'mrpc': MrpcProcessor,\n",
    "          'cola': ColaProcessor,\n",
    "          'mnli': MnliProcessor,\n",
    "          'sst-2': Sst2Processor,\n",
    "          'rte': RteProcessor,\n",
    "          'wnli': WnliProcessor,\n",
    "          'qqp': QqpProcessor,\n",
    "          'qnli': QnliProcessor,\n",
    "          'sts-b': StsbProcessor\n",
    "        }\n",
    "processors = [processor_dict[task]() for task in args.tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_PATH = os.path.join('home', 'nlp', 'data', 'glue_data')\n",
    "dataset_dict = {\n",
    "          'mrpc': args.glue_dir+'/MRPC',\n",
    "          'cola': args.glue_dir+'/CoLA',\n",
    "          'mnli': args.glue_dir+'/MNLI',\n",
    "          'sst-2': args.glue_dir+'/SST-2',\n",
    "          'rte':  args.glue_dir+'/RTE',\n",
    "          'wnli': args.glue_dir+'/WNLI',\n",
    "          'qqp':  args.glue_dir+'/QQP',\n",
    "          'qnli': args.glue_dir+'/QNLI',\n",
    "          'sts-b': args.glue_dir+'/STS-B'\n",
    "        }\n",
    "data_dirs =  [dataset_dict[task] for task in args.tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, task in enumerate(args.tasks):\n",
    "        if task == args.target_task:\n",
    "            target_task_id = i\n",
    "            break\n",
    "\n",
    "task_cluster_dict = {\n",
    "      'mrpc': 0,\n",
    "      'cola': 1,\n",
    "      'mnli': 0,\n",
    "      'sst-2': 1,\n",
    "      'rte': 0,\n",
    "      'wnli': 0,\n",
    "      'qqp': 0,\n",
    "      'qnli': 2,\n",
    "      'sts-b': 3\n",
    "    }\n",
    "task_clusters = [task_cluster_dict[task] for task in args.tasks] if args.task_shared else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lists = [processor.get_labels() for processor in processors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 0, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1'],\n",
       " ['0', '1'],\n",
       " ['contradiction', 'entailment', 'neutral'],\n",
       " ['0', '1'],\n",
       " ['entailment', 'not_entailment'],\n",
       " ['0', '1'],\n",
       " ['entailment', 'not_entailment'],\n",
       " [None]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.task_shared:\n",
    "    num_labels = [len(label_list) for label_list in label_lists]\n",
    "else:\n",
    "    cluster_num_labels = {0: 3, 1: 2, 2: 2, 3: 1}\n",
    "    num_labels = [cluster_num_labels[task_cluster] for task_cluster in task_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 3, 2, 3, 3, 2, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " glue_output_modes[args.tasks[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nlp/data/glue_data/MRPC',\n",
       " '/home/nlp/data/glue_data/CoLA',\n",
       " '/home/nlp/data/glue_data/MNLI',\n",
       " '/home/nlp/data/glue_data/SST-2',\n",
       " '/home/nlp/data/glue_data/RTE',\n",
       " '/home/nlp/data/glue_data/QQP',\n",
       " '/home/nlp/data/glue_data/QNLI',\n",
       " '/home/nlp/data/glue_data/STS-B']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:23,  2.97s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_list, eval_dataset_list = [], []\n",
    "for task, data_dir in tqdm(zip(args.tasks, data_dirs)):\n",
    "    data_args.task_name = task\n",
    "    data_args.data_dir = data_dir\n",
    "    train_dataset_list.append(GlueDataset(data_args, tokenizer))\n",
    "    eval_dataset_list.append(GlueDataset(data_args, tokenizer, mode = \"dev\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "\n",
    "class MetaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.args =  self.dataset.args\n",
    "        self.processor = self.dataset.processor\n",
    "        self.features = self.dataset.features\n",
    "        self.label_list = self.dataset.label_list\n",
    "        self.output_mode = self.dataset.output_mode\n",
    "        self.indices_mapping = self._get_indices_mapping()\n",
    "        self.num_labels = len(self.indices_mapping.keys())\n",
    "        self.min_len = self.get_len()\n",
    "        #self.data = self.form_data()\n",
    "        self.data = self.get_tensorized_data()\n",
    "    \n",
    "    def get_len(self):\n",
    "        min_len = float(\"inf\")\n",
    "        for values in self.indices_mapping.values():\n",
    "            min_len = min(len(values), min_len)\n",
    "        return min_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.min_len\n",
    "    \n",
    "    def _get_indices_mapping(self):\n",
    "        indices_mapping = {}\n",
    "        for idx, data in enumerate(self.dataset):\n",
    "            indices_mapping.update({idx: data.label})\n",
    "        \n",
    "        temp_mapping = defaultdict(list)\n",
    "        for key, value in sorted(indices_mapping.items()):\n",
    "            temp_mapping[value].append(key)\n",
    "        \n",
    "        indices_mapping = temp_mapping\n",
    "        del temp_mapping\n",
    "        return indices_mapping\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #res = []\n",
    "        # res = OrderedDict()\n",
    "        #for label in self.indices_mapping.keys():\n",
    "            # res[label] = self.features[self.indices_mapping[label][idx]]\n",
    "        #    res.append(self.features[self.indices_mapping[label][idx]])\n",
    "        \n",
    "        return self.data[idx]\n",
    "    \n",
    "    def get_tensorized_data(self):\n",
    "        tensorized_data = []\n",
    "        dtype = torch.long\n",
    "        #for i, data in tqdm(enumerate(self.data)):\n",
    "        for idx in trange(self.min_len):\n",
    "            res = []\n",
    "            for label in range(self.num_labels):\n",
    "                data = self.features[self.indices_mapping[label][idx]]\n",
    "                res.append({\n",
    "                    'input_ids': torch.tensor(data.input_ids, dtype=dtype),\n",
    "                    'attention_mask': torch.tensor(data.attention_mask, dtype=dtype),\n",
    "                    'token_type_ids': torch.tensor(data.token_type_ids, dtype=dtype),\n",
    "                    'labels': torch.tensor(data.label, dtype=dtype)\n",
    "                })\n",
    "            tensorized_data.append(res)\n",
    "        return tensorized_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130899/130899 [00:14<00:00, 9283.70it/s] \n"
     ]
    }
   ],
   "source": [
    "meta_dataset = MetaDataset(train_dataset_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': tensor([    2,    28,  3820,    15,  1033,   877,  1437,    22,    38,   164,\n",
       "            140,    20,    14,   877,    22,    18,   683,   584,    13,     5,\n",
       "           9700, 16514,     6,   163,    14,  1788,     9,     3,  1033,   877,\n",
       "           3049,   683,    17,  5339,    37,    14,   799,     3,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'labels': tensor(0)},\n",
       " {'input_ids': tensor([    2,    14,  6056,  3223,  4096,    38,   656,    96,    15,    54,\n",
       "            774,    16,    14, 19832,    13,     5,   124, 19832, 16429,    20,\n",
       "             14, 27705,    16,    14,  2014,   148,  3497,     6,    15,    25,\n",
       "           1450,  2879,    14, 10887,   774,    19,  2285,    17,  3850,    14,\n",
       "            127,  9406,    15,   768,    32,  1437,    22,    38,  3717,    21,\n",
       "            345,  7454,    16,   186,   348,     9,     3,   419,    14,   774,\n",
       "             16,    14, 19832,    25,    53,    16,    14,   246, 11804,  2285,\n",
       "             63,    20,  1994,    15,    32,  1437,    22,    38,    57,   186,\n",
       "            315, 10996,    27,  3042,     9,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'labels': tensor(1)},\n",
       " {'input_ids': tensor([    2,    42,   143,  1118,    31,    83,   395,    14,  6264,    18,\n",
       "             76,    59,    22,    99,    19,    14,   282,    17,    59,   164,\n",
       "           9723,    43,     3,    14,  6264,    18,   164, 15586,    69,    19,\n",
       "             14,   282,    65,    14,    85,     9,     3,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'labels': tensor(2)}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampler(meta_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(meta_dataset,\n",
    "            batch_size=8,\n",
    "            sampler=sampler,\n",
    "            #collate_fn=default_data_collator,\n",
    "            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**next(iter(dataloader))[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2166], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.2166], requires_grad=True).cuda() + torch.tensor(0.0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = gradient_update_parameters(model, loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6255, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[0]+torch.tensor(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6255, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler_list = []\n",
    "for dataset in train_dataset_list:\n",
    "    train_sampler_list.append(RandomSampler(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 106.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader_list, eval_dataloader_list = [], []\n",
    "data_collator = default_data_collator\n",
    "\n",
    "for train_dataset, eval_dataset, sampler in \\\n",
    "    tqdm(zip(train_dataset_list, eval_dataset_list, train_sampler_list)):\n",
    "    \n",
    "    train_dataloader_list.append(DataLoader(train_dataset,\n",
    "            batch_size=training_args.train_batch_size,\n",
    "            sampler=sampler,\n",
    "            collate_fn=data_collator,\n",
    "            drop_last=True))\n",
    "    \n",
    "    eval_dataloader_list.append(DataLoader(eval_dataset,\n",
    "            batch_size=training_args.train_batch_size,\n",
    "            sampler=sampler,\n",
    "            collate_fn=data_collator,\n",
    "            drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:06,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples = [processor.get_train_examples(data_dir) for processor, data_dir in tqdm(zip(processors, data_dirs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.num_epochs = 1\n",
    "training_args.per_device_train_batch_size = 1\n",
    "args.num_update_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 2847303.0\n"
     ]
    }
   ],
   "source": [
    "train_steps_per_task = [ math.floor((len(train_example)/training_args.per_device_train_batch_size)/(args.num_update_steps+1)) for train_example in train_examples]\n",
    "total_steps = sum(train_steps_per_task) * training_args.num_train_epochs\n",
    "print(f'Total steps: {total_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3668, 8551, 392702, 67349, 2490, 363849, 104743, 5749]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps_per_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.per_device_train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['contradiction', 'entailment', 'neutral']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnli']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1022]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps_per_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = int(len(train_dataloader_list) // training_args.gradient_accumulation_steps * training_args.num_train_epochs)\n",
    "num_train_epochs = training_args.num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders_iters = [iter(train_dataloader) for train_dataloader in train_dataloader_list]\n",
    "\n",
    "extra_ids = []\n",
    "for t_id in range(len(args.tasks)):\n",
    "    extra_ids += [t_id] * train_steps_per_task[t_id]  #math.ceil(len(train_examples[t_id]))\n",
    "extra_ids = np.random.choice(extra_ids, len(extra_ids), replace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train_dataset_list = []\n",
    "for dataset in train_dataset_list:\n",
    "    cur_len = len(dataset)\n",
    "    indices = np.arange(cur_len)\n",
    "    np.random.shuffle(indices)\n",
    "    indices_train_dataset_list.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([311245,  45402, 358631, ..., 152286, 137138, 179078])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_train_dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(train_dataset_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80976,  36001, 260520, ..., 292077, 102911, 114843])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def empty_memory():\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaTrainer(Trainer):\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 args, \n",
    "                 train_dataloader_list,\n",
    "                 eval_dataloader_list,\n",
    "                 compute_metrics,\n",
    "                 prediction_loss_only = False):\n",
    "        \n",
    "        self.model = model.to(args.device)\n",
    "        self.args = args\n",
    "        self.compute_metrics_list = [compute_metrics(task) for task in self.args.tasks]\n",
    "        self.train_dataloader_list = train_dataloader_list\n",
    "        self.eval_dataloader_list = eval_dataloader_list\n",
    "        self.data_collator = DefaultDataCollator()\n",
    "        self.prediction_loss_only = prediction_loss_only\n",
    "        self.eval_results = {}\n",
    "        self._setup_wandb()\n",
    "        \n",
    "    def update_model_params(self, model, fast_params):\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            param.data = fast_params[idx]\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        model = self.model\n",
    "        \n",
    "        self.global_step = 0\n",
    "        nb_tr_steps = 0\n",
    "        tr_loss = 0\n",
    "        optimizer, scheduler = self.get_optimizers(int(len(self.train_dataloader_list[0]) \\\n",
    "        // self.args.gradient_accumulation_steps * self.args.num_train_epochs))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        for _ in trange(int(training_args.num_train_epochs), desc='Epoch'):\n",
    "            model.train()\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples = 0 \n",
    "\n",
    "            train_dataloaders_iters = [iter(train_dataloader) for train_dataloader in train_dataloader_list]\n",
    "\n",
    "            extra_ids = []\n",
    "            for t_id in range(len(args.tasks)):\n",
    "                extra_ids += [t_id] * train_steps_per_task[t_id]  #math.ceil(len(train_examples[t_id]))\n",
    "            extra_ids = np.random.choice(extra_ids, len(extra_ids), replace=False) \n",
    "\n",
    "            meta_loss = 0\n",
    "\n",
    "            for i, task_id in tqdm(enumerate(extra_ids), desc='Task IDs'):\n",
    "                for update_step in range(args.num_update_steps+1):\n",
    "\n",
    "                    try:\n",
    "                        inputs = next(train_dataloaders_iters[task_id])\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "\n",
    "                    for k, v in inputs.items():\n",
    "                        inputs[k] = v.to(args.device)\n",
    "                        if not isinstance(inputs['labels'], torch.cuda.LongTensor):\n",
    "                            inputs['labels'] = inputs['labels'].long()\n",
    "\n",
    "                    if update_step == args.num_update_steps:\n",
    "                        if update_step == 0:\n",
    "                            raise ValueError('update_step cannot be 0!')\n",
    "\n",
    "                        for param, f_param in zip(model.parameters(), fast_params):\n",
    "                            if not param.requires_grad:\n",
    "                                continue\n",
    "                            cur_grad = (param - f_param)/update_step/args.inner_learning_rate\n",
    "                            if param.grad is None:\n",
    "                                param.grad = torch.zeros(cur_grad.size()).cuda()\n",
    "                                param.grad.add_(cur_grad/inputs['labels'].size(0))\n",
    "\n",
    "                    elif update_step == 0:\n",
    "                        loss = model(**inputs)[0]\n",
    "                        grad = torch.autograd.grad(loss, model.parameters(), allow_unused=True)\n",
    "                        fast_params = list(map(lambda p: p[1] - args.inner_learning_rate * p[0] if p[0] is not None else p[1], zip(grad, model.parameters())))\n",
    "\n",
    "                    elif update_step < args.num_update_steps:\n",
    "                        model = self.update_model_params(model, fast_params)\n",
    "                        loss = model(**inputs)[0]\n",
    "                        grad = torch.autograd.grad(loss, fast_params, allow_unused=True)\n",
    "                        fast_params = list(map(lambda p: p[1] - args.inner_learning_rate * p[0] if p[0] is not None else p[1], zip(grad, fast_params)))\n",
    "\n",
    "                if i % args.num_sample_tasks == (args.num_sample_tasks-1):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    meta_loss = 0\n",
    "\n",
    "                self.global_step += 1\n",
    "        \n",
    "                if self.global_step % args.eval_steps == 0:\n",
    "                    for idx, eval_dataloader in enumerate(self.eval_dataloader_list):\n",
    "                        self.compute_metrics = self.compute_metrics_list[idx]\n",
    "                        result = self.evaluate(eval_dataloader.dataset)\n",
    "                        \n",
    "                        for key, value in result.items():\n",
    "                            logger.info(\"%s  %s = %s\",args.tasks[idx], key, value)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/calvin/huggingface\" target=\"_blank\">https://app.wandb.ai/calvin/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/calvin/huggingface/runs/24e03zkf\" target=\"_blank\">https://app.wandb.ai/calvin/huggingface/runs/24e03zkf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = MetaTrainer(model, args, train_dataloader_list,\n",
    "                     eval_dataloader_list, build_compute_metrics_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Task IDs: 0it [00:00, ?it/s]\u001b[A\n",
      "Task IDs: 1it [00:03,  3.75s/it]\u001b[A\n",
      "Task IDs: 2it [00:06,  3.31s/it]\u001b[A\n",
      "Task IDs: 3it [00:08,  3.00s/it]\u001b[A\n",
      "Task IDs: 4it [00:10,  2.79s/it]\u001b[A\n",
      "Task IDs: 5it [00:12,  2.64s/it]\u001b[A\n",
      "Task IDs: 6it [00:15,  2.55s/it]\u001b[A\n",
      "Task IDs: 7it [00:17,  2.47s/it]\u001b[A\n",
      "Task IDs: 8it [00:19,  2.42s/it]\u001b[A\n",
      "Task IDs: 9it [00:22,  2.39s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57a33a779bd458da8acde80ea696983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=26.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.1688626500276418, \"eval_pearson\": -0.07593542849008117, \"eval_spearmanr\": -0.07026298108615246, \"eval_corr\": -0.07309920478811682, \"step\": 10}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221d3f6ddd934581a2847d07923e4c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=66.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.7732348694945828, \"eval_pearson\": 0.047892375448013634, \"eval_spearmanr\": 0.04789237544801361, \"eval_corr\": 0.04789237544801363, \"step\": 10}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016251cf2de84ed6a9b09e1b49f1d05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=614.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.125631565185634, \"eval_pearson\": 0.03112561928614942, \"eval_spearmanr\": 0.031110041573893667, \"eval_corr\": 0.031117830430021545, \"step\": 10}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972a2f7e3f0540698c99b61c08dee665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=55.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.5897113214839589, \"eval_pearson\": -0.03872658021023936, \"eval_spearmanr\": -0.03872658021023939, \"eval_corr\": -0.03872658021023938, \"step\": 10}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c268059e85490898aa5fdfde4b2bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=18.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.3225060535801783, \"eval_pearson\": -0.07009389681708172, \"eval_spearmanr\": -0.07272434521096278, \"eval_corr\": -0.07140912101402225, \"step\": 10}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe063bf69694e7384f245e97ea8a9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=2527.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 0.9290406081956698, \"eval_pearson\": 0.17356125955788465, \"eval_spearmanr\": 0.1917711813336911, \"eval_corr\": 0.18266622044578787, \"step\": 10}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4900e2ccd3754b7b8ff386e4fc9f8d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=342.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Task IDs: 10it [02:16, 36.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.299326989734382, \"eval_pearson\": -0.1945533855892897, \"eval_spearmanr\": -0.1945780773062058, \"eval_corr\": -0.19456573144774775, \"step\": 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Task IDs: 11it [02:19, 25.97s/it]\u001b[A\n",
      "Task IDs: 12it [02:21, 18.89s/it]\u001b[A\n",
      "Task IDs: 13it [02:23, 13.94s/it]\u001b[A\n",
      "Task IDs: 14it [02:26, 10.47s/it]\u001b[A\n",
      "Task IDs: 15it [02:28,  8.05s/it]\u001b[A\n",
      "Task IDs: 16it [02:31,  6.35s/it]\u001b[A\n",
      "Task IDs: 17it [02:33,  5.16s/it]\u001b[A\n",
      "Task IDs: 18it [02:35,  4.32s/it]\u001b[A\n",
      "Task IDs: 19it [02:38,  3.74s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba58c540daf3468e9aa9781737ba99e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=26.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 0.754741173524123, \"eval_pearson\": 0.05367693570305286, \"eval_spearmanr\": 0.05343511206110535, \"eval_corr\": 0.053556023882079105, \"step\": 20}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbafc6142ad46bea5b8ecc670a34f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=66.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.2134370496778777, \"eval_pearson\": -0.0027618219290598003, \"eval_spearmanr\": 0.0009026285023506604, \"eval_corr\": -0.00092959671335457, \"step\": 20}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365bc877e51c457fb3f70160a446bef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=614.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.2278344829230043, \"eval_pearson\": -0.01632747615200033, \"eval_spearmanr\": -0.0161722522877514, \"eval_corr\": -0.016249864219875863, \"step\": 20}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d828643da847e1b64f7f5e1c2dc438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=55.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 1.1502182028510355, \"eval_pearson\": 0.005972333635109359, \"eval_spearmanr\": 0.009997267686546754, \"eval_corr\": 0.007984800660828056, \"step\": 20}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6584ff0b324ee3b60d0a2264a04189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=18.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\"eval_loss\": 0.8318254517184364, \"eval_pearson\": 0.0029989208045044153, \"eval_spearmanr\": 0.0029989208045043867, \"eval_corr\": 0.002998920804504401, \"step\": 20}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567b8e293e464b8aa06a6db919a1b5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=2527.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task IDs: 19it [03:38, 11.49s/it]\n",
      "Epoch:   0%|          | 0/3 [03:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-5799b76306d9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dataloader_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, prediction_loss_only)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0meval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prediction_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                     \u001b[0mstep_eval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlueDataTrainingArguments(task_name='sts-b', data_dir='/home/nlp/data/glue_data/STS-B', max_seq_length=128, overwrite_cache=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1'],\n",
       " ['0', '1'],\n",
       " ['contradiction', 'entailment', 'neutral'],\n",
       " ['0', '1'],\n",
       " ['entailment', 'not_entailment'],\n",
       " ['0', '1'],\n",
       " ['entailment', 'not_entailment'],\n",
       " [None]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del trainer\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
