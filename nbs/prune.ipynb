{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pruner():\n",
    "    def __init__(self, model, layer_type, pct):\n",
    "        self.model = model\n",
    "        self.layer_type = layer_type\n",
    "        self.pct = pct\n",
    "        self._method_type = {'random': prune.RandomUnstructured,\n",
    "                       'l1': prune.L1Unstructured,\n",
    "                       'ln': prune.LnStructured\n",
    "                      }\n",
    "        self._parameters_to_prune = []\n",
    "        self._parameters_to_prune_names = []\n",
    "        \n",
    "        _lin_cnt, _conv_cnt = 0, 0\n",
    "        for name, module in model.named_modules():\n",
    "            if 'linear' in layer_type:\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    self._parameters_to_prune.append((module, 'weight'))\n",
    "                    self._parameters_to_prune_names.append(name)\n",
    "                    _lin_cnt += 1\n",
    "            if 'conv' in layer_type:\n",
    "                if isinstance(module, nn.Conv2d):\n",
    "                    self._parameters_to_prune.append((module, 'weight'))\n",
    "                    self._parameters_to_prune_names.append(name)\n",
    "                    _conv_cnt += 1\n",
    "        print(\"Detected {} Linear layers\".format(_lin_cnt))\n",
    "        print(\"Detected {} Conv layers\".format(_conv_cnt))\n",
    "        \n",
    "    def perform_pruning(self, method, **kwargs):\n",
    "        chosen_method = self._method_type[method]\n",
    "        prune.global_unstructured(\n",
    "            self._parameters_to_prune,\n",
    "            pruning_method=chosen_method,\n",
    "            amount=self.pct,\n",
    "        )\n",
    "        \n",
    "    def make_permanent(self):\n",
    "        for module in self._parameters_to_prune:\n",
    "            prune.remove(module[0], 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 146 Linear layers\n",
      "Detected 0 Conv layers\n"
     ]
    }
   ],
   "source": [
    "prune_proc = Pruner(model, ['linear'], 0.675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_proc.perform_pruning('random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_proc.make_permanent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prune_proc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3 Linear layers\n",
      "Detected 2 Conv layers\n"
     ]
    }
   ],
   "source": [
    "prune_proc = Pruner(model, ['conv', 'linear'], 0.675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_proc.perform_pruning('random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prune_proc.model.conv1._forward_pre_hooks)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_proc.make_permanent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prune_proc.model.conv1._forward_pre_hooks)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
